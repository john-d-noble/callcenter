{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNR7ia3OOAWrt7CnO3lKqhB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/john-d-noble/callcenter/blob/main/CB_Step_3_Classical_Time_Series_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "146748ab",
        "outputId": "4d311bb6-cd0e-4eda-9e9f-d5256b9c048e"
      },
      "source": [
        "!pip install numpy pmdarima prophet statsmodels"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy\n",
            "  Downloading numpy-2.3.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/62.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m51.2/62.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pmdarima\n",
            "  Using cached pmdarima-2.0.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (7.8 kB)\n",
            "Collecting prophet\n",
            "  Downloading prophet-1.1.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting statsmodels\n",
            "  Downloading statsmodels-0.14.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (1.5.2)\n",
            "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (3.0.12)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (1.16.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (2.5.0)\n",
            "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (75.2.0)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (25.0)\n",
            "Requirement already satisfied: cmdstanpy>=1.0.4 in /usr/local/lib/python3.12/dist-packages (from prophet) (1.2.5)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from prophet) (3.10.0)\n",
            "Requirement already satisfied: holidays<1,>=0.25 in /usr/local/lib/python3.12/dist-packages (from prophet) (0.80)\n",
            "Requirement already satisfied: tqdm>=4.36.1 in /usr/local/lib/python3.12/dist-packages (from prophet) (4.67.1)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.12/dist-packages (from prophet) (6.5.2)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels) (1.0.1)\n",
            "Requirement already satisfied: stanio<2.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from cmdstanpy>=1.0.4->prophet) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from holidays<1,>=0.25->prophet) (2.9.0.post0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->prophet) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->prophet) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->prophet) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->prophet) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->prophet) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->prophet) (3.2.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.19->pmdarima) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.19->pmdarima) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.22->pmdarima) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil->holidays<1,>=0.25->prophet) (1.17.0)\n",
            "Downloading numpy-2.3.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached pmdarima-2.0.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (2.3 MB)\n",
            "Downloading prophet-1.1.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.4/14.4 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading statsmodels-0.14.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (10.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m100.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, statsmodels, prophet, pmdarima\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.2 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\n",
            "cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.2 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.3.2 pmdarima-2.0.4 prophet-1.1.7 statsmodels-0.14.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "statsmodels"
                ]
              },
              "id": "444b93cf7f584614a02ec989cb0d9d26"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "\n",
        "# Load the updated dataset\n",
        "df = pd.read_csv('updated_final_merged_data.csv', index_col='Date', parse_dates=True)\n",
        "\n",
        "# Assume 'Calls' is the target column\n",
        "target = 'Calls'\n",
        "\n",
        "# Prepare data: Sort by date if not already\n",
        "df = df.sort_index()\n",
        "\n",
        "# Define forecast horizon (e.g., 7 days for weekly)\n",
        "horizon = 7\n",
        "\n",
        "# Time series cross-validation: 5 splits\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "# Function to calculate metrics\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mape = mean_absolute_percentage_error(y_true, y_pred) * 100  # As percentage\n",
        "    return {'MAE': mae, 'RMSE': rmse, 'MAPE': mape}\n",
        "\n",
        "# Dictionary to store average metrics for each model\n",
        "model_metrics = {}\n",
        "\n",
        "# 1. ARIMA (using SARIMAX with fixed order (1,1,1), no seasonality)\n",
        "arima_preds = []\n",
        "arima_trues = []\n",
        "for train_idx, test_idx in tscv.split(df):\n",
        "    train = df.iloc[train_idx][target]\n",
        "    test = df.iloc[test_idx][target]\n",
        "\n",
        "    # Fit ARIMA (1,1,1)\n",
        "    model = SARIMAX(train, order=(1,1,1))\n",
        "    fit = model.fit(disp=False)\n",
        "\n",
        "    # Forecast\n",
        "    pred = fit.forecast(steps=len(test))\n",
        "\n",
        "    arima_preds.extend(pred)\n",
        "    arima_trues.extend(test)\n",
        "\n",
        "arima_metrics = calculate_metrics(arima_trues, arima_preds)\n",
        "model_metrics['ARIMA'] = arima_metrics\n",
        "\n",
        "# 2. SARIMA (using SARIMAX with order (1,1,1) and seasonal_order (1,1,1,7))\n",
        "sarima_preds = []\n",
        "sarima_trues = []\n",
        "for train_idx, test_idx in tscv.split(df):\n",
        "    train = df.iloc[train_idx][target]\n",
        "    test = df.iloc[test_idx][target]\n",
        "\n",
        "    # Fit SARIMA (1,1,1)(1,1,1)[7]\n",
        "    model = SARIMAX(train, order=(1,1,1), seasonal_order=(1,1,1,7))\n",
        "    fit = model.fit(disp=False)\n",
        "\n",
        "    # Forecast\n",
        "    pred = fit.forecast(steps=len(test))\n",
        "\n",
        "    sarima_preds.extend(pred)\n",
        "    sarima_trues.extend(test)\n",
        "\n",
        "sarima_metrics = calculate_metrics(sarima_trues, sarima_preds)\n",
        "model_metrics['SARIMA'] = sarima_metrics\n",
        "\n",
        "# 3. Exponential Smoothing (Holt-Winters, additive seasonality)\n",
        "ets_preds = []\n",
        "ets_trues = []\n",
        "for train_idx, test_idx in tscv.split(df):\n",
        "    train = df.iloc[train_idx][target]\n",
        "    test = df.iloc[test_idx][target]\n",
        "\n",
        "    # Fit ETS with additive trend and seasonality (period=7)\n",
        "    model = ExponentialSmoothing(train, trend='add', seasonal='add', seasonal_periods=7)\n",
        "    fit = model.fit(optimized=True)\n",
        "\n",
        "    # Forecast\n",
        "    pred = fit.forecast(steps=len(test))\n",
        "\n",
        "    ets_preds.extend(pred)\n",
        "    ets_trues.extend(test)\n",
        "\n",
        "ets_metrics = calculate_metrics(ets_trues, ets_preds)\n",
        "model_metrics['ETS'] = ets_metrics\n",
        "\n",
        "# Summarize performance\n",
        "print(\"\\nModel Performance Summary:\")\n",
        "metrics_df = pd.DataFrame(model_metrics).T\n",
        "print(metrics_df)\n",
        "\n",
        "# Pick winner: Lowest MAE (primary metric)\n",
        "winner = metrics_df['MAE'].idxmin()\n",
        "print(f\"\\nChampion Classical Model: {winner}\")\n",
        "print(f\"Metrics: {metrics_df.loc[winner].to_dict()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjxQZtjKiGtq",
        "outputId": "13db8718-9f61-411b-d20c-839def0307af"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-465939936.py:9: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df = pd.read_csv('updated_final_merged_data.csv', index_col='Date', parse_dates=True)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/statespace/sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
            "  warn('Non-invertible starting MA parameters found.'\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Performance Summary:\n",
            "                MAE         RMSE       MAPE\n",
            "ARIMA   2268.081615  2860.607690  24.432655\n",
            "SARIMA  2560.832224  3163.069470  28.560471\n",
            "ETS     2233.644482  2882.916658  22.573863\n",
            "\n",
            "Champion Classical Model: ETS\n",
            "Metrics: {'MAE': 2233.6444824990926, 'RMSE': 2882.9166581078257, 'MAPE': 22.573863404704717}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**## ### Combined Performance Summary: Baseline vs. Classical Models**\n",
        "\n",
        "To provide a comprehensive overview, below are the performance tables for both the baseline models and the classical time series models. These were evaluated using the same metrics—Mean Absolute Error (MAE, in call counts), Root Mean Squared Error (RMSE, penalizing larger errors), and Mean Absolute Percentage Error (MAPE, as a percentage for relative accuracy)—via time-series cross-validation on the filled dataset. The baseline champion (Seasonal Naive) sets a strong benchmark, while the classical models aim to improve upon it by incorporating trends and seasonality more explicitly.\n",
        "\n",
        "#### Baseline Models Performance\n",
        "| Model          | MAE       | RMSE      | MAPE     |\n",
        "|----------------|-----------|-----------|----------|\n",
        "| Naive          | 2351.46  | 2942.38  | 24.84%  |\n",
        "| Mean           | 1634.56  | 2154.49  | 18.23%  |\n",
        "| Median         | 1613.91  | 2177.89  | 17.38%  |\n",
        "| Seasonal Naive | 907.70   | 1359.05  | 9.67%   |\n",
        "\n",
        "**Baseline Champion**: Seasonal Naive (lowest MAE of 908 calls and MAPE under 10%, leveraging the EDA's strong weekly seasonality).\n",
        "\n",
        "#### Classical Models Performance\n",
        "| Model   | MAE       | RMSE      | MAPE     |\n",
        "|---------|-----------|-----------|----------|\n",
        "| ARIMA   | 2268.08  | 2860.61  | 24.43%  |\n",
        "| SARIMA  | 2560.83  | 3163.07  | 28.56%  |\n",
        "| ETS     | 2233.64  | 2882.92  | 22.57%  |\n",
        "\n",
        "**Classical Champion**: ETS (lowest MAE of 2,234 calls and MAPE of 23%, outperforming ARIMA and SARIMA but lagging behind baselines).\n",
        "\n",
        "### Full Narrative Analysis\n",
        "The baseline models serve as simple yet effective benchmarks, capturing the essence of the call volume data's patterns without complex parameterization. The Naive approach, which repeats the last observed value, struggles with daily variability (MAE ~2,351, MAPE 25%), while the Mean and Median leverage central tendencies for moderate improvements (MAEs around 1,614-1,635, MAPEs 17-18%). However, the Seasonal Naive dominates baselines by exploiting the EDA's identified weekly cycles, achieving a remarkably low MAE of 908 and MAPE under 10%—proving that straightforward repetition of same-day-last-week values aligns well with the dataset's recurring 7-day patterns, even after imputing weekends/holidays.\n",
        "\n",
        "Transitioning to classical models, which incorporate differencing for stationarity (per EDA's ADF test) and explicit seasonality, we see mixed results. ARIMA handles non-seasonal trends adequately but ignores weekly effects, resulting in an MAE of 2,268 and MAPE of 24%—better than pure Naive but worse than Seasonal Naive. SARIMA, designed for seasonality (with weekly order), surprisingly performs the worst (MAE 2,561, MAPE 29%), possibly due to overfitting on outliers or noise in the filled data, failing to generalize despite the EDA's decomposition highlighting strong periodic components. ETS (Holt-Winters) fares best among classics, with an MAE of 2,234 and MAPE of 23%, as its smoothing of additive trends and seasonality provides stability amid the rolling volatility noted in EDA plots.\n",
        "\n",
        "Comparatively, the classical models underperform the baseline champion: ETS's errors are over 2x higher than Seasonal Naive's, suggesting that the data's patterns are more effectively captured by simple seasonal persistence than by these more sophisticated univariate methods. This reinforces the EDA's emphasis on dominant weekly seasonality while indicating potential limitations like sensitivity to imputed values or insufficient handling of market correlations (e.g., VIX/CVOL). To advance, we should prioritize multivariate extensions (e.g., adding regressors to Prophet or SARIMAX) or machine learning hybrids in the next tier, aiming to beat the baseline's 10% MAPE threshold. If not, the efficient Seasonal Naive remains a practical choice for call center forecasting."
      ],
      "metadata": {
        "id": "x86gg1b4jF-C"
      }
    }
  ]
}