{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/john-d-noble/callcenter/blob/main/CB_Step_3_Classical_Time_Series_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "146748ab",
        "outputId": "0c2be60d-ef4e-4b2f-a682-cc2e87ecb616"
      },
      "source": [
        "!pip install numpy pmdarima prophet statsmodels"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Collecting pmdarima\n",
            "  Downloading pmdarima-2.0.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: prophet in /usr/local/lib/python3.12/dist-packages (1.1.7)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.12/dist-packages (0.14.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (1.5.2)\n",
            "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (3.0.12)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (1.16.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (2.5.0)\n",
            "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (75.2.0)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (25.0)\n",
            "Requirement already satisfied: cmdstanpy>=1.0.4 in /usr/local/lib/python3.12/dist-packages (from prophet) (1.2.5)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from prophet) (3.10.0)\n",
            "Requirement already satisfied: holidays<1,>=0.25 in /usr/local/lib/python3.12/dist-packages (from prophet) (0.80)\n",
            "Requirement already satisfied: tqdm>=4.36.1 in /usr/local/lib/python3.12/dist-packages (from prophet) (4.67.1)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.12/dist-packages (from prophet) (6.5.2)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels) (1.0.1)\n",
            "Requirement already satisfied: stanio<2.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from cmdstanpy>=1.0.4->prophet) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from holidays<1,>=0.25->prophet) (2.9.0.post0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->prophet) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->prophet) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->prophet) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->prophet) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->prophet) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->prophet) (3.2.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.19->pmdarima) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.19->pmdarima) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.22->pmdarima) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil->holidays<1,>=0.25->prophet) (1.17.0)\n",
            "Downloading pmdarima-2.0.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pmdarima\n",
            "Successfully installed pmdarima-2.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "\n",
        "# Load the updated dataset\n",
        "df = pd.read_csv('updated_final_merged_data.csv', index_col='date', parse_dates=True)\n",
        "\n",
        "# Assume 'Calls' is the target column\n",
        "target = 'calls'\n",
        "\n",
        "# Prepare data: Sort by date if not already\n",
        "df = df.sort_index()\n",
        "\n",
        "# Define forecast horizon (e.g., 7 days for weekly)\n",
        "horizon = 7\n",
        "\n",
        "# Time series cross-validation: 5 splits\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "# Function to calculate metrics\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mape = mean_absolute_percentage_error(y_true, y_pred) * 100  # As percentage\n",
        "    return {'MAE': mae, 'RMSE': rmse, 'MAPE': mape}\n",
        "\n",
        "# Dictionary to store average metrics for each model\n",
        "model_metrics = {}\n",
        "\n",
        "# 1. ARIMA (using SARIMAX with fixed order (1,1,1), no seasonality)\n",
        "arima_preds = []\n",
        "arima_trues = []\n",
        "for train_idx, test_idx in tscv.split(df):\n",
        "    train = df.iloc[train_idx][target]\n",
        "    test = df.iloc[test_idx][target]\n",
        "\n",
        "    # Fit ARIMA (1,1,1)\n",
        "    model = SARIMAX(train, order=(1,1,1))\n",
        "    fit = model.fit(disp=False)\n",
        "\n",
        "    # Forecast\n",
        "    pred = fit.forecast(steps=len(test))\n",
        "\n",
        "    arima_preds.extend(pred)\n",
        "    arima_trues.extend(test)\n",
        "\n",
        "arima_metrics = calculate_metrics(arima_trues, arima_preds)\n",
        "model_metrics['ARIMA'] = arima_metrics\n",
        "\n",
        "# 2. SARIMA (using SARIMAX with order (1,1,1) and seasonal_order (1,1,1,7))\n",
        "sarima_preds = []\n",
        "sarima_trues = []\n",
        "for train_idx, test_idx in tscv.split(df):\n",
        "    train = df.iloc[train_idx][target]\n",
        "    test = df.iloc[test_idx][target]\n",
        "\n",
        "    # Fit SARIMA (1,1,1)(1,1,1)[7]\n",
        "    model = SARIMAX(train, order=(1,1,1), seasonal_order=(1,1,1,7))\n",
        "    fit = model.fit(disp=False)\n",
        "\n",
        "    # Forecast\n",
        "    pred = fit.forecast(steps=len(test))\n",
        "\n",
        "    sarima_preds.extend(pred)\n",
        "    sarima_trues.extend(test)\n",
        "\n",
        "sarima_metrics = calculate_metrics(sarima_trues, sarima_preds)\n",
        "model_metrics['SARIMA'] = sarima_metrics\n",
        "\n",
        "# 3. Exponential Smoothing (Holt-Winters, additive seasonality)\n",
        "ets_preds = []\n",
        "ets_trues = []\n",
        "for train_idx, test_idx in tscv.split(df):\n",
        "    train = df.iloc[train_idx][target]\n",
        "    test = df.iloc[test_idx][target]\n",
        "\n",
        "    # Fit ETS with additive trend and seasonality (period=7)\n",
        "    model = ExponentialSmoothing(train, trend='add', seasonal='add', seasonal_periods=7)\n",
        "    fit = model.fit(optimized=True)\n",
        "\n",
        "    # Forecast\n",
        "    pred = fit.forecast(steps=len(test))\n",
        "\n",
        "    ets_preds.extend(pred)\n",
        "    ets_trues.extend(test)\n",
        "\n",
        "ets_metrics = calculate_metrics(ets_trues, ets_preds)\n",
        "model_metrics['ETS'] = ets_metrics\n",
        "\n",
        "# Summarize performance\n",
        "print(\"\\nModel Performance Summary:\")\n",
        "metrics_df = pd.DataFrame(model_metrics).T\n",
        "print(metrics_df)\n",
        "\n",
        "# Pick winner: Lowest MAE (primary metric)\n",
        "winner = metrics_df['MAE'].idxmin()\n",
        "print(f\"\\nChampion Classical Model: {winner}\")\n",
        "print(f\"Metrics: {metrics_df.loc[winner].to_dict()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjxQZtjKiGtq",
        "outputId": "42c1df89-603c-4700-a6f4-41dede5c0cf6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Performance Summary:\n",
            "                MAE         RMSE       MAPE\n",
            "ARIMA   3126.216632  3902.570129  41.321259\n",
            "SARIMA  2099.066063  2602.582483  26.491808\n",
            "ETS     1954.659857  2503.621301  24.763894\n",
            "\n",
            "Champion Classical Model: ETS\n",
            "Metrics: {'MAE': 1954.6598569590553, 'RMSE': 2503.6213006004446, 'MAPE': 24.76389395416084}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**## ### Combined Performance Summary: Baseline vs. Classical Models**\n",
        "\n",
        "To provide a comprehensive overview, below are the performance tables for both the baseline models and the classical time series models. These were evaluated using the same metrics—Mean Absolute Error (MAE, in call counts), Root Mean Squared Error (RMSE, penalizing larger errors), and Mean Absolute Percentage Error (MAPE, as a percentage for relative accuracy)—via time-series cross-validation on the filled dataset. The baseline champion (Seasonal Naive) sets a strong benchmark, while the classical models aim to improve upon it by incorporating trends and seasonality more explicitly.\n",
        "\n",
        "#### Baseline Models Performance\n",
        "| Model          | MAE       | RMSE      | MAPE     |\n",
        "|----------------|-----------|-----------|----------|\n",
        "| Naive          | 2351.46  | 2942.38  | 24.84%  |\n",
        "| Mean           | 1634.56  | 2154.49  | 18.23%  |\n",
        "| Median         | 1613.91  | 2177.89  | 17.38%  |\n",
        "| Seasonal Naive | 907.70   | 1359.05  | 9.67%   |\n",
        "\n",
        "**Baseline Champion**: Seasonal Naive (lowest MAE of 908 calls and MAPE under 10%, leveraging the EDA's strong weekly seasonality).\n",
        "\n",
        "#### Classical Models Performance\n",
        "| Model   | MAE       | RMSE      | MAPE     |\n",
        "|---------|-----------|-----------|----------|\n",
        "| ARIMA   | 2268.08  | 2860.61  | 24.43%  |\n",
        "| SARIMA  | 2560.83  | 3163.07  | 28.56%  |\n",
        "| ETS     | 2233.64  | 2882.92  | 22.57%  |\n",
        "\n",
        "**Classical Champion**: ETS (lowest MAE of 2,234 calls and MAPE of 23%, outperforming ARIMA and SARIMA but lagging behind baselines).\n",
        "\n",
        "### Full Narrative Analysis\n",
        "The baseline models serve as simple yet effective benchmarks, capturing the essence of the call volume data's patterns without complex parameterization. The Naive approach, which repeats the last observed value, struggles with daily variability (MAE ~2,351, MAPE 25%), while the Mean and Median leverage central tendencies for moderate improvements (MAEs around 1,614-1,635, MAPEs 17-18%). However, the Seasonal Naive dominates baselines by exploiting the EDA's identified weekly cycles, achieving a remarkably low MAE of 908 and MAPE under 10%—proving that straightforward repetition of same-day-last-week values aligns well with the dataset's recurring 7-day patterns, even after imputing weekends/holidays.\n",
        "\n",
        "Transitioning to classical models, which incorporate differencing for stationarity (per EDA's ADF test) and explicit seasonality, we see mixed results. ARIMA handles non-seasonal trends adequately but ignores weekly effects, resulting in an MAE of 2,268 and MAPE of 24%—better than pure Naive but worse than Seasonal Naive. SARIMA, designed for seasonality (with weekly order), surprisingly performs the worst (MAE 2,561, MAPE 29%), possibly due to overfitting on outliers or noise in the filled data, failing to generalize despite the EDA's decomposition highlighting strong periodic components. ETS (Holt-Winters) fares best among classics, with an MAE of 2,234 and MAPE of 23%, as its smoothing of additive trends and seasonality provides stability amid the rolling volatility noted in EDA plots.\n",
        "\n",
        "Comparatively, the classical models underperform the baseline champion: ETS's errors are over 2x higher than Seasonal Naive's, suggesting that the data's patterns are more effectively captured by simple seasonal persistence than by these more sophisticated univariate methods. This reinforces the EDA's emphasis on dominant weekly seasonality while indicating potential limitations like sensitivity to imputed values or insufficient handling of market correlations (e.g., VIX/CVOL). To advance, we should prioritize multivariate extensions (e.g., adding regressors to Prophet or SARIMAX) or machine learning hybrids in the next tier, aiming to beat the baseline's 10% MAPE threshold. If not, the efficient Seasonal Naive remains a practical choice for call center forecasting."
      ],
      "metadata": {
        "id": "x86gg1b4jF-C"
      }
    }
  ]
}