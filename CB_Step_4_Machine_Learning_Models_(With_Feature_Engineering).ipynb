{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZ+vtM5L93d1i1StTQB3Js",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/john-d-noble/callcenter/blob/main/CB_Step_4_Machine_Learning_Models_(With_Feature_Engineering).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas numpy scikit-learn xgboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqObNxgrjgMd",
        "outputId": "37829f54-42ac-4ea1-dd51-89edec0f459d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.3.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the updated dataset\n",
        "df = pd.read_csv('updated_final_merged_data.csv', index_col='Date', parse_dates=True)\n",
        "\n",
        "# Assume 'Calls' is the target column\n",
        "target = 'Calls'\n",
        "\n",
        "# Prepare data: Sort by date if not already\n",
        "df = df.sort_index()\n",
        "\n",
        "# Feature Engineering\n",
        "# Lags: previous day (lag1) and previous week (lag7)\n",
        "df['Lag1'] = df[target].shift(1)\n",
        "df['Lag7'] = df[target].shift(7)\n",
        "\n",
        "# Rolling statistics: 7-day mean and std\n",
        "df['Rolling_Mean_7'] = df[target].rolling(window=7).mean()\n",
        "df['Rolling_Std_7'] = df[target].rolling(window=7).std()\n",
        "\n",
        "# Day-of-week dummies (from EDA)\n",
        "df = pd.get_dummies(df, columns=['DayOfWeek'], drop_first=True)\n",
        "\n",
        "# Select market features with |corr| > 0.2 from EDA (adjust based on actual high_corr)\n",
        "# Assuming from previous: e.g., '^VIX_Close_^VIX', 'CVOL-USD_Close_CVOL-USD', etc.\n",
        "# For code, select all numeric except target and engineered\n",
        "features = [col for col in df.columns if col != target and df[col].dtype in [np.float64, np.int64, bool]]\n",
        "\n",
        "# Drop NaNs from shifting/rolling\n",
        "df = df.dropna()\n",
        "\n",
        "# X and y\n",
        "X = df[features]\n",
        "y = df[target]\n",
        "\n",
        "# Time series cross-validation: 5 splits\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "# Function to calculate metrics\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mape = mean_absolute_percentage_error(y_true, y_pred) * 100  # As percentage\n",
        "    return {'MAE': mae, 'RMSE': rmse, 'MAPE': mape}\n",
        "\n",
        "# Dictionary to store average metrics for each model\n",
        "model_metrics = {}\n",
        "\n",
        "# Scaler for models that need it (Ridge, SVR)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# 1. Ridge Regression (linear with L2 regularization)\n",
        "ridge_preds = []\n",
        "ridge_trues = []\n",
        "for train_idx, test_idx in tscv.split(df):\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    # Scale\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Fit\n",
        "    model = Ridge(alpha=1.0)\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Predict\n",
        "    pred = model.predict(X_test_scaled)\n",
        "\n",
        "    ridge_preds.extend(pred)\n",
        "    ridge_trues.extend(y_test)\n",
        "\n",
        "ridge_metrics = calculate_metrics(ridge_trues, ridge_preds)\n",
        "model_metrics['Ridge'] = ridge_metrics\n",
        "\n",
        "# 2. Random Forest Regressor\n",
        "rf_preds = []\n",
        "rf_trues = []\n",
        "for train_idx, test_idx in tscv.split(df):\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    # Fit (no scaling needed)\n",
        "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict\n",
        "    pred = model.predict(X_test)\n",
        "\n",
        "    rf_preds.extend(pred)\n",
        "    rf_trues.extend(y_test)\n",
        "\n",
        "rf_metrics = calculate_metrics(rf_trues, rf_preds)\n",
        "model_metrics['Random Forest'] = rf_metrics\n",
        "\n",
        "# 3. XGBoost Regressor\n",
        "xgb_preds = []\n",
        "xgb_trues = []\n",
        "for train_idx, test_idx in tscv.split(df):\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    # Fit (no scaling needed)\n",
        "    model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict\n",
        "    pred = model.predict(X_test)\n",
        "\n",
        "    xgb_preds.extend(pred)\n",
        "    xgb_trues.extend(y_test)\n",
        "\n",
        "xgb_metrics = calculate_metrics(xgb_trues, xgb_preds)\n",
        "model_metrics['XGBoost'] = xgb_metrics\n",
        "\n",
        "# 4. Support Vector Regression (SVR)\n",
        "svr_preds = []\n",
        "svr_trues = []\n",
        "for train_idx, test_idx in tscv.split(df):\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    # Scale\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Fit\n",
        "    model = SVR(kernel='rbf', C=100, epsilon=0.1)\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Predict\n",
        "    pred = model.predict(X_test_scaled)\n",
        "\n",
        "    svr_preds.extend(pred)\n",
        "    svr_trues.extend(y_test)\n",
        "\n",
        "svr_metrics = calculate_metrics(svr_trues, svr_preds)\n",
        "model_metrics['SVR'] = svr_metrics\n",
        "\n",
        "# Summarize performance\n",
        "print(\"\\nModel Performance Summary:\")\n",
        "metrics_df = pd.DataFrame(model_metrics).T\n",
        "print(metrics_df)\n",
        "\n",
        "# Pick winner: Lowest MAE (primary metric)\n",
        "winner = metrics_df['MAE'].idxmin()\n",
        "print(f\"\\nChampion ML Model: {winner}\")\n",
        "print(f\"Metrics: {metrics_df.loc[winner].to_dict()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjTQ75CRjg9t",
        "outputId": "ee899d80-699d-4642-81a8-d4477c7ab60d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3143648958.py:12: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df = pd.read_csv('updated_final_merged_data.csv', index_col='Date', parse_dates=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Performance Summary:\n",
            "                       MAE         RMSE       MAPE\n",
            "Ridge          1011.386531  1392.164956  10.887078\n",
            "Random Forest  1080.180770  1700.625098  11.130627\n",
            "XGBoost        1338.681402  1955.162291  14.519525\n",
            "SVR            1925.278643  2607.626401  20.171805\n",
            "\n",
            "Champion ML Model: Ridge\n",
            "Metrics: {'MAE': 1011.3865312439392, 'RMSE': 1392.1649564183208, 'MAPE': 10.887077830494986}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**### Combined Performance Summary: Baseline, Classical, and Machine Learning Models**\n",
        "\n",
        "To provide a holistic view of the forecasting progression, below are the performance tables for all model tiers evaluated so far: baselines (simple benchmarks), classical time series (univariate with trend/seasonality), and machine learning (multivariate with feature engineering like lags, rollings, dummies, and market indicators). All were assessed using time-series cross-validation on the filled dataset, with metrics including Mean Absolute Error (MAE, in call counts), Root Mean Squared Error (RMSE, emphasizing large errors), and Mean Absolute Percentage Error (MAPE, for relative scale). This cumulative context highlights improvements (or lack thereof) across complexity levels, informed by the EDA's insights on seasonality, trends, and market correlations.\n",
        "\n",
        "#### Baseline Models Performance\n",
        "| Model          | MAE       | RMSE      | MAPE     |\n",
        "|----------------|-----------|-----------|----------|\n",
        "| Naive          | 2351.46  | 2942.38  | 24.84%  |\n",
        "| Mean           | 1634.56  | 2154.49  | 18.23%  |\n",
        "| Median         | 1613.91  | 2177.89  | 17.38%  |\n",
        "| Seasonal Naive | 907.70   | 1359.05  | 9.67%   |\n",
        "\n",
        "**Baseline Champion**: Seasonal Naive (excels due to strong weekly patterns from EDA).\n",
        "\n",
        "#### Classical Models Performance\n",
        "| Model   | MAE       | RMSE      | MAPE     |\n",
        "|---------|-----------|-----------|----------|\n",
        "| ARIMA   | 2268.08  | 2860.61  | 24.43%  |\n",
        "| SARIMA  | 2560.83  | 3163.07  | 28.56%  |\n",
        "| ETS     | 2233.64  | 2882.92  | 22.57%  |\n",
        "\n",
        "**Classical Champion**: ETS (best among classics but underperforms baselines).\n",
        "\n",
        "#### Machine Learning Models Performance\n",
        "| Model         | MAE       | RMSE      | MAPE     |\n",
        "|---------------|-----------|-----------|----------|\n",
        "| Ridge         | 1011.39  | 1392.16  | 10.89%  |\n",
        "| Random Forest | 1080.18  | 1700.63  | 11.13%  |\n",
        "| XGBoost       | 1338.68  | 1955.16  | 14.52%  |\n",
        "| SVR           | 1925.28  | 2607.63  | 20.17%  |\n",
        "\n",
        "**ML Champion**: Ridge (lowest errors, leveraging regularization for stability).\n",
        "\n",
        "### Full Narrative Analysis\n",
        "The baseline models establish a solid starting point, relying on minimal assumptions to benchmark against the call volume data's inherent patterns. The Naive method, repeating the prior day's value, yields high errors (MAE ~2,351, MAPE 25%) due to daily volatility, while Mean and Median offer modest gains (MAEs ~1,614-1,635, MAPEs 17-18%) by centering on overall tendencies—benefiting from the EDA's distribution analysis showing slight skew. The standout Seasonal Naive, with an MAE of 908 and MAPE under 10%, capitalizes on the EDA's decomposed weekly seasonality and day-of-week averages, proving that simple periodic repetition effectively handles the recurring cycles in this 7-day operational context, even post-imputation of weekends/holidays.\n",
        "\n",
        "Classical models, designed to explicitly model trends and seasonality, show limited advancement. ARIMA addresses non-stationarity (per EDA's ADF test suggesting differencing) but ignores seasonality, resulting in an MAE of 2,268 and MAPE of 24%—comparable to Naive but inferior to Seasonal Naive. SARIMA, incorporating weekly terms, disappointingly ranks worst (MAE 2,561, MAPE 29%), likely due to overfitting on outliers or noise in filled data, failing to leverage the EDA's clear periodic signals. ETS performs best in this tier (MAE 2,234, MAPE 23%), using smoothing to balance trends and additive seasonality amid the rolling volatility from EDA plots, yet it still trails baselines by over 2x in MAE, indicating classical univariate approaches add complexity without proportional gains.\n",
        "\n",
        "The machine learning tier, enhanced by feature engineering (e.g., lags for autocorrelation, rollings for trends, day-of-week dummies for seasonality, and market features like VIX/CVOL per EDA correlations >0.2), demonstrates clearer improvements by integrating multivariate signals. Ridge regression, with regularization to handle collinearity, emerges as champion (MAE 1,011, MAPE 11%), offering stability and benefiting from scaled inputs to mitigate outlier impacts. Random Forest follows closely (MAE 1,080, MAPE 11%), using ensembles for non-linearity and feature interactions, while XGBoost (MAE 1,339, MAPE 15%) provides gains through boosting but may overfit on the dataset's noise. SVR lags (MAE 1,925, MAPE 20%), struggling with kernel-based non-linearity in this time-series setup.\n",
        "\n",
        "Cumulatively, ML models outperform classical ones—Ridge reduces ETS's MAE by ~55%—but still fall short of the baseline Seasonal Naive's precision (MAE 908 vs. 1,011), suggesting that while externalities and engineered features add value, the dominant weekly rhythm remains best captured simply. This aligns with EDA findings: strong seasonality trumps complex modeling unless further tuned (e.g., hyperparameter optimization or hybridizing with Prophet). Across tiers, errors trend downward with multivariate integration, but the baseline's efficiency highlights potential over-engineering risks. Next steps could involve deep learning hybrids or ensemble stacking to push below the 10% MAPE benchmark, ensuring scalable, robust forecasts for call center operations."
      ],
      "metadata": {
        "id": "dO7Sxjs8lEib"
      }
    }
  ]
}