{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/john-d-noble/callcenter/blob/main/CB_Step_4_Machine_Learning_Models_(With_Feature_Engineering).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas numpy scikit-learn xgboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqObNxgrjgMd",
        "outputId": "ff76ebf2-43b6-4438-e601-4f9aeafcadc6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the updated dataset\n",
        "df = pd.read_csv('enhanced_eda_data.csv', index_col='date', parse_dates=True)\n",
        "\n",
        "# Assume 'Calls' is the target column\n",
        "target = 'calls'\n",
        "\n",
        "# Prepare data: Sort by date if not already\n",
        "df = df.sort_index()\n",
        "\n",
        "# Feature Engineering\n",
        "# Lags: previous day (lag1) and previous week (lag7)\n",
        "df['Lag1'] = df[target].shift(1)\n",
        "df['Lag7'] = df[target].shift(7)\n",
        "\n",
        "# Rolling statistics: 7-day mean and std\n",
        "df['Rolling_Mean_7'] = df[target].rolling(window=7).mean()\n",
        "df['Rolling_Std_7'] = df[target].rolling(window=7).std()\n",
        "\n",
        "# Day-of-week dummies (from EDA)\n",
        "df = pd.get_dummies(df, columns=['DayOfWeek'], drop_first=True)\n",
        "\n",
        "# Select market features with |corr| > 0.2 from EDA (adjust based on actual high_corr)\n",
        "# Assuming from previous: e.g., '^VIX_Close_^VIX', 'CVOL-USD_Close_CVOL-USD', etc.\n",
        "# For code, select all numeric except target and engineered\n",
        "features = [col for col in df.columns if col != target and df[col].dtype in [np.float64, np.int64, bool]]\n",
        "\n",
        "# Drop NaNs from shifting/rolling\n",
        "df = df.dropna()\n",
        "\n",
        "# X and y\n",
        "X = df[features]\n",
        "y = df[target]\n",
        "\n",
        "# Time series cross-validation: 5 splits\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "# Function to calculate metrics\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mape = mean_absolute_percentage_error(y_true, y_pred) * 100  # As percentage\n",
        "    return {'MAE': mae, 'RMSE': rmse, 'MAPE': mape}\n",
        "\n",
        "# Dictionary to store average metrics for each model\n",
        "model_metrics = {}\n",
        "\n",
        "# Scaler for models that need it (Ridge, SVR)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# 1. Ridge Regression (linear with L2 regularization)\n",
        "ridge_preds = []\n",
        "ridge_trues = []\n",
        "for train_idx, test_idx in tscv.split(df):\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    # Scale\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Fit\n",
        "    model = Ridge(alpha=1.0)\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Predict\n",
        "    pred = model.predict(X_test_scaled)\n",
        "\n",
        "    ridge_preds.extend(pred)\n",
        "    ridge_trues.extend(y_test)\n",
        "\n",
        "ridge_metrics = calculate_metrics(ridge_trues, ridge_preds)\n",
        "model_metrics['Ridge'] = ridge_metrics\n",
        "\n",
        "# 2. Random Forest Regressor\n",
        "rf_preds = []\n",
        "rf_trues = []\n",
        "for train_idx, test_idx in tscv.split(df):\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    # Fit (no scaling needed)\n",
        "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict\n",
        "    pred = model.predict(X_test)\n",
        "\n",
        "    rf_preds.extend(pred)\n",
        "    rf_trues.extend(y_test)\n",
        "\n",
        "rf_metrics = calculate_metrics(rf_trues, rf_preds)\n",
        "model_metrics['Random Forest'] = rf_metrics\n",
        "\n",
        "# 3. XGBoost Regressor\n",
        "xgb_preds = []\n",
        "xgb_trues = []\n",
        "for train_idx, test_idx in tscv.split(df):\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    # Fit (no scaling needed)\n",
        "    model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict\n",
        "    pred = model.predict(X_test)\n",
        "\n",
        "    xgb_preds.extend(pred)\n",
        "    xgb_trues.extend(y_test)\n",
        "\n",
        "xgb_metrics = calculate_metrics(xgb_trues, xgb_preds)\n",
        "model_metrics['XGBoost'] = xgb_metrics\n",
        "\n",
        "# 4. Support Vector Regression (SVR)\n",
        "svr_preds = []\n",
        "svr_trues = []\n",
        "for train_idx, test_idx in tscv.split(df):\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    # Scale\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Fit\n",
        "    model = SVR(kernel='rbf', C=100, epsilon=0.1)\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Predict\n",
        "    pred = model.predict(X_test_scaled)\n",
        "\n",
        "    svr_preds.extend(pred)\n",
        "    svr_trues.extend(y_test)\n",
        "\n",
        "svr_metrics = calculate_metrics(svr_trues, svr_preds)\n",
        "model_metrics['SVR'] = svr_metrics\n",
        "\n",
        "# Summarize performance\n",
        "print(\"\\nModel Performance Summary:\")\n",
        "metrics_df = pd.DataFrame(model_metrics).T\n",
        "print(metrics_df)\n",
        "\n",
        "# Pick winner: Lowest MAE (primary metric)\n",
        "winner = metrics_df['MAE'].idxmin()\n",
        "print(f\"\\nChampion ML Model: {winner}\")\n",
        "print(f\"Metrics: {metrics_df.loc[winner].to_dict()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjTQ75CRjg9t",
        "outputId": "e6df3d92-292b-4476-c215-cb5674338851"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Performance Summary:\n",
            "                       MAE         RMSE       MAPE\n",
            "Ridge           493.337919   624.324098   7.162782\n",
            "Random Forest   396.581019   948.543361   5.098744\n",
            "XGBoost         374.221868   825.921138   5.347607\n",
            "SVR            1997.180295  2693.427873  25.689883\n",
            "\n",
            "Champion ML Model: XGBoost\n",
            "Metrics: {'MAE': 374.22186772127327, 'RMSE': 825.9211378157587, 'MAPE': 5.347607421028823}\n"
          ]
        }
      ]
    }
  ]
}