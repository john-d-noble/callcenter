{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPUuNG/V2M4kvfSHYq+WVeT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/john-d-noble/callcenter/blob/main/CB_Step_3_Classical_Time_Series_%26_Machine_Learning_Models_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 1: Install and Import Necessary Libraries ---\n",
        "# Uninstall and reinstall numpy and pmdarima to resolve potential compatibility issues\n",
        "!pip uninstall -y numpy\n",
        "!pip install numpy==1.26.4\n",
        "!pip install pmdarima\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 687
        },
        "id": "xLSuleVjIWI4",
        "outputId": "fcb1b930-c275-42ab-ce6a-a28c94fbd443"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.26.4\n",
            "Uninstalling numpy-1.26.4:\n",
            "  Successfully uninstalled numpy-1.26.4\n",
            "Collecting numpy==1.26.4\n",
            "  Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "Installing collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "0b94d0be522041c481fbd055eeb545e5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pmdarima in /usr/local/lib/python3.12/dist-packages (2.0.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (1.5.2)\n",
            "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (1.16.1)\n",
            "Requirement already satisfied: statsmodels>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (0.14.5)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (2.5.0)\n",
            "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (75.2.0)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.12/dist-packages (from pmdarima) (25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.19->pmdarima) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.19->pmdarima) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.19->pmdarima) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.22->pmdarima) (3.6.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.13.2->pmdarima) (1.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=0.19->pmdarima) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pmdarima as pm\n",
        "from math import sqrt\n",
        "\n",
        "# Metrics and CV\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
        "\n",
        "# Classical Models\n",
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "from prophet import Prophet\n",
        "\n",
        "# Machine Learning Models\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import ElasticNet"
      ],
      "metadata": {
        "id": "y3TaYQO3ar9L"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 2: Helper Functions & Data Prep ---\n",
        "\n",
        "# Helper functions for metrics\n",
        "def rmse(y_true, y_pred):\n",
        "    return sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "def mape(y_true, y_pred):\n",
        "    y_true, y_pred = np.asarray(y_true), np.asarray(y_pred)\n",
        "    mask = y_true != 0\n",
        "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100.0 if mask.sum() > 0 else np.nan\n",
        "\n",
        "# Helper functions for classical models\n",
        "def infer_seasonal_period(y: pd.Series):\n",
        "    if y.index.freqstr:\n",
        "        freq = y.index.freqstr.upper()\n",
        "        if freq in (\"D\", \"B\"): return 7\n",
        "        if \"W\" in freq: return 52\n",
        "        if \"M\" in freq: return 12\n",
        "    return 7 # Default\n",
        "\n",
        "def fit_predict_arima(y_train, fh, seasonal_period):\n",
        "    model = pm.auto_arima(y_train, seasonal=True, m=seasonal_period, suppress_warnings=True, error_action='ignore', stepwise=True)\n",
        "    return model.predict(n_periods=fh)\n",
        "\n",
        "def fit_predict_ets(y_train, fh, seasonal_period):\n",
        "    model = ExponentialSmoothing(y_train, trend='add', seasonal='add', seasonal_periods=seasonal_period, initialization_method='estimated').fit()\n",
        "    return model.forecast(fh)\n",
        "\n",
        "def fit_predict_prophet(y_train, fh):\n",
        "    train_df = y_train.reset_index().rename(columns={'Date': 'ds', 'calls': 'y'})\n",
        "    model = Prophet()\n",
        "    model.fit(train_df)\n",
        "    future = model.make_future_dataframe(periods=len(y_test), freq='D')\n",
        "    forecast = model.predict(future).tail(len(y_test))\n",
        "    return forecast['yhat'].values\n",
        "\n",
        "# Load and prepare data\n",
        "df = pd.read_csv('enhanced_eda_data.csv', index_col='Date', parse_dates=True)\n",
        "target = 'calls' # Corrected column name\n",
        "\n",
        "# Feature Engineering for ML models\n",
        "df['Lag1'] = df[target].shift(1)\n",
        "df['Lag7'] = df[target].shift(7)\n",
        "df['Rolling_Mean_7'] = df[target].rolling(window=7).mean()\n",
        "df['Rolling_Std_7'] = df[target].rolling(window=7).std()\n",
        "df = pd.get_dummies(df, columns=['DayOfWeek'], drop_first=True)\n",
        "df = df.dropna()\n",
        "\n",
        "features = [col for col in df.columns if col != target and df[col].dtype in ['float64', 'int64', 'bool', 'uint8']]\n",
        "X = df[features]\n",
        "y = df[target]\n",
        "\n",
        "print(\"Data and functions are ready.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1h-oA0uasFA",
        "outputId": "a04c9531-b586-489b-abc7-ed60a3a641c0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data and functions are ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 2: Helper Functions & Data Prep ---\n",
        "\n",
        "# Helper functions for metrics\n",
        "def rmse(y_true, y_pred):\n",
        "    return sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "def mape(y_true, y_pred):\n",
        "    y_true, y_pred = np.asarray(y_true), np.asarray(y_pred)\n",
        "    mask = y_true != 0\n",
        "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100.0 if mask.sum() > 0 else np.nan\n",
        "\n",
        "# Helper functions for classical models\n",
        "def infer_seasonal_period(y: pd.Series):\n",
        "    if y.index.freqstr:\n",
        "        freq = y.index.freqstr.upper()\n",
        "        if freq in (\"D\", \"B\"): return 7\n",
        "        if \"W\" in freq: return 52\n",
        "        if \"M\" in freq: return 12\n",
        "    return 7 # Default\n",
        "\n",
        "def fit_predict_arima(y_train, fh, seasonal_period):\n",
        "    model = pm.auto_arima(y_train, seasonal=True, m=seasonal_period, suppress_warnings=True, error_action='ignore', stepwise=True)\n",
        "    return model.predict(n_periods=fh)\n",
        "\n",
        "def fit_predict_ets(y_train, fh, seasonal_period):\n",
        "    model = ExponentialSmoothing(y_train, trend='add', seasonal='add', seasonal_periods=seasonal_period, initialization_method='estimated').fit()\n",
        "    return model.forecast(fh)\n",
        "\n",
        "def fit_predict_prophet(y_train, fh):\n",
        "    train_df = y_train.reset_index().rename(columns={'Date': 'ds', 'calls': 'y'})\n",
        "    model = Prophet()\n",
        "    model.fit(train_df)\n",
        "    future = model.make_future_dataframe(periods=fh, freq='D')\n",
        "    forecast = model.predict(future).tail(fh)\n",
        "    return forecast['yhat'].values\n",
        "\n",
        "# Load and prepare data\n",
        "df = pd.read_csv('enhanced_eda_data.csv', index_col='Date', parse_dates=True)\n",
        "target = 'calls' # Corrected column name\n",
        "\n",
        "# Feature Engineering for ML models\n",
        "df['Lag1'] = df[target].shift(1)\n",
        "df['Lag7'] = df[target].shift(7)\n",
        "df['Rolling_Mean_7'] = df[target].rolling(window=7).mean()\n",
        "df['Rolling_Std_7'] = df[target].rolling(window=7).std()\n",
        "df = pd.get_dummies(df, columns=['DayOfWeek'], drop_first=True)\n",
        "df = df.dropna()\n",
        "\n",
        "features = [col for col in df.columns if col != target and df[col].dtype in ['float64', 'int64', 'bool', 'uint8']]\n",
        "X = df[features]\n",
        "y = df[target]\n",
        "\n",
        "print(\"Data and functions are ready.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AavcgwFbHXm",
        "outputId": "051c97c6-10d1-4f0e-e174-81bc64754444"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data and functions are ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 3: Run Cross-Validation and Produce Leaderboard ---\n",
        "\n",
        "# Helper function for MASE\n",
        "# def mase(y_true, y_pred, y_train):\n",
        "#     numerator = np.mean(np.abs(y_true - y_pred))\n",
        "#     denominator = np.mean(np.abs(y_train[1:] - y_train[:-1]))\n",
        "#     return numerator / denominator if denominator != 0 else np.nan\n",
        "\n",
        "# Enhanced: Function to calculate metrics + MASE (scaled to Seasonal Naive)\n",
        "from sklearn.metrics import mean_absolute_percentage_error # Import MAPE\n",
        "\n",
        "def calculate_metrics(y_true, y_pred, naive_seasonal_mae=858):  # From Step 2 baseline\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mape = mean_absolute_percentage_error(y_true, y_pred) * 100\n",
        "    mase = mae / naive_seasonal_mae  # Relative to seasonal naive benchmark\n",
        "    return {'MAE': mae, 'RMSE': rmse, 'MAPE': mape, 'MASE': mase}\n",
        "\n",
        "\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "all_metrics = {}\n",
        "seasonal_period = infer_seasonal_period(y)\n",
        "\n",
        "# --- PART 1: Classical Models CV ---\n",
        "print(\"--- Running Classical Models (ARIMA, ETS, Prophet) ---\")\n",
        "classical_models = {\n",
        "    'ARIMA': fit_predict_arima,\n",
        "    'ETS': fit_predict_ets,\n",
        "    'Prophet': fit_predict_prophet\n",
        "}\n",
        "\n",
        "for name, func in classical_models.items():\n",
        "    maes = []\n",
        "    rmses = []\n",
        "    mapes = []\n",
        "    mases = []\n",
        "    print(f\"Cross-validating {name}...\")\n",
        "    for train_idx, test_idx in tscv.split(y):\n",
        "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "        fh = len(y_test)\n",
        "\n",
        "        # ETS and ARIMA need the seasonal period passed in\n",
        "        if name in ['ETS', 'ARIMA']:\n",
        "            forecast = func(y_train, fh, seasonal_period=seasonal_period)\n",
        "        else: # Prophet does not\n",
        "            forecast = func(y_train, fh)\n",
        "\n",
        "        metrics = calculate_metrics(y_test.values, forecast) # Convert y_test to numpy array\n",
        "        maes.append(metrics['MAE'])\n",
        "        rmses.append(metrics['RMSE'])\n",
        "        mapes.append(metrics['MAPE'])\n",
        "        mases.append(metrics['MASE'])\n",
        "\n",
        "    all_metrics[name] = {'MAE': np.mean(maes), 'RMSE': np.mean(rmses), 'MAPE': np.mean(mapes), 'MASE': np.mean(mases)}\n",
        "    print(f\"{name} Average CV MAE: {np.mean(maes):.2f}\")\n",
        "\n",
        "# --- PART 2: Machine Learning Models CV ---\n",
        "print(\"\\n--- Running Machine Learning Models (XGBoost, RandomForest, etc.) ---\")\n",
        "ml_models = {\n",
        "    'XGBoost': XGBRegressor(random_state=42),\n",
        "    'RandomForest': RandomForestRegressor(random_state=42)\n",
        "}\n",
        "param_grids = {\n",
        "    'XGBoost': {'n_estimators': [100, 200], 'learning_rate': [0.05, 0.1]},\n",
        "    'RandomForest': {'n_estimators': [100, 200], 'max_depth': [10, 20]}\n",
        "}\n",
        "\n",
        "for name, model in ml_models.items():\n",
        "    maes = []\n",
        "    rmses = []\n",
        "    mapes = []\n",
        "    mases = []\n",
        "    print(f\"\\nRunning GridSearchCV for {name}...\")\n",
        "    grid_search = GridSearchCV(model, param_grids[name], cv=tscv, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
        "    grid_search.fit(X, y)\n",
        "\n",
        "    # Get best model and make predictions for CV folds to calculate other metrics\n",
        "    best_model = grid_search.best_estimator_\n",
        "    for train_idx, test_idx in tscv.split(X, y):\n",
        "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "        forecast = best_model.predict(X_test)\n",
        "\n",
        "        metrics = calculate_metrics(y_test.values, forecast) # Convert y_test to numpy array\n",
        "        maes.append(metrics['MAE'])\n",
        "        rmses.append(metrics['RMSE'])\n",
        "        mapes.append(metrics['MAPE'])\n",
        "        mases.append(metrics['MASE'])\n",
        "\n",
        "    all_metrics[name] = {'MAE': np.mean(maes), 'RMSE': np.mean(rmses), 'MAPE': np.mean(mapes), 'MASE': np.mean(mases)}\n",
        "\n",
        "    best_mae = -grid_search.best_score_\n",
        "    print(f\"Best CV MAE for {name}: {best_mae:.2f}\")\n",
        "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "\n",
        "\n",
        "# --- PART 3: Unified Leaderboard ---\n",
        "print(\"\\n\" + \"=\"*50 + \"\\nUNIFIED MODEL LEADERBOARD\\n\" + \"=\"*50)\n",
        "leaderboard = pd.DataFrame.from_dict(all_metrics, orient='index').sort_values('MAE')\n",
        "champion_model = leaderboard.index[0]\n",
        "\n",
        "print(leaderboard)\n",
        "print(f\"\\nüèÜ Champion Model: {champion_model} with an average MAE of {leaderboard.iloc[0]['MAE']:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80F8qfbsbHvB",
        "outputId": "3a67e271-72cc-47be-c82e-bcfc646f3672"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Running Classical Models (ARIMA, ETS, Prophet) ---\n",
            "Cross-validating ARIMA...\n",
            "ARIMA Average CV MAE: 2638.25\n",
            "Cross-validating ETS...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfd5mmghi/t5l9cebk.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfd5mmghi/blqzk008.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.12/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=51384', 'data', 'file=/tmp/tmpfd5mmghi/t5l9cebk.json', 'init=/tmp/tmpfd5mmghi/blqzk008.json', 'output', 'file=/tmp/tmpfd5mmghi/prophet_modelb0n_e_z4/prophet_model-20250916184348.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "18:43:48 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "18:43:48 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfd5mmghi/yk_avj8s.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfd5mmghi/_i88h6al.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ETS Average CV MAE: 1608.69\n",
            "Cross-validating Prophet...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.12/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=64208', 'data', 'file=/tmp/tmpfd5mmghi/yk_avj8s.json', 'init=/tmp/tmpfd5mmghi/_i88h6al.json', 'output', 'file=/tmp/tmpfd5mmghi/prophet_model_hfk57g7/prophet_model-20250916184348.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "18:43:48 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "18:43:48 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfd5mmghi/9iy72itb.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfd5mmghi/q5m2y0k4.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.12/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=56173', 'data', 'file=/tmp/tmpfd5mmghi/9iy72itb.json', 'init=/tmp/tmpfd5mmghi/q5m2y0k4.json', 'output', 'file=/tmp/tmpfd5mmghi/prophet_model6hbfbxfe/prophet_model-20250916184349.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "18:43:49 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "18:43:49 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfd5mmghi/82xb801q.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfd5mmghi/b81llrco.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.12/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=67979', 'data', 'file=/tmp/tmpfd5mmghi/82xb801q.json', 'init=/tmp/tmpfd5mmghi/b81llrco.json', 'output', 'file=/tmp/tmpfd5mmghi/prophet_modelj0tqozxj/prophet_model-20250916184349.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "18:43:49 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "18:43:49 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfd5mmghi/715zaqm7.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpfd5mmghi/aakpmhoa.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.12/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=80397', 'data', 'file=/tmp/tmpfd5mmghi/715zaqm7.json', 'init=/tmp/tmpfd5mmghi/aakpmhoa.json', 'output', 'file=/tmp/tmpfd5mmghi/prophet_model6dra_2mz/prophet_model-20250916184349.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "18:43:49 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "18:43:49 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prophet Average CV MAE: 3983.69\n",
            "\n",
            "--- Running Machine Learning Models (XGBoost, RandomForest, etc.) ---\n",
            "\n",
            "Running GridSearchCV for XGBoost...\n",
            "Best CV MAE for XGBoost: 1151.87\n",
            "Best parameters: {'learning_rate': 0.1, 'n_estimators': 100}\n",
            "\n",
            "Running GridSearchCV for RandomForest...\n",
            "Best CV MAE for RandomForest: 1017.66\n",
            "Best parameters: {'max_depth': 20, 'n_estimators': 100}\n",
            "\n",
            "==================================================\n",
            "UNIFIED MODEL LEADERBOARD\n",
            "==================================================\n",
            "                      MAE         RMSE       MAPE      MASE\n",
            "XGBoost        123.097348   168.181477   1.526670  0.143470\n",
            "RandomForest   187.407200   295.129169   2.349396  0.218423\n",
            "ETS           1608.689314  2033.914031  19.316007  1.874929\n",
            "ARIMA         2638.247377  3229.977527  31.565572  3.074880\n",
            "Prophet       3983.689730  4424.119265  53.967103  4.642995\n",
            "\n",
            "üèÜ Champion Model: XGBoost with an average MAE of 123.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8aW08al3bH27"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}