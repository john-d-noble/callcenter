{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/john-d-noble/callcenter/blob/main/FINAL_CX_CB_RUN_3_IPYNB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clHwuOJtzA6S"
      },
      "source": [
        "# Enhanced Time Series Forecasting System\n",
        "\n",
        "**Complete Implementation with 25-30 ML Models and VERIFIED GridSearchCV**\n",
        "\n",
        "This notebook implements a comprehensive machine learning approach to time series forecasting with full debugging.\n",
        "\n",
        "## Key Features:\n",
        "- 25-30 diverse ML models (tree-based, linear, neural networks, ensemble)\n",
        "- VERIFIED GridSearchCV execution with timing\n",
        "- Advanced feature engineering for time series â†’ supervised learning\n",
        "- Market regime-aware model selection and feature engineering\n",
        "- Three-phase optimization: V1 â†’ V2 â†’ VP\n",
        "- Comprehensive debugging and error visibility\n",
        "- Performance monitoring at every step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwAZSmohzA6Y"
      },
      "source": [
        "## GPU and System Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1q5XOFiczA6Z"
      },
      "outputs": [],
      "source": [
        "# Check NVIDIA GPU Status\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Aw50woXzA6c"
      },
      "outputs": [],
      "source": [
        "# PyTorch GPU Setup and System Info\n",
        "import torch\n",
        "import psutil\n",
        "\n",
        "# Check if CUDA (GPU) is available\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
        "    print(\"GPU Memory:\", torch.cuda.get_device_properties(0).total_memory / 1e9, \"GB\")\n",
        "    print(\"GPU Compute Capability:\", torch.cuda.get_device_properties(0).major, \".\", torch.cuda.get_device_properties(0).minor)\n",
        "    GPU_AVAILABLE = True\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Using CPU\")\n",
        "    GPU_AVAILABLE = False\n",
        "\n",
        "# Memory check\n",
        "available_ram_gb = psutil.virtual_memory().available / 1e9\n",
        "total_ram_gb = psutil.virtual_memory().total / 1e9\n",
        "print(f\"Available RAM: {available_ram_gb:.1f} GB\")\n",
        "print(f\"Total RAM: {total_ram_gb:.1f} GB\")\n",
        "\n",
        "# Set system capabilities flags\n",
        "HIGH_MEMORY = available_ram_gb > 16\n",
        "print(f\"\\nSYSTEM CAPABILITIES:\")\n",
        "print(f\"  GPU Available: {GPU_AVAILABLE}\")\n",
        "print(f\"  High Memory: {HIGH_MEMORY}\")\n",
        "\n",
        "# Example: Move a tensor to the GPU\n",
        "x = torch.randn(10, 10).to(device)\n",
        "print(f\"\\nTensor device test: {x.device}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y numpy\n",
        "!pip install numpy==1.26.4\n",
        "!pip install tensorflow\n",
        "!pip install tbats\n",
        "!pip install pmdarima"
      ],
      "metadata": {
        "id": "8J_acMzfzWvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyF8yY-rzA6d"
      },
      "source": [
        "## Enhanced Imports & Logging Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJkmb1WrzA6d",
        "outputId": "8257f2e4-b65c-43b6-8675-9e13afa7b788"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU: Tesla T4\n",
            "GPU Memory: 15.828320256 GB\n",
            "GPU Compute Capability: 7 . 5\n",
            "Available RAM: 52.5 GB\n",
            "Total RAM: 54.8 GB\n",
            "\n",
            "SYSTEM CAPABILITIES:\n",
            "  GPU Available: True\n",
            "  High Memory: True\n",
            "\n",
            "Tensor device test: cuda:0\n",
            "\n",
            "LIBRARY STATUS:\n",
            "  XGBoost: âœ… (GPU: âœ…)\n",
            "  LightGBM: âœ… (GPU: âœ…)\n",
            "  PyTorch: âœ…\n"
          ]
        }
      ],
      "source": [
        "# Enhanced imports with debugging setup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "import time\n",
        "import logging\n",
        "import sys\n",
        "import traceback\n",
        "from datetime import datetime, timedelta\n",
        "from typing import Dict, List, Optional, Tuple, Any, Union\n",
        "from dataclasses import dataclass\n",
        "import itertools\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "# PyTorch GPU Setup and System Info\n",
        "import torch\n",
        "import psutil\n",
        "\n",
        "# Configure comprehensive logging for notebook visibility\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    handlers=[\n",
        "        logging.StreamHandler(sys.stdout),  # Force notebook output\n",
        "        logging.FileHandler('ml_pipeline_debug.log')  # Save to file\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.info(\"DEBUG LOGGING INITIALIZED - Messages will appear in notebook and log file\")\n",
        "\n",
        "# Check if CUDA (GPU) is available\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
        "    print(\"GPU Memory:\", torch.cuda.get_device_properties(0).total_memory / 1e9, \"GB\")\n",
        "    print(\"GPU Compute Capability:\", torch.cuda.get_device_properties(0).major, \".\", torch.cuda.get_device_properties(0).minor)\n",
        "    GPU_AVAILABLE = True\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Using CPU\")\n",
        "    GPU_AVAILABLE = False\n",
        "\n",
        "# Memory check\n",
        "available_ram_gb = psutil.virtual_memory().available / 1e9\n",
        "total_ram_gb = psutil.virtual_memory().total / 1e9\n",
        "print(f\"Available RAM: {available_ram_gb:.1f} GB\")\n",
        "print(f\"Total RAM: {total_ram_gb:.1f} GB\")\n",
        "\n",
        "# Set system capabilities flags\n",
        "HIGH_MEMORY = available_ram_gb > 16\n",
        "print(f\"\\nSYSTEM CAPABILITIES:\")\n",
        "print(f\"  GPU Available: {GPU_AVAILABLE}\")\n",
        "print(f\"  High Memory: {HIGH_MEMORY}\")\n",
        "\n",
        "# Example: Move a tensor to the GPU\n",
        "x = torch.randn(10, 10).to(device)\n",
        "print(f\"\\nTensor device test: {x.device}\")\n",
        "\n",
        "\n",
        "# Core ML imports\n",
        "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import SelectKBest, f_regression, RFE\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.base import clone\n",
        "\n",
        "# Tree-based models\n",
        "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
        "from sklearn.ensemble import BaggingRegressor, AdaBoostRegressor, VotingRegressor, StackingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# Check optional libraries with detailed reporting\n",
        "logger.info(\"Checking optional ML libraries...\")\n",
        "try:\n",
        "    import xgboost as xgb\n",
        "    XGB_AVAILABLE = True\n",
        "    logger.info(f\"XGBoost available: {xgb.__version__}\")\n",
        "    # Test GPU capability\n",
        "    if GPU_AVAILABLE:\n",
        "        try:\n",
        "            test_xgb = xgb.XGBRegressor(tree_method='gpu_hist', n_estimators=1)\n",
        "            XGB_GPU_AVAILABLE = True\n",
        "            logger.info(\"XGBoost GPU support: AVAILABLE\")\n",
        "        except Exception as e:\n",
        "            XGB_GPU_AVAILABLE = False\n",
        "            logger.warning(f\"XGBoost GPU support: NOT AVAILABLE - {str(e)}\")\n",
        "    else:\n",
        "        XGB_GPU_AVAILABLE = False\n",
        "except ImportError:\n",
        "    XGB_AVAILABLE = False\n",
        "    XGB_GPU_AVAILABLE = False\n",
        "    logger.warning(\"XGBoost not available. Install with: pip install xgboost\")\n",
        "\n",
        "try:\n",
        "    import lightgbm as lgb\n",
        "    LGB_AVAILABLE = True\n",
        "    logger.info(f\"LightGBM available: {lgb.__version__}\")\n",
        "    # Test GPU capability\n",
        "    if GPU_AVAILABLE:\n",
        "        try:\n",
        "            test_lgb = lgb.LGBMRegressor(device='gpu', n_estimators=1, verbose=-1)\n",
        "            LGB_GPU_AVAILABLE = True\n",
        "            logger.info(\"LightGBM GPU support: AVAILABLE\")\n",
        "        except Exception as e:\n",
        "            LGB_GPU_AVAILABLE = False\n",
        "            logger.warning(f\"LightGBM GPU support: NOT AVAILABLE - {str(e)}\")\n",
        "    else:\n",
        "        LGB_GPU_AVAILABLE = False\n",
        "except ImportError:\n",
        "    LGB_AVAILABLE = False\n",
        "    LGB_GPU_AVAILABLE = False\n",
        "    logger.warning(\"LightGBM not available. Install with: pip install lightgbm\")\n",
        "\n",
        "# Linear models\n",
        "from sklearn.linear_model import (\n",
        "    LinearRegression, Ridge, Lasso, ElasticNet,\n",
        "    BayesianRidge, ARDRegression, HuberRegressor,\n",
        "    SGDRegressor, PassiveAggressiveRegressor\n",
        ")\n",
        "\n",
        "# Neural networks\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "# Other models\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "\n",
        "# Feature engineering\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from scipy import stats\n",
        "from scipy.signal import find_peaks\n",
        "\n",
        "# Suppress sklearn warnings but keep our logging\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "\n",
        "# Set reproducible seed\n",
        "np.random.seed(42)\n",
        "\n",
        "logger.info(\"All imports completed successfully\")\n",
        "print(f\"\\nLIBRARY STATUS:\")\n",
        "print(f\"  XGBoost: {'âœ…' if XGB_AVAILABLE else 'âŒ'} (GPU: {'âœ…' if XGB_GPU_AVAILABLE else 'âŒ'})\")\n",
        "print(f\"  LightGBM: {'âœ…' if LGB_AVAILABLE else 'âŒ'} (GPU: {'âœ…' if LGB_GPU_AVAILABLE else 'âŒ'})\")\n",
        "print(f\"  PyTorch: {'âœ…' if torch.cuda.is_available() else 'âŒ'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tu83sAf6zA6e"
      },
      "source": [
        "## Configuration with Debug Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Fk7W0fjzA6f",
        "outputId": "9cf860f4-0e2c-47d8-a220-55af4ddfc8f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration and monitoring setup complete\n"
          ]
        }
      ],
      "source": [
        "@dataclass\n",
        "class DebugMLForecastingConfig:\n",
        "    \"\"\"Configuration with comprehensive debugging capabilities\"\"\"\n",
        "\n",
        "    # Data parameters\n",
        "    target_column: str = \"calls\"\n",
        "    seasonal_period: int = 7\n",
        "    test_split_ratio: float = 0.7\n",
        "    validation_split_ratio: float = 0.15\n",
        "\n",
        "    # Feature engineering\n",
        "    max_lags: int = 21\n",
        "    rolling_windows: List[int] = None\n",
        "    create_technical_indicators: bool = True\n",
        "    create_calendar_features: bool = True\n",
        "    polynomial_degree: int = 2\n",
        "\n",
        "    # Model selection\n",
        "    use_tree_models: bool = True\n",
        "    use_linear_models: bool = True\n",
        "    use_neural_models: bool = True\n",
        "    use_ensemble_models: bool = True\n",
        "    use_other_models: bool = True\n",
        "\n",
        "    # GridSearchCV parameters - CRITICAL FOR DEBUGGING\n",
        "    cv_splits: int = 3\n",
        "    parallel_jobs: int = 1  # Single job for debugging visibility\n",
        "    scoring_metric: str = 'neg_mean_absolute_error'\n",
        "    gridsearch_verbose: int = 2  # Show GridSearch progress\n",
        "\n",
        "    # Market regime integration\n",
        "    use_market_regime_switching: bool = True\n",
        "    use_regime_features: bool = True\n",
        "    vix_thresholds: Dict[str, float] = None\n",
        "    regime_specific_models: Dict[str, List[str]] = None\n",
        "\n",
        "    # Optimization levels\n",
        "    quick_search: bool = False  # Force detailed search for debugging\n",
        "    detailed_search: bool = True\n",
        "    top_models_for_optimization: int = 5\n",
        "\n",
        "    # Pipeline phases\n",
        "    enable_v2_feature_engineering: bool = True\n",
        "    enable_vp_optimization: bool = True\n",
        "\n",
        "    # Feature selection\n",
        "    feature_selection_method: str = 'auto'\n",
        "    max_features_ratio: float = 0.8\n",
        "\n",
        "    # Debug settings\n",
        "    debug_mode: bool = True\n",
        "    show_progress: bool = True\n",
        "    time_each_phase: bool = True\n",
        "    validate_gridsearch: bool = True\n",
        "    save_intermediate_results: bool = True\n",
        "\n",
        "    def __post_init__(self):\n",
        "        if self.rolling_windows is None:\n",
        "            if HIGH_MEMORY:\n",
        "                self.rolling_windows = [3, 7, 14, 21, 30]\n",
        "                self.max_lags = 30\n",
        "                self.top_models_for_optimization = 8\n",
        "                self.cv_splits = 5\n",
        "            else:\n",
        "                self.rolling_windows = [3, 7, 14]\n",
        "                self.max_lags = 15\n",
        "                self.top_models_for_optimization = 3\n",
        "\n",
        "        if self.vix_thresholds is None:\n",
        "            self.vix_thresholds = {\n",
        "                'low_volatility': 15,\n",
        "                'normal': 25,\n",
        "                'high_volatility': 35\n",
        "            }\n",
        "\n",
        "        if self.regime_specific_models is None:\n",
        "            self.regime_specific_models = {\n",
        "                'low_volatility': ['LinearRegression', 'Ridge', 'RandomForest'],\n",
        "                'normal': ['RandomForest', 'GradientBoosting', 'XGBoost', 'LightGBM'],\n",
        "                'high_volatility': ['ExtraTrees', 'SVR', 'KNeighbors', 'MLP'],\n",
        "                'extreme_volatility': ['Lasso', 'ElasticNet', 'Huber', 'BayesianRidge']\n",
        "            }\n",
        "\n",
        "        logger.info(f\"Configuration initialized - Debug mode: {self.debug_mode}\")\n",
        "        logger.info(f\"  Max lags: {self.max_lags}\")\n",
        "        logger.info(f\"  Rolling windows: {self.rolling_windows}\")\n",
        "        logger.info(f\"  Top models for optimization: {self.top_models_for_optimization}\")\n",
        "        logger.info(f\"  GridSearch CV splits: {self.cv_splits}\")\n",
        "\n",
        "# Performance monitoring decorator\n",
        "def monitor_performance(func_name: str = None):\n",
        "    \"\"\"Decorator to monitor function execution time and memory\"\"\"\n",
        "    def decorator(func):\n",
        "        def wrapper(*args, **kwargs):\n",
        "            name = func_name or func.__name__\n",
        "            start_time = time.time()\n",
        "            start_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB\n",
        "\n",
        "            logger.info(f\"ðŸš€ Starting {name}...\")\n",
        "\n",
        "            try:\n",
        "                result = func(*args, **kwargs)\n",
        "\n",
        "                end_time = time.time()\n",
        "                end_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB\n",
        "\n",
        "                duration = end_time - start_time\n",
        "                memory_delta = end_memory - start_memory\n",
        "\n",
        "                logger.info(f\"âœ… {name} completed in {duration:.1f}s, memory: {memory_delta:+.1f}MB\")\n",
        "\n",
        "                return result\n",
        "\n",
        "            except Exception as e:\n",
        "                end_time = time.time()\n",
        "                duration = end_time - start_time\n",
        "                logger.error(f\"âŒ {name} failed after {duration:.1f}s: {str(e)}\")\n",
        "                raise\n",
        "\n",
        "        return wrapper\n",
        "    return decorator\n",
        "\n",
        "print(\"Configuration and monitoring setup complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdYu1qI5zA6f"
      },
      "source": [
        "## Base ML Forecaster with Enhanced Debugging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jyIlrnbRzA6g"
      },
      "outputs": [],
      "source": [
        "class DebugMLForecaster:\n",
        "    \"\"\"Enhanced ML forecaster with comprehensive debugging\"\"\"\n",
        "\n",
        "    def __init__(self, name: str, model, debug_mode: bool = True):\n",
        "        self.name = name\n",
        "        self.model = clone(model)\n",
        "        self.pipeline = None\n",
        "        self.is_fitted = False\n",
        "        self.feature_importance_ = None\n",
        "        self.debug_mode = debug_mode\n",
        "        self.training_time = None\n",
        "        self.prediction_time = None\n",
        "        self.fit_error = None\n",
        "\n",
        "    def fit(self, X: pd.DataFrame, y: pd.Series) -> 'DebugMLForecaster':\n",
        "        \"\"\"Fit model with comprehensive error handling and timing\"\"\"\n",
        "\n",
        "        fit_start = time.time()\n",
        "\n",
        "        try:\n",
        "            if self.debug_mode:\n",
        "                logger.debug(f\"Fitting {self.name} on data shape: {X.shape}\")\n",
        "\n",
        "            # Validate input data\n",
        "            if X.empty or y.empty:\n",
        "                raise ValueError(f\"Empty input data for {self.name}\")\n",
        "\n",
        "            if len(X) != len(y):\n",
        "                raise ValueError(f\"Feature/target length mismatch for {self.name}: {len(X)} vs {len(y)}\")\n",
        "\n",
        "            # Convert to numpy arrays for consistent handling\n",
        "            X_array = X.values if isinstance(X, pd.DataFrame) else X\n",
        "            y_array = y.values if isinstance(y, pd.Series) else y\n",
        "\n",
        "            # Check for NaN/inf values\n",
        "            if np.any(np.isnan(X_array)) or np.any(np.isinf(X_array)):\n",
        "                logger.warning(f\"{self.name}: Found NaN/inf in features, cleaning...\")\n",
        "                X_array = np.nan_to_num(X_array, nan=0.0, posinf=1e6, neginf=-1e6)\n",
        "\n",
        "            if np.any(np.isnan(y_array)) or np.any(np.isinf(y_array)):\n",
        "                logger.warning(f\"{self.name}: Found NaN/inf in target, cleaning...\")\n",
        "                y_array = np.nan_to_num(y_array, nan=np.nanmean(y_array))\n",
        "\n",
        "            # Create and fit pipeline\n",
        "            self.pipeline = Pipeline([\n",
        "                ('scaler', StandardScaler()),\n",
        "                ('model', clone(self.model))\n",
        "            ])\n",
        "\n",
        "            # Fit with error handling for specific model types\n",
        "            try:\n",
        "                self.pipeline.fit(X_array, y_array.ravel())\n",
        "                self.is_fitted = True\n",
        "\n",
        "                # Extract feature importance\n",
        "                self._extract_feature_importance(X)\n",
        "\n",
        "                # Test prediction capability\n",
        "                test_pred = self.pipeline.predict(X_array[:min(5, len(X_array))])\n",
        "                if np.any(np.isnan(test_pred)) or np.any(np.isinf(test_pred)):\n",
        "                    logger.warning(f\"{self.name}: Model produces invalid predictions\")\n",
        "                    self.is_fitted = False\n",
        "\n",
        "            except Exception as model_error:\n",
        "                self.fit_error = str(model_error)\n",
        "                logger.error(f\"{self.name} fit failed: {self.fit_error}\")\n",
        "                self.is_fitted = False\n",
        "\n",
        "        except Exception as e:\n",
        "            self.fit_error = str(e)\n",
        "            logger.error(f\"{self.name} preprocessing failed: {self.fit_error}\")\n",
        "            self.is_fitted = False\n",
        "\n",
        "        finally:\n",
        "            self.training_time = time.time() - fit_start\n",
        "\n",
        "            if self.debug_mode:\n",
        "                status = \"âœ… SUCCESS\" if self.is_fitted else \"âŒ FAILED\"\n",
        "                logger.info(f\"{self.name}: {status} (Training time: {self.training_time:.2f}s)\")\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X: pd.DataFrame) -> np.ndarray:\n",
        "        \"\"\"Make predictions with error handling\"\"\"\n",
        "\n",
        "        if not self.is_fitted:\n",
        "            logger.error(f\"{self.name}: Cannot predict - model not fitted\")\n",
        "            return np.zeros(len(X))\n",
        "\n",
        "        pred_start = time.time()\n",
        "\n",
        "        try:\n",
        "            X_array = X.values if isinstance(X, pd.DataFrame) else X\n",
        "\n",
        "            # Clean input data\n",
        "            if np.any(np.isnan(X_array)) or np.any(np.isinf(X_array)):\n",
        "                X_array = np.nan_to_num(X_array, nan=0.0, posinf=1e6, neginf=-1e6)\n",
        "\n",
        "            predictions = self.pipeline.predict(X_array)\n",
        "\n",
        "            # Validate predictions\n",
        "            if np.any(np.isnan(predictions)) or np.any(np.isinf(predictions)):\n",
        "                logger.warning(f\"{self.name}: Invalid predictions detected, cleaning...\")\n",
        "                predictions = np.nan_to_num(predictions, nan=0.0, posinf=1e6, neginf=-1e6)\n",
        "\n",
        "            self.prediction_time = time.time() - pred_start\n",
        "\n",
        "            if self.debug_mode:\n",
        "                logger.debug(f\"{self.name}: Prediction completed in {self.prediction_time:.3f}s\")\n",
        "\n",
        "            return predictions.flatten()\n",
        "\n",
        "        except Exception as e:\n",
        "            self.prediction_time = time.time() - pred_start\n",
        "            logger.error(f\"{self.name} prediction failed: {str(e)}\")\n",
        "            return np.zeros(len(X))\n",
        "\n",
        "    def _extract_feature_importance(self, X: pd.DataFrame):\n",
        "        \"\"\"Extract feature importance if available\"\"\"\n",
        "        try:\n",
        "            model = self.pipeline.named_steps['model']\n",
        "\n",
        "            if hasattr(model, 'feature_importances_'):\n",
        "                importances = model.feature_importances_\n",
        "            elif hasattr(model, 'coef_'):\n",
        "                importances = np.abs(model.coef_).flatten()\n",
        "            else:\n",
        "                importances = None\n",
        "\n",
        "            if importances is not None and len(importances) == len(X.columns):\n",
        "                self.feature_importance_ = dict(zip(X.columns, importances))\n",
        "                if self.debug_mode:\n",
        "                    top_features = sorted(self.feature_importance_.items(), key=lambda x: x[1], reverse=True)[:3]\n",
        "                    logger.debug(f\"{self.name} top features: {[f[0] for f in top_features]}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            if self.debug_mode:\n",
        "                logger.debug(f\"Could not extract feature importance for {self.name}: {str(e)}\")\n",
        "            self.feature_importance_ = None\n",
        "\n",
        "    def get_info(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get comprehensive model information\"\"\"\n",
        "        return {\n",
        "            'name': self.name,\n",
        "            'is_fitted': self.is_fitted,\n",
        "            'training_time': self.training_time,\n",
        "            'prediction_time': self.prediction_time,\n",
        "            'fit_error': self.fit_error,\n",
        "            'has_feature_importance': self.feature_importance_ is not None\n",
        "        }\n",
        "\n",
        "logger.info(\"Enhanced ML Forecaster class loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXskS-B6zA6h"
      },
      "source": [
        "## Data Generation with Debug Tracking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CbKI4FerzA6h"
      },
      "outputs": [],
      "source": [
        "@monitor_performance(\"Data Generation\")\n",
        "def generate_debug_synthetic_data(n_points: int = 300) -> pd.DataFrame:\n",
        "    \"\"\"Generate synthetic data optimized for ML forecasting with debug tracking\"\"\"\n",
        "\n",
        "    logger.info(f\"ðŸ“Š Generating synthetic data with {n_points} points...\")\n",
        "\n",
        "    np.random.seed(42)\n",
        "    dates = pd.date_range(start='2023-01-01', periods=n_points, freq='D')\n",
        "\n",
        "    # Base call volume with complex patterns\n",
        "    trend = np.linspace(8000, 9500, n_points)\n",
        "\n",
        "    # Multiple seasonal components\n",
        "    weekly_seasonal = 1000 * np.sin(2 * np.pi * np.arange(n_points) / 7)\n",
        "    monthly_seasonal = 500 * np.sin(2 * np.pi * np.arange(n_points) / 30)\n",
        "\n",
        "    # Generate VIX first (needed for regime detection)\n",
        "    logger.info(\"  Generating VIX data...\")\n",
        "    base_vix = 18\n",
        "    vix_values = [base_vix]\n",
        "\n",
        "    regime_counts = {'low_volatility': 0, 'normal': 0, 'high_volatility': 0, 'extreme_volatility': 0}\n",
        "\n",
        "    for i in range(1, n_points):\n",
        "        change = 0.15 * (base_vix - vix_values[-1]) + np.random.normal(0, 1.5)\n",
        "        if np.random.random() < 0.08:  # 8% chance of volatility spike\n",
        "            change += np.random.uniform(8, 25)\n",
        "        new_vix = max(8, min(vix_values[-1] + change, 80))  # Cap at reasonable levels\n",
        "        vix_values.append(new_vix)\n",
        "\n",
        "        # Count regimes for validation\n",
        "        if new_vix < 15:\n",
        "            regime_counts['low_volatility'] += 1\n",
        "        elif new_vix < 25:\n",
        "            regime_counts['normal'] += 1\n",
        "        elif new_vix < 35:\n",
        "            regime_counts['high_volatility'] += 1\n",
        "        else:\n",
        "            regime_counts['extreme_volatility'] += 1\n",
        "\n",
        "    vix_series = pd.Series(vix_values, index=dates)\n",
        "\n",
        "    # Create regime-dependent noise\n",
        "    logger.info(\"  Creating regime-dependent patterns...\")\n",
        "    noise_levels = []\n",
        "    for vix_val in vix_values:\n",
        "        if vix_val < 15:  # Low volatility\n",
        "            noise_levels.append(150)\n",
        "        elif vix_val < 25:  # Normal\n",
        "            noise_levels.append(250)\n",
        "        elif vix_val < 35:  # High volatility\n",
        "            noise_levels.append(400)\n",
        "        else:  # Extreme volatility\n",
        "            noise_levels.append(600)\n",
        "\n",
        "    noise = np.random.normal(0, noise_levels)\n",
        "\n",
        "    # Day-of-week effects\n",
        "    dow_effects = np.array([1.3 if d.weekday() < 5 else 0.7 for d in dates])\n",
        "\n",
        "    # Generate call volume with all components\n",
        "    call_volume = (\n",
        "        trend +\n",
        "        weekly_seasonal +\n",
        "        monthly_seasonal\n",
        "    ) * dow_effects + noise\n",
        "\n",
        "    call_volume = np.maximum(call_volume, 1000)  # Minimum call volume\n",
        "\n",
        "    # Generate correlated S&P 500 data\n",
        "    logger.info(\"  Generating S&P 500 data...\")\n",
        "    sp500_base = 4000\n",
        "    sp500_values = [sp500_base]\n",
        "\n",
        "    for i in range(1, n_points):\n",
        "        vix_effect = -0.001 * (vix_values[i] - 20) / 20  # VIX fear effect\n",
        "        base_return = 0.0008 + vix_effect + np.random.normal(0, 0.012)\n",
        "        new_price = sp500_values[-1] * (1 + base_return)\n",
        "        sp500_values.append(max(new_price, 2000))  # Minimum price floor\n",
        "\n",
        "    # Create comprehensive DataFrame - FIXED pandas methods\n",
        "    data = pd.DataFrame({\n",
        "        'calls': call_volume,\n",
        "        'vix': vix_values,\n",
        "        'sp500': sp500_values\n",
        "    }, index=dates)\n",
        "\n",
        "    # Add additional market indicators\n",
        "    data['sp500_volume'] = np.random.gamma(2, 50000000, n_points)\n",
        "    data['treasury_10y'] = 2.5 + 0.5 * np.sin(2 * np.pi * np.arange(n_points) / 365) + np.random.normal(0, 0.1, n_points)\n",
        "\n",
        "    # Clean data - FIXED methods\n",
        "    data = data.ffill().bfill()\n",
        "    data = data.replace([np.inf, -np.inf], np.nan).fillna(data.median())\n",
        "\n",
        "    # Data quality summary\n",
        "    logger.info(\"âœ… Data generation complete:\")\n",
        "    logger.info(f\"  Shape: {data.shape}\")\n",
        "    logger.info(f\"  Call volume range: {data['calls'].min():.0f} - {data['calls'].max():.0f}\")\n",
        "    logger.info(f\"  VIX range: {data['vix'].min():.1f} - {data['vix'].max():.1f}\")\n",
        "    logger.info(f\"  Regime distribution:\")\n",
        "    for regime, count in regime_counts.items():\n",
        "        pct = count / n_points * 100\n",
        "        logger.info(f\"    {regime}: {pct:.1f}%\")\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkrTQOKfzA6i"
      },
      "source": [
        "## Quick Functionality Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9J6NJFodzA6i",
        "outputId": "10eda9a6-99c3-4f24-be49-bc560ef3121c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Functionality test result: PASS\n"
          ]
        }
      ],
      "source": [
        "# Quick test to verify core functionality\n",
        "def quick_functionality_test():\n",
        "    \"\"\"Quick test of core functionality before main execution\"\"\"\n",
        "\n",
        "    logger.info(\"ðŸ§ª Running quick functionality test...\")\n",
        "\n",
        "    try:\n",
        "        # Test data generation\n",
        "        test_data = generate_debug_synthetic_data(n_points=50)\n",
        "        if test_data.empty:\n",
        "            raise ValueError(\"Data generation failed\")\n",
        "\n",
        "        logger.info(\"âœ… Functionality test PASSED\")\n",
        "        logger.info(f\"  Data: {test_data.shape}\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"âŒ Functionality test FAILED: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "# Run the test\n",
        "test_result = quick_functionality_test()\n",
        "print(f\"\\nFunctionality test result: {'PASS' if test_result else 'FAIL'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THIwRyGnzA6j"
      },
      "source": [
        "## Full Pipeline Execution\n",
        "\n",
        "**Note:** The complete pipeline implementation includes:\n",
        "- Model Factory (25+ ML models)\n",
        "- Feature Engineering (100+ features)\n",
        "- Market Regime Analysis\n",
        "- GridSearchCV Optimization\n",
        "- Comprehensive Evaluation\n",
        "\n",
        "**To see the full implementation, use the original artifact or implement the remaining classes as needed.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOXAR6XUzA6j",
        "outputId": "3b02b793-79c2-48e8-db19-2c314fef39ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŽ¯ ML FORECASTING SYSTEM - READY FOR EXECUTION\n",
            "================================================================================\n",
            "\n",
            "To run the full pipeline:\n",
            "1. Implement the remaining classes from the full artifact\n",
            "2. Run: results = run_debug_pipeline()\n",
            "\n",
            "Current status:\n",
            "  GPU Available: True\n",
            "  High Memory: True\n",
            "  XGBoost: True\n",
            "  LightGBM: True\n",
            "  Test Data Generation: âœ… PASS\n"
          ]
        }
      ],
      "source": [
        "# Example execution (requires full implementation)\n",
        "print(\"ðŸŽ¯ ML FORECASTING SYSTEM - READY FOR EXECUTION\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\")\n",
        "print(\"To run the full pipeline:\")\n",
        "print(\"1. Implement the remaining classes from the full artifact\")\n",
        "print(\"2. Run: results = run_debug_pipeline()\")\n",
        "print(\"\")\n",
        "print(\"Current status:\")\n",
        "print(f\"  GPU Available: {GPU_AVAILABLE}\")\n",
        "print(f\"  High Memory: {HIGH_MEMORY}\")\n",
        "print(f\"  XGBoost: {XGB_AVAILABLE}\")\n",
        "print(f\"  LightGBM: {LGB_AVAILABLE}\")\n",
        "print(f\"  Test Data Generation: {'âœ… PASS' if test_result else 'âŒ FAIL'}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# ML MODEL FACTORY\n",
        "# ============================================================================\n",
        "\n",
        "class DebugMLModelFactory:\n",
        "    \"\"\"Model factory with comprehensive creation debugging\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    @monitor_performance(\"Model Creation\")\n",
        "    def create_all_models(config: DebugMLForecastingConfig) -> List[DebugMLForecaster]:\n",
        "        \"\"\"Create comprehensive set of ML models with debugging\"\"\"\n",
        "\n",
        "        logger.info(\"ðŸ­ Creating ML models...\")\n",
        "\n",
        "        all_models = []\n",
        "        creation_stats = {\n",
        "            'total_attempted': 0,\n",
        "            'successful': 0,\n",
        "            'failed': 0,\n",
        "            'errors': []\n",
        "        }\n",
        "\n",
        "        model_groups = [\n",
        "            (\"Tree Models\", config.use_tree_models, DebugMLModelFactory._create_tree_models),\n",
        "            (\"Linear Models\", config.use_linear_models, DebugMLModelFactory._create_linear_models),\n",
        "            (\"Neural Models\", config.use_neural_models, DebugMLModelFactory._create_neural_models),\n",
        "            (\"Ensemble Models\", config.use_ensemble_models, DebugMLModelFactory._create_ensemble_models),\n",
        "            (\"Other Models\", config.use_other_models, DebugMLModelFactory._create_other_models)\n",
        "        ]\n",
        "\n",
        "        for group_name, enabled, creator_func in model_groups:\n",
        "            if not enabled:\n",
        "                logger.info(f\"  â­ï¸ {group_name}: DISABLED\")\n",
        "                continue\n",
        "\n",
        "            logger.info(f\"  ðŸ”¨ Creating {group_name}...\")\n",
        "\n",
        "            try:\n",
        "                group_models = creator_func(config)\n",
        "                group_successful = 0\n",
        "\n",
        "                for model in group_models:\n",
        "                    creation_stats['total_attempted'] += 1\n",
        "\n",
        "                    try:\n",
        "                        # Test model creation\n",
        "                        _ = model.model.get_params()\n",
        "                        all_models.append(model)\n",
        "                        group_successful += 1\n",
        "                        creation_stats['successful'] += 1\n",
        "\n",
        "                        logger.debug(f\"    âœ… {model.name}\")\n",
        "\n",
        "                    except Exception as e:\n",
        "                        creation_stats['failed'] += 1\n",
        "                        error_msg = f\"{model.name}: {str(e)[:50]}...\"\n",
        "                        creation_stats['errors'].append(error_msg)\n",
        "\n",
        "                        logger.warning(f\"    âŒ {model.name} - {str(e)[:50]}...\")\n",
        "\n",
        "                logger.info(f\"    ðŸ“Š {group_name}: {group_successful}/{len(group_models)} successful\")\n",
        "\n",
        "            except Exception as e:\n",
        "                error_msg = f\"{group_name} creation failed: {str(e)}\"\n",
        "                creation_stats['errors'].append(error_msg)\n",
        "                logger.error(f\"    ðŸ’¥ {group_name} creation failed: {str(e)}\")\n",
        "\n",
        "        # Final summary\n",
        "        logger.info(f\"ðŸŽ¯ Model creation complete:\")\n",
        "        logger.info(f\"  Total models: {creation_stats['successful']}/{creation_stats['total_attempted']}\")\n",
        "        logger.info(f\"  Success rate: {creation_stats['successful']/max(1,creation_stats['total_attempted'])*100:.1f}%\")\n",
        "\n",
        "        if creation_stats['errors'] and config.debug_mode:\n",
        "            logger.info(f\"  Errors encountered: {len(creation_stats['errors'])}\")\n",
        "            for error in creation_stats['errors'][:3]:  # Show first 3 errors\n",
        "                logger.debug(f\"    {error}\")\n",
        "\n",
        "        if len(all_models) == 0:\n",
        "            logger.error(\"No models created successfully! Creating fallback models...\")\n",
        "            all_models = DebugMLModelFactory._create_fallback_models(config)\n",
        "\n",
        "        return all_models\n",
        "\n",
        "    @staticmethod\n",
        "    def _create_tree_models(config: DebugMLForecastingConfig) -> List[DebugMLForecaster]:\n",
        "        \"\"\"Create tree-based models\"\"\"\n",
        "        models = []\n",
        "\n",
        "        # Random Forest variants\n",
        "        models.extend([\n",
        "            DebugMLForecaster(\"RandomForest_100\", RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=1), config.debug_mode),\n",
        "            DebugMLForecaster(\"RandomForest_200\", RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=1), config.debug_mode),\n",
        "        ])\n",
        "\n",
        "        # Extra Trees\n",
        "        models.extend([\n",
        "            DebugMLForecaster(\"ExtraTrees_100\", ExtraTreesRegressor(n_estimators=100, random_state=42, n_jobs=1), config.debug_mode),\n",
        "            DebugMLForecaster(\"ExtraTrees_200\", ExtraTreesRegressor(n_estimators=200, random_state=42, n_jobs=1), config.debug_mode),\n",
        "        ])\n",
        "\n",
        "        # Gradient Boosting\n",
        "        models.extend([\n",
        "            DebugMLForecaster(\"GradientBoosting_100\", GradientBoostingRegressor(n_estimators=100, random_state=42), config.debug_mode),\n",
        "            DebugMLForecaster(\"GradientBoosting_200\", GradientBoostingRegressor(n_estimators=200, random_state=42), config.debug_mode),\n",
        "        ])\n",
        "\n",
        "        # XGBoost models (CPU and GPU)\n",
        "        if XGB_AVAILABLE:\n",
        "            models.extend([\n",
        "                DebugMLForecaster(\"XGBoost_100\", xgb.XGBRegressor(n_estimators=100, random_state=42, n_jobs=1), config.debug_mode),\n",
        "                DebugMLForecaster(\"XGBoost_200\", xgb.XGBRegressor(n_estimators=200, random_state=42, n_jobs=1), config.debug_mode),\n",
        "            ])\n",
        "\n",
        "            # GPU models if available\n",
        "            if XGB_GPU_AVAILABLE and HIGH_MEMORY:\n",
        "                models.extend([\n",
        "                    DebugMLForecaster(\"XGBoost_GPU_200\", xgb.XGBRegressor(n_estimators=200, tree_method='gpu_hist', gpu_id=0, random_state=42), config.debug_mode),\n",
        "                    DebugMLForecaster(\"XGBoost_GPU_500\", xgb.XGBRegressor(n_estimators=500, tree_method='gpu_hist', gpu_id=0, random_state=42), config.debug_mode),\n",
        "                ])\n",
        "\n",
        "        # LightGBM models\n",
        "        if LGB_AVAILABLE:\n",
        "            models.extend([\n",
        "                DebugMLForecaster(\"LightGBM_100\", lgb.LGBMRegressor(n_estimators=100, random_state=42, verbose=-1, n_jobs=1), config.debug_mode),\n",
        "                DebugMLForecaster(\"LightGBM_200\", lgb.LGBMRegressor(n_estimators=200, random_state=42, verbose=-1, n_jobs=1), config.debug_mode),\n",
        "            ])\n",
        "\n",
        "            # GPU models if available\n",
        "            if LGB_GPU_AVAILABLE and HIGH_MEMORY:\n",
        "                models.extend([\n",
        "                    DebugMLForecaster(\"LightGBM_GPU_200\", lgb.LGBMRegressor(n_estimators=200, device='gpu', random_state=42, verbose=-1), config.debug_mode),\n",
        "                    DebugMLForecaster(\"LightGBM_GPU_500\", lgb.LGBMRegressor(n_estimators=500, device='gpu', random_state=42, verbose=-1), config.debug_mode),\n",
        "                ])\n",
        "\n",
        "        # Decision Tree\n",
        "        models.append(\n",
        "            DebugMLForecaster(\"DecisionTree\", DecisionTreeRegressor(random_state=42, max_depth=10), config.debug_mode)\n",
        "        )\n",
        "\n",
        "        return models\n",
        "\n",
        "    @staticmethod\n",
        "    def _create_linear_models(config: DebugMLForecastingConfig) -> List[DebugMLForecaster]:\n",
        "        \"\"\"Create linear models\"\"\"\n",
        "        models = []\n",
        "\n",
        "        # Basic linear models\n",
        "        models.extend([\n",
        "            DebugMLForecaster(\"LinearRegression\", LinearRegression(), config.debug_mode),\n",
        "            DebugMLForecaster(\"Ridge_0.1\", Ridge(alpha=0.1), config.debug_mode),\n",
        "            DebugMLForecaster(\"Ridge_1.0\", Ridge(alpha=1.0), config.debug_mode),\n",
        "            DebugMLForecaster(\"Ridge_10.0\", Ridge(alpha=10.0), config.debug_mode),\n",
        "            DebugMLForecaster(\"Lasso_0.1\", Lasso(alpha=0.1, max_iter=2000), config.debug_mode),\n",
        "            DebugMLForecaster(\"Lasso_1.0\", Lasso(alpha=1.0, max_iter=2000), config.debug_mode),\n",
        "            DebugMLForecaster(\"ElasticNet_0.1\", ElasticNet(alpha=0.1, max_iter=2000), config.debug_mode),\n",
        "            DebugMLForecaster(\"ElasticNet_1.0\", ElasticNet(alpha=1.0, max_iter=2000), config.debug_mode),\n",
        "        ])\n",
        "\n",
        "        # Bayesian models\n",
        "        models.extend([\n",
        "            DebugMLForecaster(\"BayesianRidge\", BayesianRidge(), config.debug_mode),\n",
        "            DebugMLForecaster(\"ARDRegression\", ARDRegression(max_iter=500), config.debug_mode),\n",
        "        ])\n",
        "\n",
        "        # Robust models\n",
        "        models.extend([\n",
        "            DebugMLForecaster(\"HuberRegressor\", HuberRegressor(max_iter=200), config.debug_mode),\n",
        "            DebugMLForecaster(\"SGDRegressor\", SGDRegressor(random_state=42, max_iter=2000), config.debug_mode),\n",
        "        ])\n",
        "\n",
        "        return models\n",
        "\n",
        "    @staticmethod\n",
        "    def _create_neural_models(config: DebugMLForecastingConfig) -> List[DebugMLForecaster]:\n",
        "        \"\"\"Create neural network models\"\"\"\n",
        "        models = []\n",
        "\n",
        "        # MLPRegressor variants with proper parameters\n",
        "        models.extend([\n",
        "            DebugMLForecaster(\"MLP_50\", MLPRegressor(\n",
        "                hidden_layer_sizes=(50,),\n",
        "                random_state=42,\n",
        "                max_iter=1000,\n",
        "                early_stopping=True,\n",
        "                validation_fraction=0.1,\n",
        "                n_iter_no_change=10\n",
        "            ), config.debug_mode),\n",
        "            DebugMLForecaster(\"MLP_100_50\", MLPRegressor(\n",
        "                hidden_layer_sizes=(100, 50),\n",
        "                random_state=42,\n",
        "                max_iter=1000,\n",
        "                early_stopping=True,\n",
        "                validation_fraction=0.1,\n",
        "                n_iter_no_change=10\n",
        "            ), config.debug_mode),\n",
        "            DebugMLForecaster(\"MLP_200_100\", MLPRegressor(\n",
        "                hidden_layer_sizes=(200, 100),\n",
        "                random_state=42,\n",
        "                max_iter=1000,\n",
        "                early_stopping=True,\n",
        "                validation_fraction=0.1,\n",
        "                n_iter_no_change=10\n",
        "            ), config.debug_mode),\n",
        "        ])\n",
        "\n",
        "        return models\n",
        "\n",
        "    @staticmethod\n",
        "    def _create_ensemble_models(config: DebugMLForecastingConfig) -> List[DebugMLForecaster]:\n",
        "        \"\"\"Create ensemble models\"\"\"\n",
        "        models = []\n",
        "\n",
        "        # Bagging models\n",
        "        models.extend([\n",
        "            DebugMLForecaster(\"BaggingRegressor\", BaggingRegressor(random_state=42, n_jobs=1), config.debug_mode),\n",
        "            DebugMLForecaster(\"AdaBoostRegressor\", AdaBoostRegressor(random_state=42, n_estimators=50), config.debug_mode),\n",
        "        ])\n",
        "\n",
        "        # Voting ensemble\n",
        "        try:\n",
        "            voting_models = [\n",
        "                ('rf', RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=1)),\n",
        "                ('ridge', Ridge(alpha=1.0)),\n",
        "                ('tree', DecisionTreeRegressor(random_state=42, max_depth=10))\n",
        "            ]\n",
        "            models.append(\n",
        "                DebugMLForecaster(\"VotingRegressor\", VotingRegressor(estimators=voting_models, n_jobs=1), config.debug_mode)\n",
        "            )\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Could not create VotingRegressor: {str(e)}\")\n",
        "\n",
        "        return models\n",
        "\n",
        "    @staticmethod\n",
        "    def _create_other_models(config: DebugMLForecastingConfig) -> List[DebugMLForecaster]:\n",
        "        \"\"\"Create other ML models\"\"\"\n",
        "        models = []\n",
        "\n",
        "        # Support Vector Regression\n",
        "        models.extend([\n",
        "            DebugMLForecaster(\"SVR_linear\", SVR(kernel='linear', C=1.0), config.debug_mode),\n",
        "            DebugMLForecaster(\"SVR_rbf\", SVR(kernel='rbf', C=1.0), config.debug_mode),\n",
        "        ])\n",
        "\n",
        "        # K-Nearest Neighbors\n",
        "        models.extend([\n",
        "            DebugMLForecaster(\"KNeighbors_5\", KNeighborsRegressor(n_neighbors=5), config.debug_mode),\n",
        "            DebugMLForecaster(\"KNeighbors_10\", KNeighborsRegressor(n_neighbors=10), config.debug_mode),\n",
        "        ])\n",
        "\n",
        "        # Kernel Ridge\n",
        "        models.append(\n",
        "            DebugMLForecaster(\"KernelRidge\", KernelRidge(alpha=1.0), config.debug_mode)\n",
        "        )\n",
        "\n",
        "        return models\n",
        "\n",
        "    @staticmethod\n",
        "    def _create_fallback_models(config: DebugMLForecastingConfig) -> List[DebugMLForecaster]:\n",
        "        \"\"\"Create basic fallback models if all others fail\"\"\"\n",
        "        logger.warning(\"Creating fallback models...\")\n",
        "\n",
        "        return [\n",
        "            DebugMLForecaster(\"Fallback_LinearRegression\", LinearRegression(), config.debug_mode),\n",
        "            DebugMLForecaster(\"Fallback_Ridge\", Ridge(alpha=1.0), config.debug_mode),\n",
        "            DebugMLForecaster(\"Fallback_RandomForest\", RandomForestRegressor(n_estimators=50, random_state=42), config.debug_mode)\n",
        "        ]\n",
        "\n",
        "print(\"DebugMLModelFactory loaded\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmAB8lIc61zm",
        "outputId": "3627f292-c787-4dcb-c50e-d8efcfe41f39"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DebugMLModelFactory loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# FEATURE ENGINEERING\n",
        "# ============================================================================\n",
        "\n",
        "class DebugFeatureEngineer:\n",
        "    \"\"\"Advanced feature engineering with comprehensive debugging\"\"\"\n",
        "\n",
        "    def __init__(self, config: DebugMLForecastingConfig):\n",
        "        self.config = config\n",
        "        self.feature_names_ = []\n",
        "        self.feature_creation_log = []\n",
        "\n",
        "    @monitor_performance(\"Feature Engineering\")\n",
        "    def create_features(self, data: pd.DataFrame, regime_data: pd.Series = None) -> pd.DataFrame:\n",
        "        \"\"\"Create comprehensive feature set with debugging\"\"\"\n",
        "\n",
        "        logger.info(f\"ðŸ› ï¸ Starting feature engineering on data shape: {data.shape}\")\n",
        "\n",
        "        # Validate input\n",
        "        if data.empty:\n",
        "            raise ValueError(\"Empty input data for feature engineering\")\n",
        "\n",
        "        target_col = self.config.target_column\n",
        "        if target_col not in data.columns:\n",
        "            raise ValueError(f\"Target column '{target_col}' not found in data\")\n",
        "\n",
        "        # Initialize features dataframe\n",
        "        features_df = pd.DataFrame(index=data.index)\n",
        "        target_series = data[target_col].copy()\n",
        "\n",
        "        # Log initial data quality\n",
        "        nan_count = target_series.isna().sum()\n",
        "        logger.info(f\"Target series: {len(target_series)} points, {nan_count} NaN values\")\n",
        "\n",
        "        # Feature creation steps with individual error handling\n",
        "        feature_steps = [\n",
        "            (\"Lagged Features\", self._add_lagged_features, target_series),\n",
        "            (\"Rolling Features\", self._add_rolling_features, target_series),\n",
        "            (\"Technical Indicators\", self._add_technical_indicators, target_series),\n",
        "            (\"Calendar Features\", self._add_calendar_features, None),\n",
        "            (\"Statistical Features\", self._add_statistical_features, target_series)\n",
        "        ]\n",
        "\n",
        "        # Add market features if available\n",
        "        if 'vix' in data.columns:\n",
        "            feature_steps.append((\"Market Features\", self._add_market_features, data))\n",
        "\n",
        "        # Add regime features if available\n",
        "        if self.config.use_regime_features and regime_data is not None:\n",
        "            feature_steps.append((\"Regime Features\", self._add_regime_features, regime_data))\n",
        "\n",
        "        # Execute feature creation steps\n",
        "        for step_name, step_func, step_data in feature_steps:\n",
        "            initial_count = len(features_df.columns)\n",
        "            step_start = time.time()\n",
        "\n",
        "            try:\n",
        "                logger.info(f\"  ðŸ”§ Creating {step_name}...\")\n",
        "\n",
        "                if step_name == \"Calendar Features\":\n",
        "                    features_df = step_func(features_df)\n",
        "                else:\n",
        "                    features_df = step_func(features_df, step_data)\n",
        "\n",
        "                added_count = len(features_df.columns) - initial_count\n",
        "                step_time = time.time() - step_start\n",
        "\n",
        "                logger.info(f\"    âœ… {step_name}: +{added_count} features ({step_time:.2f}s)\")\n",
        "                self.feature_creation_log.append({\n",
        "                    'step': step_name,\n",
        "                    'features_added': added_count,\n",
        "                    'time': step_time,\n",
        "                    'status': 'success'\n",
        "                })\n",
        "\n",
        "            except Exception as e:\n",
        "                step_time = time.time() - step_start\n",
        "                logger.error(f\"    âŒ {step_name} failed: {str(e)}\")\n",
        "                self.feature_creation_log.append({\n",
        "                    'step': step_name,\n",
        "                    'features_added': 0,\n",
        "                    'time': step_time,\n",
        "                    'status': 'failed',\n",
        "                    'error': str(e)\n",
        "                })\n",
        "\n",
        "        # Clean and validate features\n",
        "        logger.info(f\"  ðŸ§¹ Cleaning features...\")\n",
        "        features_df = self._clean_features(features_df)\n",
        "\n",
        "        self.feature_names_ = list(features_df.columns)\n",
        "\n",
        "        # Log final feature summary\n",
        "        logger.info(f\"âœ… Feature engineering complete:\")\n",
        "        logger.info(f\"  Final shape: {features_df.shape}\")\n",
        "        logger.info(f\"  Features created: {len(self.feature_names_)}\")\n",
        "\n",
        "        return features_df\n",
        "\n",
        "    def _add_lagged_features(self, df: pd.DataFrame, series: pd.Series) -> pd.DataFrame:\n",
        "        \"\"\"Add lagged features with validation\"\"\"\n",
        "        max_lags = min(self.config.max_lags, len(series) // 4)\n",
        "        logger.debug(f\"Creating {max_lags} lag features\")\n",
        "\n",
        "        for lag in range(1, max_lags + 1):\n",
        "            df[f'lag_{lag}'] = series.shift(lag)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _add_rolling_features(self, df: pd.DataFrame, series: pd.Series) -> pd.DataFrame:\n",
        "        \"\"\"Add rolling window features with validation\"\"\"\n",
        "        for window in self.config.rolling_windows:\n",
        "            if window < len(series):\n",
        "                df[f'rolling_mean_{window}'] = series.rolling(window=window, min_periods=1).mean()\n",
        "                df[f'rolling_std_{window}'] = series.rolling(window=window, min_periods=1).std()\n",
        "                df[f'rolling_min_{window}'] = series.rolling(window=window, min_periods=1).min()\n",
        "                df[f'rolling_max_{window}'] = series.rolling(window=window, min_periods=1).max()\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _add_technical_indicators(self, df: pd.DataFrame, series: pd.Series) -> pd.DataFrame:\n",
        "        \"\"\"Add technical indicators with error handling\"\"\"\n",
        "        try:\n",
        "            # RSI calculation\n",
        "            for period in [7, 14]:\n",
        "                if period < len(series):\n",
        "                    delta = series.diff()\n",
        "                    gain = delta.where(delta > 0, 0).rolling(window=period, min_periods=1).mean()\n",
        "                    loss = (-delta.where(delta < 0, 0)).rolling(window=period, min_periods=1).mean()\n",
        "                    rs = gain / (loss + 1e-8)\n",
        "                    df[f'rsi_{period}'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "            # Moving average ratios\n",
        "            if len(series) > 12:\n",
        "                ma_short = series.rolling(window=5, min_periods=1).mean()\n",
        "                ma_long = series.rolling(window=12, min_periods=1).mean()\n",
        "                df['ma_ratio'] = ma_short / (ma_long + 1e-8)\n",
        "\n",
        "            # Momentum indicators\n",
        "            for period in [3, 7]:\n",
        "                if period < len(series):\n",
        "                    df[f'momentum_{period}'] = series / (series.shift(period) + 1e-8) - 1\n",
        "                    df[f'rate_of_change_{period}'] = series.pct_change(periods=period)\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Technical indicators creation failed: {str(e)}\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _add_calendar_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Add calendar features with validation\"\"\"\n",
        "        try:\n",
        "            if isinstance(df.index, pd.DatetimeIndex):\n",
        "                df['dow'] = df.index.dayofweek\n",
        "                df['is_weekend'] = (df['dow'] >= 5).astype(int)\n",
        "                df['month'] = df.index.month\n",
        "                df['quarter'] = df.index.quarter\n",
        "                df['day_of_month'] = df.index.day\n",
        "                df['day_of_year'] = df.index.dayofyear\n",
        "\n",
        "                # Cyclical encoding\n",
        "                df['dow_sin'] = np.sin(2 * np.pi * df['dow'] / 7)\n",
        "                df['dow_cos'] = np.cos(2 * np.pi * df['dow'] / 7)\n",
        "                df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
        "                df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
        "            else:\n",
        "                # Position-based features for non-datetime index\n",
        "                df['position'] = np.arange(len(df))\n",
        "                df['position_sin'] = np.sin(2 * np.pi * df['position'] / 7)\n",
        "                df['position_cos'] = np.cos(2 * np.pi * df['position'] / 7)\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Calendar features creation failed: {str(e)}\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _add_market_features(self, df: pd.DataFrame, data: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Add market features with validation\"\"\"\n",
        "        try:\n",
        "            if 'vix' in data.columns:\n",
        "                df['vix'] = data['vix']\n",
        "                df['vix_lag1'] = data['vix'].shift(1)\n",
        "                df['vix_change'] = data['vix'].diff()\n",
        "                if len(data['vix']) > 7:\n",
        "                    df['vix_rolling_7'] = data['vix'].rolling(7, min_periods=1).mean()\n",
        "\n",
        "            if 'sp500' in data.columns:\n",
        "                df['sp500_return'] = data['sp500'].pct_change()\n",
        "                if len(data['sp500']) > 7:\n",
        "                    df['sp500_volatility'] = data['sp500'].pct_change().rolling(7, min_periods=1).std()\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Market features creation failed: {str(e)}\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _add_regime_features(self, df: pd.DataFrame, regime_data: pd.Series) -> pd.DataFrame:\n",
        "        \"\"\"Add regime features with validation\"\"\"\n",
        "        try:\n",
        "            aligned_regimes = regime_data.reindex(df.index, method='ffill')\n",
        "            regime_dummies = pd.get_dummies(aligned_regimes, prefix='regime')\n",
        "            regime_dummies.index = df.index\n",
        "            df = pd.concat([df, regime_dummies], axis=1)\n",
        "\n",
        "            # Regime duration\n",
        "            regime_changes = aligned_regimes != aligned_regimes.shift(1)\n",
        "            regime_groups = regime_changes.cumsum()\n",
        "            df['regime_duration'] = regime_groups.groupby(regime_groups).cumcount() + 1\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Regime features creation failed: {str(e)}\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _add_statistical_features(self, df: pd.DataFrame, series: pd.Series) -> pd.DataFrame:\n",
        "        \"\"\"Add statistical features\"\"\"\n",
        "        try:\n",
        "            # Z-scores\n",
        "            for window in [7, 14]:\n",
        "                if window < len(series):\n",
        "                    rolling_mean = series.rolling(window, min_periods=1).mean()\n",
        "                    rolling_std = series.rolling(window, min_periods=1).std()\n",
        "                    df[f'zscore_{window}'] = (series - rolling_mean) / (rolling_std + 1e-8)\n",
        "\n",
        "            # Distance from moving averages\n",
        "            for window in [7, 14]:\n",
        "                if window < len(series):\n",
        "                    ma = series.rolling(window, min_periods=1).mean()\n",
        "                    df[f'distance_from_ma_{window}'] = (series - ma) / (ma + 1e-8)\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Statistical features creation failed: {str(e)}\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _clean_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Clean and validate features - FIXED for modern pandas\"\"\"\n",
        "        initial_shape = df.shape\n",
        "\n",
        "        # Replace infinite values\n",
        "        df = df.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "        # Drop columns with all NaN\n",
        "        df = df.dropna(axis=1, how='all')\n",
        "\n",
        "        # Drop rows with too many NaN values\n",
        "        threshold = len(df.columns) * 0.5\n",
        "        df = df.dropna(thresh=threshold)\n",
        "\n",
        "        # FIXED: Use modern pandas methods\n",
        "        df = df.ffill()  # Forward fill\n",
        "        df = df.bfill()  # Backward fill\n",
        "\n",
        "        # Final cleanup\n",
        "        df = df.fillna(0)\n",
        "\n",
        "        if self.config.debug_mode:\n",
        "            logger.debug(f\"Feature cleaning: {initial_shape} â†’ {df.shape}\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    def create_target_from_features(self, features_df: pd.DataFrame,\n",
        "                                   original_data: pd.DataFrame,\n",
        "                                   forecast_horizon: int = 1) -> Tuple[pd.DataFrame, pd.Series]:\n",
        "        \"\"\"Create target variable aligned with features\"\"\"\n",
        "\n",
        "        logger.info(f\"ðŸŽ¯ Creating target variable with forecast horizon: {forecast_horizon}\")\n",
        "\n",
        "        target_col = self.config.target_column\n",
        "\n",
        "        if target_col not in original_data.columns:\n",
        "            raise ValueError(f\"Target column '{target_col}' not found in original data\")\n",
        "\n",
        "        # Create target with forecast horizon\n",
        "        target_series = original_data[target_col].shift(-forecast_horizon)\n",
        "\n",
        "        # Align indices\n",
        "        common_index = features_df.index.intersection(target_series.index)\n",
        "\n",
        "        if len(common_index) == 0:\n",
        "            raise ValueError(\"No common index between features and target\")\n",
        "\n",
        "        aligned_features = features_df.loc[common_index]\n",
        "        aligned_target = target_series.loc[common_index]\n",
        "\n",
        "        # Remove rows where target is NaN\n",
        "        valid_mask = ~aligned_target.isna()\n",
        "\n",
        "        final_features = aligned_features[valid_mask]\n",
        "        final_target = aligned_target[valid_mask]\n",
        "\n",
        "        if len(final_features) == 0:\n",
        "            raise ValueError(\"No valid samples after alignment\")\n",
        "\n",
        "        logger.info(f\"âœ… Target alignment complete: Features {final_features.shape}, Target {final_target.shape}\")\n",
        "\n",
        "        return final_features, final_target\n",
        "\n",
        "print(\"DebugFeatureEngineer loaded\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFw76bJ2614S",
        "outputId": "64bc23c6-a5cf-47a2-c627-dd781542eae2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DebugFeatureEngineer loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# GRIDSEARCHCV OPTIMIZER\n",
        "# ============================================================================\n",
        "\n",
        "def get_verified_param_grids(config: DebugMLForecastingConfig) -> Dict[str, Dict]:\n",
        "    \"\"\"Get VERIFIED parameter grids that will actually trigger GridSearchCV\"\"\"\n",
        "\n",
        "    logger.info(f\"ðŸŽ›ï¸ Creating parameter grids (detailed_search: {config.detailed_search})\")\n",
        "\n",
        "    if config.detailed_search and HIGH_MEMORY:\n",
        "        # Comprehensive parameter grids for high-memory systems\n",
        "        param_grids = {\n",
        "            'RandomForest': {\n",
        "                'model__n_estimators': [100, 200, 500],\n",
        "                'model__max_depth': [10, 20, None],\n",
        "                'model__min_samples_split': [2, 5, 10],\n",
        "                'model__min_samples_leaf': [1, 2, 4]\n",
        "            },\n",
        "            'XGBoost': {\n",
        "                'model__n_estimators': [100, 200, 500],\n",
        "                'model__max_depth': [3, 4, 5, 6],\n",
        "                'model__learning_rate': [0.01, 0.1, 0.2],\n",
        "                'model__subsample': [0.8, 1.0],\n",
        "                'model__reg_alpha': [0, 0.1, 1]\n",
        "            },\n",
        "            'LightGBM': {\n",
        "                'model__n_estimators': [100, 200, 500],\n",
        "                'model__max_depth': [3, 5, 10, -1],\n",
        "                'model__learning_rate': [0.01, 0.1, 0.2],\n",
        "                'model__num_leaves': [20, 31, 50],\n",
        "                'model__reg_alpha': [0, 0.1, 1]\n",
        "            },\n",
        "            'Ridge': {\n",
        "                'model__alpha': [0.1, 1.0, 10.0, 100.0]\n",
        "            },\n",
        "            'SVR': {\n",
        "                'model__C': [0.1, 1.0, 10.0],\n",
        "                'model__kernel': ['linear', 'rbf'],\n",
        "                'model__epsilon': [0.01, 0.1]\n",
        "            },\n",
        "            'MLP': {\n",
        "                'model__hidden_layer_sizes': [(50,), (100,), (100, 50)],\n",
        "                'model__alpha': [0.001, 0.01, 0.1],\n",
        "                'model__learning_rate': ['constant', 'adaptive'],\n",
        "                'model__max_iter': [1000, 2000]\n",
        "            }\n",
        "        }\n",
        "    else:\n",
        "        # Quick search grids for faster execution\n",
        "        param_grids = {\n",
        "            'RandomForest': {\n",
        "                'model__n_estimators': [50, 100, 200],\n",
        "                'model__max_depth': [10, None],\n",
        "                'model__min_samples_split': [2, 5]\n",
        "            },\n",
        "            'XGBoost': {\n",
        "                'model__n_estimators': [50, 100],\n",
        "                'model__max_depth': [3, 6],\n",
        "                'model__learning_rate': [0.1, 0.2]\n",
        "            },\n",
        "            'Ridge': {\n",
        "                'model__alpha': [0.1, 1.0, 10.0]\n",
        "            },\n",
        "            'SVR': {\n",
        "                'model__C': [0.1, 1.0, 10.0],\n",
        "                'model__kernel': ['linear', 'rbf']\n",
        "            },\n",
        "            'MLP': {\n",
        "                'model__hidden_layer_sizes': [(50,), (100,)],\n",
        "                'model__alpha': [0.001, 0.01]\n",
        "            }\n",
        "        }\n",
        "\n",
        "    # Calculate and log total parameter combinations\n",
        "    total_combinations = 0\n",
        "    for model_type, grid in param_grids.items():\n",
        "        combinations = 1\n",
        "        for param_values in grid.values():\n",
        "            combinations *= len(param_values)\n",
        "        total_combinations += combinations\n",
        "\n",
        "        logger.info(f\"  {model_type}: {combinations} parameter combinations\")\n",
        "\n",
        "    expected_gridsearch_fits = total_combinations * config.cv_splits\n",
        "    expected_time_minutes = expected_gridsearch_fits * 0.5 / 60  # Rough estimate\n",
        "\n",
        "    logger.info(f\"ðŸ“Š Parameter grid summary:\")\n",
        "    logger.info(f\"  Total combinations: {total_combinations}\")\n",
        "    logger.info(f\"  With {config.cv_splits}-fold CV: {expected_gridsearch_fits} total fits\")\n",
        "    logger.info(f\"  Estimated GridSearch time: {expected_time_minutes:.1f} minutes\")\n",
        "\n",
        "    return param_grids\n",
        "\n",
        "class VerifiedGridSearchOptimizer:\n",
        "    \"\"\"GridSearchCV optimizer with VERIFIED execution and comprehensive debugging\"\"\"\n",
        "\n",
        "    def __init__(self, config: DebugMLForecastingConfig):\n",
        "        self.config = config\n",
        "        self.param_grids = get_verified_param_grids(config)\n",
        "        self.optimization_log = []\n",
        "\n",
        "    @monitor_performance(\"VP GridSearch Optimization\")\n",
        "    def optimize_top_models(self, v2_predictions: Dict[str, np.ndarray],\n",
        "                           X_train: pd.DataFrame, y_train: pd.Series,\n",
        "                           X_test: pd.DataFrame, y_test: pd.Series) -> Dict[str, np.ndarray]:\n",
        "        \"\"\"Optimize hyperparameters with VERIFIED GridSearchCV execution\"\"\"\n",
        "\n",
        "        logger.info(\"ðŸš€ Starting VERIFIED VP GridSearchCV optimization...\")\n",
        "\n",
        "        if len(v2_predictions) == 0:\n",
        "            logger.error(\"âŒ No V2 predictions provided for optimization\")\n",
        "            return {}\n",
        "\n",
        "        try:\n",
        "            # CRITICAL: Rank V2 models by performance with detailed logging\n",
        "            logger.info(\"  ðŸ“Š Ranking V2 models by performance...\")\n",
        "            v2_performance = {}\n",
        "\n",
        "            for model_name, predictions in v2_predictions.items():\n",
        "                try:\n",
        "                    if len(predictions) == 0:\n",
        "                        logger.warning(f\"    {model_name}: Empty predictions\")\n",
        "                        v2_performance[model_name] = float('inf')\n",
        "                        continue\n",
        "\n",
        "                    # Ensure proper alignment\n",
        "                    pred_len = min(len(predictions), len(y_test))\n",
        "                    if pred_len == 0:\n",
        "                        logger.warning(f\"    {model_name}: No overlapping predictions\")\n",
        "                        v2_performance[model_name] = float('inf')\n",
        "                        continue\n",
        "\n",
        "                    mae = mean_absolute_error(y_test.iloc[:pred_len], predictions[:pred_len])\n",
        "                    v2_performance[model_name] = mae\n",
        "\n",
        "                    logger.debug(f\"    {model_name}: MAE = {mae:.3f}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"    {model_name}: Performance calculation failed - {str(e)}\")\n",
        "                    v2_performance[model_name] = float('inf')\n",
        "\n",
        "            # Filter out infinite performance scores\n",
        "            valid_performance = {k: v for k, v in v2_performance.items() if not np.isinf(v)}\n",
        "\n",
        "            logger.info(f\"  Valid models for optimization: {len(valid_performance)}/{len(v2_predictions)}\")\n",
        "\n",
        "            if not valid_performance:\n",
        "                logger.error(\"âŒ CRITICAL: No valid V2 models for optimization!\")\n",
        "                return v2_predictions\n",
        "\n",
        "            # Select top models\n",
        "            top_models = sorted(valid_performance.items(), key=lambda x: x[1])[:self.config.top_models_for_optimization]\n",
        "\n",
        "            logger.info(f\"ðŸ“ˆ Top {len(top_models)} models selected for GridSearchCV:\")\n",
        "            for i, (model_name, mae) in enumerate(top_models, 1):\n",
        "                logger.info(f\"  {i}. {model_name}: MAE = {mae:.3f}\")\n",
        "\n",
        "            vp_predictions = v2_predictions.copy()\n",
        "            gridsearch_count = 0\n",
        "            successful_optimizations = 0\n",
        "\n",
        "            # CRITICAL: Actually run GridSearchCV on each top model\n",
        "            logger.info(f\"\\nðŸ”¥ STARTING GRIDSEARCHCV EXECUTION...\")\n",
        "            gridsearch_start_time = time.time()\n",
        "\n",
        "            for i, (model_name, baseline_mae) in enumerate(top_models, 1):\n",
        "                logger.info(f\"\\nðŸŽ¯ [{i}/{len(top_models)}] Optimizing {model_name}...\")\n",
        "                logger.info(f\"  Baseline MAE: {baseline_mae:.3f}\")\n",
        "\n",
        "                try:\n",
        "                    optimized_predictions = self._run_verified_gridsearch(\n",
        "                        model_name, X_train, y_train, X_test, baseline_mae\n",
        "                    )\n",
        "\n",
        "                    if optimized_predictions is not None:\n",
        "                        vp_predictions[f\"{model_name}_VP_optimized\"] = optimized_predictions\n",
        "                        successful_optimizations += 1\n",
        "                        gridsearch_count += 1\n",
        "                        logger.info(f\"  âœ… {model_name} optimization completed\")\n",
        "                    else:\n",
        "                        logger.warning(f\"  âš ï¸ {model_name} optimization failed\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"  âŒ {model_name} optimization error: {str(e)}\")\n",
        "\n",
        "            total_gridsearch_time = time.time() - gridsearch_start_time\n",
        "\n",
        "            # VERIFICATION: Check that GridSearchCV actually ran\n",
        "            logger.info(f\"\\nðŸ VP OPTIMIZATION SUMMARY:\")\n",
        "            logger.info(f\"  Models attempted: {len(top_models)}\")\n",
        "            logger.info(f\"  GridSearchCV runs completed: {gridsearch_count}\")\n",
        "            logger.info(f\"  Successful optimizations: {successful_optimizations}\")\n",
        "            logger.info(f\"  Total GridSearchCV time: {total_gridsearch_time:.1f} seconds\")\n",
        "\n",
        "            # CRITICAL VERIFICATION\n",
        "            if gridsearch_count == 0:\n",
        "                logger.error(\"ðŸš¨ CRITICAL ERROR: NO GRIDSEARCHCV RUNS COMPLETED!\")\n",
        "            elif total_gridsearch_time < 30:\n",
        "                logger.warning(f\"âš ï¸ WARNING: GridSearchCV completed very quickly ({total_gridsearch_time:.1f}s)\")\n",
        "            else:\n",
        "                logger.info(f\"âœ… VERIFIED: GridSearchCV ran successfully for {total_gridsearch_time:.1f} seconds\")\n",
        "\n",
        "            return vp_predictions\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"âŒ VP optimization pipeline failed: {str(e)}\")\n",
        "            return v2_predictions\n",
        "\n",
        "    def _run_verified_gridsearch(self, model_name: str, X_train: pd.DataFrame, y_train: pd.Series,\n",
        "                                X_test: pd.DataFrame, baseline_mae: float) -> Optional[np.ndarray]:\n",
        "        \"\"\"Run a single GridSearchCV with comprehensive verification\"\"\"\n",
        "\n",
        "        try:\n",
        "            # Determine model type and get parameter grid\n",
        "            model_type = self._get_model_type(model_name)\n",
        "\n",
        "            if model_type not in self.param_grids:\n",
        "                logger.warning(f\"    No parameter grid for {model_type}\")\n",
        "                return None\n",
        "\n",
        "            param_grid = self.param_grids[model_type]\n",
        "\n",
        "            # Calculate expected number of fits\n",
        "            total_combinations = 1\n",
        "            for param_values in param_grid.values():\n",
        "                total_combinations *= len(param_values)\n",
        "\n",
        "            expected_fits = total_combinations * self.config.cv_splits\n",
        "\n",
        "            logger.info(f\"    Parameter combinations: {total_combinations}\")\n",
        "            logger.info(f\"    Expected CV fits: {expected_fits}\")\n",
        "\n",
        "            # Create base model\n",
        "            base_model = self._create_base_model(model_type)\n",
        "            if base_model is None:\n",
        "                logger.warning(f\"    Could not create base model for {model_type}\")\n",
        "                return None\n",
        "\n",
        "            # Create pipeline\n",
        "            pipeline = Pipeline([\n",
        "                ('scaler', StandardScaler()),\n",
        "                ('model', base_model)\n",
        "            ])\n",
        "\n",
        "            # Setup TimeSeriesSplit with validation\n",
        "            n_splits = max(2, min(self.config.cv_splits, len(X_train) // 50))\n",
        "            tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "\n",
        "            logger.info(f\"    Using {n_splits}-fold TimeSeriesSplit\")\n",
        "\n",
        "            # Setup GridSearchCV with comprehensive logging\n",
        "            grid_search = GridSearchCV(\n",
        "                pipeline,\n",
        "                param_grid=param_grid,\n",
        "                cv=tscv,\n",
        "                scoring=self.config.scoring_metric,\n",
        "                n_jobs=1,  # Single job for debugging visibility\n",
        "                verbose=self.config.gridsearch_verbose,  # Show progress\n",
        "                error_score='raise'\n",
        "            )\n",
        "\n",
        "            # CRITICAL: Actually run GridSearchCV with timing\n",
        "            logger.info(f\"    ðŸš€ STARTING GridSearchCV for {model_name}...\")\n",
        "            gridsearch_start = time.time()\n",
        "\n",
        "            # Clean input data\n",
        "            X_train_clean = X_train.fillna(0).replace([np.inf, -np.inf], 0)\n",
        "            y_train_clean = y_train.fillna(y_train.mean())\n",
        "\n",
        "            grid_search.fit(X_train_clean, y_train_clean)\n",
        "\n",
        "            gridsearch_end = time.time()\n",
        "            gridsearch_duration = gridsearch_end - gridsearch_start\n",
        "\n",
        "            # VERIFICATION: Check that GridSearchCV actually ran\n",
        "            actual_fits = len(grid_search.cv_results_['params'])\n",
        "\n",
        "            logger.info(f\"    âœ… GridSearchCV completed in {gridsearch_duration:.1f} seconds\")\n",
        "            logger.info(f\"    Expected fits: {expected_fits}, Actual fits: {actual_fits}\")\n",
        "            logger.info(f\"    Best score: {-grid_search.best_score_:.4f}\")\n",
        "            logger.info(f\"    Best params: {grid_search.best_params_}\")\n",
        "\n",
        "            # Make predictions with optimized model\n",
        "            X_test_clean = X_test.fillna(0).replace([np.inf, -np.inf], 0)\n",
        "            predictions = grid_search.predict(X_test_clean)\n",
        "\n",
        "            # Log optimization improvement\n",
        "            optimized_mae = -grid_search.best_score_\n",
        "            improvement = ((baseline_mae - optimized_mae) / baseline_mae) * 100\n",
        "\n",
        "            logger.info(f\"    ðŸ“ˆ Optimization result:\")\n",
        "            logger.info(f\"      Baseline MAE: {baseline_mae:.4f}\")\n",
        "            logger.info(f\"      Optimized MAE: {optimized_mae:.4f}\")\n",
        "            logger.info(f\"      Improvement: {improvement:+.2f}%\")\n",
        "\n",
        "            # Store optimization log\n",
        "            self.optimization_log.append({\n",
        "                'model_name': model_name,\n",
        "                'model_type': model_type,\n",
        "                'baseline_mae': baseline_mae,\n",
        "                'optimized_mae': optimized_mae,\n",
        "                'improvement_pct': improvement,\n",
        "                'gridsearch_duration': gridsearch_duration,\n",
        "                'expected_fits': expected_fits,\n",
        "                'actual_fits': actual_fits,\n",
        "                'best_params': grid_search.best_params_\n",
        "            })\n",
        "\n",
        "            return predictions\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"    âŒ GridSearchCV failed for {model_name}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def _get_model_type(self, model_name: str) -> str:\n",
        "        \"\"\"Extract model type from model name with comprehensive matching\"\"\"\n",
        "\n",
        "        name_lower = model_name.lower()\n",
        "\n",
        "        if 'randomforest' in name_lower:\n",
        "            return 'RandomForest'\n",
        "        elif 'xgboost' in name_lower and XGB_AVAILABLE:\n",
        "            return 'XGBoost'\n",
        "        elif 'lightgbm' in name_lower and LGB_AVAILABLE:\n",
        "            return 'LightGBM'\n",
        "        elif 'ridge' in name_lower:\n",
        "            return 'Ridge'\n",
        "        elif 'svr' in name_lower:\n",
        "            return 'SVR'\n",
        "        elif 'mlp' in name_lower:\n",
        "            return 'MLP'\n",
        "        else:\n",
        "            return 'Unknown'\n",
        "\n",
        "    def _create_base_model(self, model_type: str):\n",
        "        \"\"\"Create base model for optimization with error handling\"\"\"\n",
        "\n",
        "        try:\n",
        "            if model_type == 'RandomForest':\n",
        "                return RandomForestRegressor(random_state=42, n_jobs=1)\n",
        "            elif model_type == 'XGBoost' and XGB_AVAILABLE:\n",
        "                return xgb.XGBRegressor(random_state=42, n_jobs=1)\n",
        "            elif model_type == 'LightGBM' and LGB_AVAILABLE:\n",
        "                return lgb.LGBMRegressor(random_state=42, verbose=-1, n_jobs=1)\n",
        "            elif model_type == 'Ridge':\n",
        "                return Ridge()\n",
        "            elif model_type == 'SVR':\n",
        "                return SVR()\n",
        "            elif model_type == 'MLP':\n",
        "                return MLPRegressor(random_state=42, max_iter=1000, early_stopping=True, validation_fraction=0.1)\n",
        "            else:\n",
        "                return None\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Could not create {model_type}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def get_optimization_summary(self) -> pd.DataFrame:\n",
        "        \"\"\"Get comprehensive optimization summary\"\"\"\n",
        "\n",
        "        if not self.optimization_log:\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        df = pd.DataFrame(self.optimization_log)\n",
        "        return df.sort_values('improvement_pct', ascending=False)\n",
        "\n",
        "print(\"VerifiedGridSearchOptimizer loaded\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qk0WQxhR6179",
        "outputId": "1fcdb8cf-ca63-4a40-daa3-28e5199bfc98"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VerifiedGridSearchOptimizer loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# MARKET REGIME ANALYZER\n",
        "# ============================================================================\n",
        "\n",
        "class DebugMarketRegimeAnalyzer:\n",
        "    \"\"\"Market regime analysis with comprehensive debugging\"\"\"\n",
        "\n",
        "    def __init__(self, config: DebugMLForecastingConfig):\n",
        "        self.config = config\n",
        "        self.vix_thresholds = config.vix_thresholds\n",
        "        self.regime_stats = None\n",
        "\n",
        "    @monitor_performance(\"Market Regime Analysis\")\n",
        "    def analyze_regimes(self, data: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"Comprehensive market regime analysis with debugging\"\"\"\n",
        "\n",
        "        logger.info(\"ðŸ“ˆ Analyzing market regimes...\")\n",
        "\n",
        "        # Get or simulate VIX data\n",
        "        if 'vix' in data.columns:\n",
        "            vix_series = data['vix'].copy()\n",
        "            logger.info(f\"  Using actual VIX data: {len(vix_series)} points\")\n",
        "        else:\n",
        "            vix_series = self._simulate_vix_data(len(data))\n",
        "            vix_series.index = data.index\n",
        "            logger.info(f\"  Using simulated VIX data: {len(vix_series)} points\")\n",
        "\n",
        "        # Clean VIX data\n",
        "        initial_nan_count = vix_series.isna().sum()\n",
        "        vix_series = vix_series.ffill().bfill().fillna(20.0)\n",
        "\n",
        "        if initial_nan_count > 0:\n",
        "            logger.info(f\"  Cleaned {initial_nan_count} NaN values in VIX data\")\n",
        "\n",
        "        # Classify regimes\n",
        "        regimes = vix_series.apply(self.classify_market_regime)\n",
        "\n",
        "        # Log VIX statistics\n",
        "        logger.info(f\"  VIX range: {vix_series.min():.1f} - {vix_series.max():.1f}\")\n",
        "        logger.info(f\"  VIX mean: {vix_series.mean():.1f}, std: {vix_series.std():.1f}\")\n",
        "\n",
        "        # Calculate regime statistics\n",
        "        try:\n",
        "            regime_distribution = regimes.value_counts(normalize=True)\n",
        "            regime_transitions = self._calculate_transition_matrix(regimes)\n",
        "\n",
        "            logger.info(f\"  Regime distribution:\")\n",
        "            for regime, pct in regime_distribution.items():\n",
        "                logger.info(f\"    {regime}: {pct*100:.1f}%\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Could not calculate regime statistics: {str(e)}\")\n",
        "            regime_distribution = pd.Series([1.0], index=['normal'])\n",
        "            regime_transitions = pd.DataFrame()\n",
        "\n",
        "        current_regime = regimes.iloc[-1] if len(regimes) > 0 else 'normal'\n",
        "\n",
        "        self.regime_stats = {\n",
        "            'vix_values': vix_series,\n",
        "            'regimes': regimes,\n",
        "            'current_regime': current_regime,\n",
        "            'regime_distribution': regime_distribution,\n",
        "            'transition_matrix': regime_transitions\n",
        "        }\n",
        "\n",
        "        logger.info(f\"âœ… Market regime analysis complete\")\n",
        "        logger.info(f\"  Current regime: {current_regime}\")\n",
        "\n",
        "        return self.regime_stats\n",
        "\n",
        "    def classify_market_regime(self, vix_value: float) -> str:\n",
        "        \"\"\"Classify market regime based on VIX with validation\"\"\"\n",
        "\n",
        "        if pd.isna(vix_value) or vix_value <= 0:\n",
        "            return 'normal'\n",
        "\n",
        "        if vix_value < self.vix_thresholds['low_volatility']:\n",
        "            return 'low_volatility'\n",
        "        elif vix_value < self.vix_thresholds['normal']:\n",
        "            return 'normal'\n",
        "        elif vix_value < self.vix_thresholds['high_volatility']:\n",
        "            return 'high_volatility'\n",
        "        else:\n",
        "            return 'extreme_volatility'\n",
        "\n",
        "    def select_models_for_regime(self, all_models: List[DebugMLForecaster], regime: str) -> List[DebugMLForecaster]:\n",
        "        \"\"\"Select appropriate ML models for current market regime with logging\"\"\"\n",
        "\n",
        "        logger.info(f\"ðŸŽ¯ Selecting models for {regime} regime...\")\n",
        "\n",
        "        regime_preferences = self.config.regime_specific_models.get(\n",
        "            regime,\n",
        "            self.config.regime_specific_models['normal']\n",
        "        )\n",
        "\n",
        "        selected = []\n",
        "        for model in all_models:\n",
        "            model_type = model.name.split('_')[0]\n",
        "\n",
        "            # Check if model type matches regime preference\n",
        "            for pref in regime_preferences:\n",
        "                if pref.lower() in model_type.lower():\n",
        "                    selected.append(model)\n",
        "                    break\n",
        "\n",
        "        # Ensure minimum number of models\n",
        "        min_models = 8 if HIGH_MEMORY else 6\n",
        "        if len(selected) < min_models:\n",
        "            logger.info(f\"  Adding additional models to reach minimum of {min_models}\")\n",
        "            for model in all_models:\n",
        "                if model not in selected:\n",
        "                    selected.append(model)\n",
        "                    if len(selected) >= min_models * 2:  # Cap at 2x minimum\n",
        "                        break\n",
        "\n",
        "        selected_names = [model.name for model in selected]\n",
        "        logger.info(f\"  Selected {len(selected)} models: {selected_names[:5]}{'...' if len(selected_names) > 5 else ''}\")\n",
        "\n",
        "        return selected\n",
        "\n",
        "    def _calculate_transition_matrix(self, regimes: pd.Series) -> pd.DataFrame:\n",
        "        \"\"\"Calculate regime transition probabilities with error handling\"\"\"\n",
        "\n",
        "        try:\n",
        "            unique_regimes = regimes.unique()\n",
        "            n_regimes = len(unique_regimes)\n",
        "\n",
        "            if n_regimes == 0:\n",
        "                return pd.DataFrame()\n",
        "\n",
        "            transition_matrix = pd.DataFrame(\n",
        "                np.zeros((n_regimes, n_regimes)),\n",
        "                index=unique_regimes,\n",
        "                columns=unique_regimes\n",
        "            )\n",
        "\n",
        "            for i in range(1, len(regimes)):\n",
        "                from_regime = regimes.iloc[i-1]\n",
        "                to_regime = regimes.iloc[i]\n",
        "                if pd.notna(from_regime) and pd.notna(to_regime):\n",
        "                    transition_matrix.loc[from_regime, to_regime] += 1\n",
        "\n",
        "            # Normalize rows to get probabilities\n",
        "            row_sums = transition_matrix.sum(axis=1)\n",
        "            transition_matrix = transition_matrix.div(row_sums, axis=0).fillna(0)\n",
        "\n",
        "            return transition_matrix\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Could not calculate transition matrix: {str(e)}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    def _simulate_vix_data(self, n_points: int) -> pd.Series:\n",
        "        \"\"\"Generate realistic VIX simulation\"\"\"\n",
        "\n",
        "        logger.debug(f\"Simulating VIX data for {n_points} points\")\n",
        "\n",
        "        base_vix = 18\n",
        "        vix_values = [base_vix]\n",
        "\n",
        "        for i in range(1, n_points):\n",
        "            # Mean reversion with random noise\n",
        "            change = 0.15 * (base_vix - vix_values[-1]) + np.random.normal(0, 1.8)\n",
        "\n",
        "            # Random volatility spikes\n",
        "            if np.random.random() < 0.08:  # 8% chance of volatility spike\n",
        "                change += np.random.uniform(8, 20)\n",
        "\n",
        "            new_vix = max(10, vix_values[-1] + change)\n",
        "            vix_values.append(new_vix)\n",
        "\n",
        "        return pd.Series(vix_values, name='VIX_simulated')\n",
        "\n",
        "print(\"DebugMarketRegimeAnalyzer loaded\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y04GqHo361_b",
        "outputId": "b713b3ab-7f57-40a4-8006-a0a8463ee9a3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DebugMarketRegimeAnalyzer loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# MAIN PIPELINE\n",
        "# ============================================================================\n",
        "\n",
        "class DebugMLForecastingPipeline:\n",
        "    \"\"\"Complete ML forecasting pipeline with comprehensive debugging and verification\"\"\"\n",
        "\n",
        "    def __init__(self, config: DebugMLForecastingConfig):\n",
        "        self.config = config\n",
        "        self.results = {}\n",
        "        self.regime_analyzer = DebugMarketRegimeAnalyzer(config)\n",
        "        self.feature_engineer = DebugFeatureEngineer(config)\n",
        "        self.models = {}\n",
        "        self.phase_timings = {}\n",
        "        self.execution_log = []\n",
        "\n",
        "    @monitor_performance(\"Complete ML Pipeline\")\n",
        "    def execute(self, data: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Execute complete ML forecasting pipeline with comprehensive debugging\"\"\"\n",
        "\n",
        "        logger.info(\"=\" * 80)\n",
        "        logger.info(\"ðŸš€ ENHANCED MACHINE LEARNING FORECASTING PIPELINE - DEBUG VERSION\")\n",
        "        logger.info(\"=\" * 80)\n",
        "        logger.info(f\"Input data shape: {data.shape}\")\n",
        "        logger.info(f\"Target column: {self.config.target_column}\")\n",
        "        logger.info(f\"Debug mode: {self.config.debug_mode}\")\n",
        "        logger.info(f\"System capabilities: GPU={GPU_AVAILABLE}, High Memory={HIGH_MEMORY}\")\n",
        "\n",
        "        pipeline_start_time = time.time()\n",
        "\n",
        "        try:\n",
        "            # 1. Input validation\n",
        "            logger.info(\"\\nðŸ“‹ Step 1: Input Validation\")\n",
        "            if not self._validate_input_data(data):\n",
        "                raise ValueError(\"Input data validation failed\")\n",
        "\n",
        "            # 2. Market regime analysis\n",
        "            logger.info(\"\\nðŸ“ˆ Step 2: Market Regime Analysis\")\n",
        "            regime_stats = self.regime_analyzer.analyze_regimes(data)\n",
        "            current_regime = regime_stats['current_regime']\n",
        "            self.execution_log.append(f\"Market regime identified: {current_regime}\")\n",
        "\n",
        "            # 3. Feature engineering\n",
        "            logger.info(\"\\nðŸ› ï¸ Step 3: Feature Engineering\")\n",
        "            features_df = self.feature_engineer.create_features(\n",
        "                data,\n",
        "                regime_data=regime_stats['regimes'] if self.config.use_regime_features else None\n",
        "            )\n",
        "\n",
        "            # 4. Create supervised learning dataset\n",
        "            logger.info(\"\\nðŸŽ¯ Step 4: Supervised Dataset Creation\")\n",
        "            X, y = self.feature_engineer.create_target_from_features(features_df, data)\n",
        "\n",
        "            # 5. Data validation and splitting\n",
        "            logger.info(\"\\nâœ‚ï¸ Step 5: Data Splitting\")\n",
        "            if len(X) < 50:\n",
        "                raise ValueError(f\"Insufficient data: {len(X)} samples (minimum 50 required)\")\n",
        "\n",
        "            train_end = int(len(X) * self.config.test_split_ratio)\n",
        "            train_end = max(train_end, 30)  # Ensure minimum training samples\n",
        "\n",
        "            X_train = X.iloc[:train_end].copy()\n",
        "            X_test = X.iloc[train_end:].copy()\n",
        "            y_train = y.iloc[:train_end].copy()\n",
        "            y_test = y.iloc[train_end:].copy()\n",
        "\n",
        "            logger.info(f\"  Train set: {X_train.shape} features, {y_train.shape} targets\")\n",
        "            logger.info(f\"  Test set: {X_test.shape} features, {y_test.shape} targets\")\n",
        "\n",
        "            # 6. Model creation\n",
        "            logger.info(\"\\nðŸ­ Step 6: Model Creation\")\n",
        "            all_models = DebugMLModelFactory.create_all_models(self.config)\n",
        "\n",
        "            if len(all_models) == 0:\n",
        "                raise ValueError(\"No models created successfully\")\n",
        "\n",
        "            # 7. Model selection based on regime\n",
        "            logger.info(\"\\nðŸŽ¯ Step 7: Model Selection\")\n",
        "            if self.config.use_market_regime_switching:\n",
        "                selected_models = self.regime_analyzer.select_models_for_regime(all_models, current_regime)\n",
        "            else:\n",
        "                max_models = 15 if HIGH_MEMORY else 10\n",
        "                selected_models = all_models[:max_models]\n",
        "                logger.info(f\"  Selected first {len(selected_models)} models (regime switching disabled)\")\n",
        "\n",
        "            # 8. PHASE 1: V1 Baseline Models\n",
        "            logger.info(\"\\n\" + \"=\" * 60)\n",
        "            logger.info(\"ðŸ”¥ PHASE 1: V1 BASELINE ML MODELS\")\n",
        "            logger.info(\"=\" * 60)\n",
        "\n",
        "            v1_predictions = self._train_v1_models_with_debug(selected_models, X_train, y_train, X_test)\n",
        "\n",
        "            if len(v1_predictions) == 0:\n",
        "                raise ValueError(\"No V1 models trained successfully\")\n",
        "\n",
        "            # 9. PHASE 2: V2 Advanced Feature Engineering\n",
        "            if self.config.enable_v2_feature_engineering and len(v1_predictions) > 0:\n",
        "                logger.info(\"\\n\" + \"=\" * 60)\n",
        "                logger.info(\"ðŸ”¥ PHASE 2: V2 ADVANCED FEATURE ENGINEERING\")\n",
        "                logger.info(\"=\" * 60)\n",
        "\n",
        "                X_train_v2, X_test_v2 = self._create_v2_features(X_train, y_train, X_test, v1_predictions)\n",
        "                v2_predictions = self._train_v2_models_with_debug(selected_models[:8], X_train_v2, y_train, X_test_v2)\n",
        "            else:\n",
        "                logger.info(\"\\nâ­ï¸ PHASE 2: V2 Feature Engineering SKIPPED\")\n",
        "                v2_predictions = v1_predictions\n",
        "                X_train_v2, X_test_v2 = X_train, X_test\n",
        "\n",
        "            # 10. PHASE 3: VP Hyperparameter Optimization (CRITICAL - GridSearchCV)\n",
        "            if self.config.enable_vp_optimization and len(v2_predictions) > 0:\n",
        "                logger.info(\"\\n\" + \"=\" * 60)\n",
        "                logger.info(\"ðŸ”¥ PHASE 3: VP HYPERPARAMETER OPTIMIZATION (GridSearchCV)\")\n",
        "                logger.info(\"=\" * 60)\n",
        "\n",
        "                vp_optimizer = VerifiedGridSearchOptimizer(self.config)\n",
        "                vp_predictions = vp_optimizer.optimize_top_models(v2_predictions, X_train_v2, y_train, X_test_v2, y_test)\n",
        "\n",
        "                # Log GridSearchCV optimization summary\n",
        "                optimization_summary = vp_optimizer.get_optimization_summary()\n",
        "                if not optimization_summary.empty:\n",
        "                    logger.info(f\"\\nðŸ“Š GRIDSEARCHCV OPTIMIZATION RESULTS:\")\n",
        "                    for _, row in optimization_summary.head(3).iterrows():\n",
        "                        logger.info(f\"  {row['model_name']}: {row['improvement_pct']:+.1f}% improvement\")\n",
        "                else:\n",
        "                    logger.warning(f\"  No optimization summary available - GridSearchCV may not have run\")\n",
        "\n",
        "                # Store VP timing\n",
        "                self.phase_timings['VP'] = time.time() - pipeline_start_time - sum(self.phase_timings.values())\n",
        "\n",
        "            else:\n",
        "                logger.info(f\"\\nâ­ï¸ PHASE 3: VP Optimization SKIPPED\")\n",
        "                vp_predictions = v2_predictions\n",
        "                self.phase_timings['VP'] = 0\n",
        "\n",
        "            # 11. Comprehensive evaluation\n",
        "            logger.info(f\"\\nðŸ“Š Step 11: Final Evaluation\")\n",
        "            eval_start = time.time()\n",
        "\n",
        "            results = self._evaluate_all_predictions_with_debug(\n",
        "                {'V1': v1_predictions, 'V2': v2_predictions, 'VP': vp_predictions},\n",
        "                y_test,\n",
        "                y_train\n",
        "            )\n",
        "\n",
        "            eval_time = time.time() - eval_start\n",
        "\n",
        "            # 12. Pipeline summary and verification\n",
        "            total_time = time.time() - pipeline_start_time\n",
        "\n",
        "            logger.info(f\"\\n\" + \"=\" * 80)\n",
        "            logger.info(f\"âœ… PIPELINE EXECUTION COMPLETE\")\n",
        "            logger.info(f\"=\" * 80)\n",
        "\n",
        "            # Detailed timing breakdown\n",
        "            logger.info(f\"EXECUTION TIMING:\")\n",
        "            logger.info(f\"  V1 Phase: {self.phase_timings.get('V1', 0):.1f}s\")\n",
        "            logger.info(f\"  V2 Phase: {self.phase_timings.get('V2', 0):.1f}s\")\n",
        "            logger.info(f\"  VP Phase: {self.phase_timings.get('VP', 0):.1f}s\")\n",
        "            logger.info(f\"  Evaluation: {eval_time:.1f}s\")\n",
        "            logger.info(f\"  Total: {total_time:.1f}s ({total_time/60:.1f} minutes)\")\n",
        "\n",
        "            # Results summary\n",
        "            if not results.empty:\n",
        "                logger.info(f\"\\nRESULTS SUMMARY:\")\n",
        "                logger.info(f\"  Total models evaluated: {len(results)}\")\n",
        "                logger.info(f\"  V1 models: {len(results[results['Phase'] == 'V1'])}\")\n",
        "                logger.info(f\"  V2 models: {len(results[results['Phase'] == 'V2'])}\")\n",
        "                logger.info(f\"  VP models: {len(results[results['Phase'] == 'VP'])}\")\n",
        "\n",
        "                # Champion model\n",
        "                best_model = results.iloc[0]\n",
        "                logger.info(f\"\\nCHAMPION MODEL:\")\n",
        "                logger.info(f\"  Name: {best_model['Phase']}_{best_model['Model']}\")\n",
        "                logger.info(f\"  MAE: {best_model['MAE']:.3f}\")\n",
        "                if best_model['R2'] > -1:\n",
        "                    logger.info(f\"  RÂ²: {best_model['R2']:.3f}\")\n",
        "                if best_model['MAPE'] < 999:\n",
        "                    logger.info(f\"  MAPE: {best_model['MAPE']:.1f}%\")\n",
        "\n",
        "                # Phase performance comparison\n",
        "                if len(results[results['Phase'] == 'VP']) > 0:\n",
        "                    v2_best_mae = results[results['Phase'] == 'V2']['MAE'].min()\n",
        "                    vp_best_mae = results[results['Phase'] == 'VP']['MAE'].min()\n",
        "                    improvement = ((v2_best_mae - vp_best_mae) / v2_best_mae) * 100\n",
        "                    logger.info(f\"\\nOPTIMIZATION IMPACT:\")\n",
        "                    logger.info(f\"  Best V2 MAE: {v2_best_mae:.3f}\")\n",
        "                    logger.info(f\"  Best VP MAE: {vp_best_mae:.3f}\")\n",
        "                    logger.info(f\"  GridSearch improvement: {improvement:+.1f}%\")\n",
        "\n",
        "                    if improvement > 0:\n",
        "                        logger.info(f\"  âœ… GridSearchCV successfully improved models\")\n",
        "                    else:\n",
        "                        logger.warning(f\"  âš ï¸ GridSearchCV did not improve best model\")\n",
        "                else:\n",
        "                    logger.warning(f\"  âš ï¸ No VP models found - GridSearchCV may have failed\")\n",
        "            else:\n",
        "                logger.error(f\"  âŒ No valid results generated\")\n",
        "\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            total_time = time.time() - pipeline_start_time\n",
        "            logger.error(f\"âŒ Pipeline execution failed after {total_time:.1f} seconds: {str(e)}\")\n",
        "            logger.error(f\"Full traceback: {traceback.format_exc()}\")\n",
        "\n",
        "            # Return minimal error results\n",
        "            return pd.DataFrame({\n",
        "                'Phase': ['Error'],\n",
        "                'Model': ['Pipeline_Failed'],\n",
        "                'MAE': [float('inf')],\n",
        "                'RMSE': [float('inf')],\n",
        "                'R2': [-1.0],\n",
        "                'Error': [str(e)]\n",
        "            })\n",
        "\n",
        "    def _validate_input_data(self, data: pd.DataFrame) -> bool:\n",
        "        \"\"\"Comprehensive input data validation\"\"\"\n",
        "\n",
        "        try:\n",
        "            if data.empty:\n",
        "                logger.error(\"  âŒ Input data is empty\")\n",
        "                return False\n",
        "\n",
        "            if self.config.target_column not in data.columns:\n",
        "                logger.error(f\"  âŒ Target column '{self.config.target_column}' not found\")\n",
        "                return False\n",
        "\n",
        "            target_series = data[self.config.target_column]\n",
        "            nan_pct = target_series.isna().sum() / len(target_series) * 100\n",
        "\n",
        "            logger.info(f\"  Data shape: {data.shape}\")\n",
        "            logger.info(f\"  Target column: {self.config.target_column}\")\n",
        "            logger.info(f\"  NaN percentage in target: {nan_pct:.1f}%\")\n",
        "\n",
        "            if nan_pct > 50:\n",
        "                logger.error(f\"  âŒ Too many NaN values in target: {nan_pct:.1f}%\")\n",
        "                return False\n",
        "\n",
        "            if len(data) < 100:\n",
        "                logger.warning(f\"  âš ï¸ Small dataset: {len(data)} samples (recommended: 200+)\")\n",
        "\n",
        "            logger.info(\"  âœ… Input data validation passed\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"  âŒ Data validation failed: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def _train_v1_models_with_debug(self, models: List[DebugMLForecaster],\n",
        "                                   X_train: pd.DataFrame, y_train: pd.Series,\n",
        "                                   X_test: pd.DataFrame) -> Dict[str, np.ndarray]:\n",
        "        \"\"\"Train V1 models with comprehensive debugging\"\"\"\n",
        "\n",
        "        v1_predictions = {}\n",
        "        total_models = len(models)\n",
        "        phase_start = time.time()\n",
        "\n",
        "        logger.info(f\"ðŸš€ Training {total_models} V1 models...\")\n",
        "\n",
        "        successful = 0\n",
        "        failed = 0\n",
        "\n",
        "        for i, model in enumerate(models, 1):\n",
        "            model_start = time.time()\n",
        "\n",
        "            # Progress indicator\n",
        "            progress = f\"[{i}/{total_models}]\"\n",
        "            logger.info(f\"{progress} Training {model.name}...\")\n",
        "\n",
        "            try:\n",
        "                model.fit(X_train, y_train)\n",
        "\n",
        "                if model.is_fitted:\n",
        "                    predictions = model.predict(X_test)\n",
        "\n",
        "                    # Validate predictions\n",
        "                    if len(predictions) > 0 and not np.all(np.isnan(predictions)):\n",
        "                        v1_predictions[model.name] = predictions\n",
        "                        successful += 1\n",
        "\n",
        "                        model_time = time.time() - model_start\n",
        "\n",
        "                        # Log success with timing\n",
        "                        logger.info(f\"  âœ… {model.name} SUCCESS ({model_time:.2f}s)\")\n",
        "                    else:\n",
        "                        failed += 1\n",
        "                        logger.warning(f\"  âŒ {model.name} FAILED - Invalid predictions\")\n",
        "                else:\n",
        "                    failed += 1\n",
        "                    error_msg = model.fit_error or \"Unknown error\"\n",
        "                    logger.warning(f\"  âŒ {model.name} FAILED - {error_msg[:50]}...\")\n",
        "\n",
        "            except Exception as e:\n",
        "                failed += 1\n",
        "                model_time = time.time() - model_start\n",
        "                logger.error(f\"  âŒ {model.name} FAILED - {str(e)[:50]}... ({model_time:.2f}s)\")\n",
        "\n",
        "        phase_time = time.time() - phase_start\n",
        "        success_rate = (successful / total_models) * 100\n",
        "\n",
        "        logger.info(f\"\\nðŸ“Š V1 PHASE COMPLETE:\")\n",
        "        logger.info(f\"  Duration: {phase_time:.1f} seconds\")\n",
        "        logger.info(f\"  Success rate: {successful}/{total_models} ({success_rate:.1f}%)\")\n",
        "        logger.info(f\"  Valid predictions: {len(v1_predictions)}\")\n",
        "\n",
        "        self.phase_timings['V1'] = phase_time\n",
        "\n",
        "        return v1_predictions\n",
        "\n",
        "    def _create_v2_features(self, X_train: pd.DataFrame, y_train: pd.Series,\n",
        "                           X_test: pd.DataFrame, v1_predictions: Dict[str, np.ndarray]) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "        \"\"\"Create enhanced V2 features\"\"\"\n",
        "\n",
        "        logger.info(\"ðŸ”§ Creating V2 enhanced features...\")\n",
        "\n",
        "        try:\n",
        "            X_train_v2 = X_train.copy()\n",
        "            X_test_v2 = X_test.copy()\n",
        "\n",
        "            # Add simple ensemble features from V1 predictions\n",
        "            if len(v1_predictions) > 0:\n",
        "                logger.info(\"  Adding V1 ensemble features...\")\n",
        "\n",
        "                valid_preds = []\n",
        "                for name, preds in v1_predictions.items():\n",
        "                    if len(preds) >= len(X_test):\n",
        "                        valid_preds.append(preds[:len(X_test)])\n",
        "\n",
        "                if valid_preds:\n",
        "                    pred_array = np.column_stack(valid_preds)\n",
        "\n",
        "                    X_test_v2['v1_ensemble_mean'] = np.mean(pred_array, axis=1)\n",
        "                    X_test_v2['v1_ensemble_std'] = np.std(pred_array, axis=1)\n",
        "\n",
        "                    # For training set - create proxy features\n",
        "                    overall_mean = np.mean([np.mean(pred) for pred in valid_preds])\n",
        "                    overall_std = np.std([np.mean(pred) for pred in valid_preds])\n",
        "\n",
        "                    X_train_v2['v1_ensemble_mean'] = overall_mean\n",
        "                    X_train_v2['v1_ensemble_std'] = overall_std\n",
        "\n",
        "                    logger.info(f\"    Added 2 ensemble features\")\n",
        "\n",
        "            logger.info(f\"  V2 features created: {X_train_v2.shape[1]} features\")\n",
        "\n",
        "            return X_train_v2, X_test_v2\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"  V2 feature creation failed: {str(e)}\")\n",
        "            return X_train.copy(), X_test.copy()\n",
        "\n",
        "    def _train_v2_models_with_debug(self, models: List[DebugMLForecaster],\n",
        "                                   X_train: pd.DataFrame, y_train: pd.Series,\n",
        "                                   X_test: pd.DataFrame) -> Dict[str, np.ndarray]:\n",
        "        \"\"\"Train V2 models with enhanced features\"\"\"\n",
        "\n",
        "        v2_predictions = {}\n",
        "        phase_start = time.time()\n",
        "\n",
        "        logger.info(f\"ðŸš€ Training {len(models)} V2 models with enhanced features...\")\n",
        "\n",
        "        successful = 0\n",
        "        failed = 0\n",
        "\n",
        "        for i, model in enumerate(models, 1):\n",
        "            progress = f\"[{i}/{len(models)}]\"\n",
        "            logger.info(f\"{progress} Training V2_{model.name}...\")\n",
        "\n",
        "            try:\n",
        "                # Create new model instance for V2\n",
        "                model_v2 = DebugMLForecaster(f\"{model.name}_V2\", clone(model.model), self.config.debug_mode)\n",
        "                model_v2.fit(X_train, y_train)\n",
        "\n",
        "                if model_v2.is_fitted:\n",
        "                    predictions = model_v2.predict(X_test)\n",
        "\n",
        "                    if len(predictions) > 0 and not np.all(np.isnan(predictions)):\n",
        "                        v2_predictions[model_v2.name] = predictions\n",
        "                        successful += 1\n",
        "                        logger.info(f\"  âœ… V2_{model.name} SUCCESS\")\n",
        "                    else:\n",
        "                        failed += 1\n",
        "                        logger.warning(f\"  âŒ V2_{model.name} FAILED - Invalid predictions\")\n",
        "                else:\n",
        "                    failed += 1\n",
        "                    logger.warning(f\"  âŒ V2_{model.name} FAILED - Not fitted\")\n",
        "\n",
        "            except Exception as e:\n",
        "                failed += 1\n",
        "                logger.error(f\"  âŒ V2_{model.name} FAILED - {str(e)[:50]}...\")\n",
        "\n",
        "        phase_time = time.time() - phase_start\n",
        "\n",
        "        logger.info(f\"\\nðŸ“Š V2 PHASE COMPLETE:\")\n",
        "        logger.info(f\"  Duration: {phase_time:.1f} seconds\")\n",
        "        logger.info(f\"  Success rate: {successful}/{len(models)} ({successful/len(models)*100:.1f}%)\")\n",
        "        logger.info(f\"  Valid predictions: {len(v2_predictions)}\")\n",
        "\n",
        "        self.phase_timings['V2'] = phase_time\n",
        "\n",
        "        return v2_predictions\n",
        "\n",
        "    def _evaluate_all_predictions_with_debug(self, all_predictions: Dict[str, Dict[str, np.ndarray]],\n",
        "                                            y_test: pd.Series, y_train: pd.Series) -> pd.DataFrame:\n",
        "        \"\"\"Evaluate all predictions with comprehensive debugging\"\"\"\n",
        "\n",
        "        logger.info(\"ðŸ“Š Evaluating all model predictions...\")\n",
        "\n",
        "        results = []\n",
        "        evaluation_errors = []\n",
        "\n",
        "        for phase_name, phase_predictions in all_predictions.items():\n",
        "            logger.info(f\"  Evaluating {phase_name} models: {len(phase_predictions)} models\")\n",
        "\n",
        "            for model_name, predictions in phase_predictions.items():\n",
        "                try:\n",
        "                    metrics = self._calculate_comprehensive_metrics(\n",
        "                        y_test.values,\n",
        "                        predictions,\n",
        "                        y_train.values,\n",
        "                        model_name\n",
        "                    )\n",
        "\n",
        "                    result_row = {\n",
        "                        'Phase': phase_name,\n",
        "                        'Model': model_name,\n",
        "                        **metrics\n",
        "                    }\n",
        "                    results.append(result_row)\n",
        "\n",
        "                except Exception as e:\n",
        "                    evaluation_errors.append(f\"{model_name}: {str(e)}\")\n",
        "                    logger.warning(f\"    âŒ Evaluation failed for {model_name}: {str(e)[:50]}...\")\n",
        "\n",
        "        if not results:\n",
        "            logger.error(\"âŒ No valid results to evaluate!\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        results_df = pd.DataFrame(results)\n",
        "\n",
        "        # Handle infinite values in sorting\n",
        "        results_df['MAE_sort'] = results_df['MAE'].replace([np.inf, -np.inf], 999999)\n",
        "        results_df = results_df.sort_values('MAE_sort', ascending=True).drop('MAE_sort', axis=1)\n",
        "\n",
        "        logger.info(f\"âœ… Evaluation complete:\")\n",
        "        logger.info(f\"  Total models evaluated: {len(results_df)}\")\n",
        "        logger.info(f\"  Evaluation errors: {len(evaluation_errors)}\")\n",
        "\n",
        "        return results_df\n",
        "\n",
        "    def _calculate_comprehensive_metrics(self, y_true: np.ndarray, y_pred: np.ndarray,\n",
        "                                        y_train: np.ndarray = None, model_name: str = None) -> Dict[str, float]:\n",
        "        \"\"\"Calculate comprehensive evaluation metrics with error handling\"\"\"\n",
        "\n",
        "        try:\n",
        "            # Ensure arrays are proper format\n",
        "            y_true = np.asarray(y_true).flatten()\n",
        "            y_pred = np.asarray(y_pred).flatten()\n",
        "\n",
        "            # Handle length mismatch\n",
        "            min_length = min(len(y_true), len(y_pred))\n",
        "            if min_length == 0:\n",
        "                raise ValueError(\"Empty prediction arrays\")\n",
        "\n",
        "            y_true = y_true[:min_length]\n",
        "            y_pred = y_pred[:min_length]\n",
        "\n",
        "            # Remove invalid values\n",
        "            valid_mask = ~(np.isnan(y_true) | np.isnan(y_pred) | np.isinf(y_true) | np.isinf(y_pred))\n",
        "\n",
        "            if not np.any(valid_mask):\n",
        "                raise ValueError(\"No valid prediction pairs\")\n",
        "\n",
        "            y_true_clean = y_true[valid_mask]\n",
        "            y_pred_clean = y_pred[valid_mask]\n",
        "\n",
        "            # Calculate metrics\n",
        "            metrics = {}\n",
        "\n",
        "            metrics['MAE'] = float(mean_absolute_error(y_true_clean, y_pred_clean))\n",
        "            metrics['RMSE'] = float(np.sqrt(mean_squared_error(y_true_clean, y_pred_clean)))\n",
        "\n",
        "            # RÂ² with error handling\n",
        "            try:\n",
        "                r2 = r2_score(y_true_clean, y_pred_clean)\n",
        "                metrics['R2'] = float(r2) if not np.isnan(r2) else -1.0\n",
        "            except:\n",
        "                metrics['R2'] = -1.0\n",
        "\n",
        "            # MAPE with zero handling\n",
        "            try:\n",
        "                mask_nonzero = y_true_clean != 0\n",
        "                if mask_nonzero.sum() > 0:\n",
        "                    mape = np.mean(np.abs((y_true_clean[mask_nonzero] - y_pred_clean[mask_nonzero]) / y_true_clean[mask_nonzero])) * 100\n",
        "                    metrics['MAPE'] = float(mape) if not np.isnan(mape) else 999.0\n",
        "                else:\n",
        "                    metrics['MAPE'] = 999.0\n",
        "            except:\n",
        "                metrics['MAPE'] = 999.0\n",
        "\n",
        "            return metrics\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Metrics calculation failed for {model_name}: {str(e)}\")\n",
        "            return {\n",
        "                'MAE': float('inf'),\n",
        "                'RMSE': float('inf'),\n",
        "                'R2': -1.0,\n",
        "                'MAPE': 999.0\n",
        "            }\n",
        "\n",
        "print(\"DebugMLForecastingPipeline loaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grJBL4kL62CQ",
        "outputId": "25a23187-b1b4-4836-c272-048520516185"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DebugMLForecastingPipeline loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# EXECUTION FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def run_debug_pipeline(data_size: int = None, quick_test: bool = False) -> pd.DataFrame:\n",
        "    \"\"\"Run the complete debug pipeline with comprehensive logging\"\"\"\n",
        "\n",
        "    logger.info(\"ðŸŽ¯ STARTING DEBUG ML FORECASTING PIPELINE\")\n",
        "    logger.info(\"=\" * 80)\n",
        "\n",
        "    # Determine optimal data size based on system capabilities\n",
        "    if data_size is None:\n",
        "        if HIGH_MEMORY and not quick_test:\n",
        "            data_size = 400\n",
        "        else:\n",
        "            data_size = 200\n",
        "\n",
        "    logger.info(f\"Configuration: {data_size} data points, quick_test={quick_test}\")\n",
        "    logger.info(f\"System: GPU={GPU_AVAILABLE}, High Memory={HIGH_MEMORY}\")\n",
        "\n",
        "    try:\n",
        "        # Generate data\n",
        "        data = generate_debug_synthetic_data(n_points=data_size)\n",
        "\n",
        "        # Configure pipeline based on system and test mode\n",
        "        config = DebugMLForecastingConfig(\n",
        "            # Core settings\n",
        "            target_column=\"calls\",\n",
        "            seasonal_period=7,\n",
        "            test_split_ratio=0.75,\n",
        "\n",
        "            # Feature engineering - scale with system\n",
        "            max_lags=15 if quick_test else (25 if HIGH_MEMORY else 20),\n",
        "            rolling_windows=[3, 7, 14] if quick_test else ([3, 7, 14, 21, 30] if HIGH_MEMORY else [3, 7, 14, 21]),\n",
        "            create_technical_indicators=True,\n",
        "            create_calendar_features=True,\n",
        "\n",
        "            # Model settings\n",
        "            use_tree_models=True,\n",
        "            use_linear_models=True,\n",
        "            use_neural_models=not quick_test,  # Skip neural for quick tests\n",
        "            use_ensemble_models=not quick_test,\n",
        "            use_other_models=True,\n",
        "\n",
        "            # GridSearchCV settings - CRITICAL for optimization verification\n",
        "            cv_splits=3 if quick_test else 5,\n",
        "            gridsearch_verbose=2,  # Show GridSearch progress\n",
        "            parallel_jobs=1,  # Single job for debug visibility\n",
        "\n",
        "            # Optimization settings\n",
        "            quick_search=quick_test,\n",
        "            detailed_search=not quick_test,\n",
        "            top_models_for_optimization=3 if quick_test else (8 if HIGH_MEMORY else 5),\n",
        "\n",
        "            # Pipeline phases\n",
        "            enable_v2_feature_engineering=True,\n",
        "            enable_vp_optimization=True,  # CRITICAL - ensure GridSearchCV runs\n",
        "\n",
        "            # Debug settings\n",
        "            debug_mode=True,\n",
        "            show_progress=True,\n",
        "            time_each_phase=True,\n",
        "            validate_gridsearch=True\n",
        "        )\n",
        "\n",
        "        # Create and execute pipeline\n",
        "        pipeline = DebugMLForecastingPipeline(config)\n",
        "        results = pipeline.execute(data)\n",
        "\n",
        "        # Enhanced results display\n",
        "        if not results.empty:\n",
        "            logger.info(\"ðŸ† PIPELINE RESULTS SUMMARY:\")\n",
        "            logger.info(\"=\" * 60)\n",
        "\n",
        "            # Show top 10 models\n",
        "            top_10 = results.head(10)\n",
        "            logger.info(\"Top 10 Models:\")\n",
        "            for i, (_, row) in enumerate(top_10.iterrows(), 1):\n",
        "                mae_str = f\"{row['MAE']:.3f}\" if row['MAE'] != float('inf') else \"inf\"\n",
        "                r2_str = f\"{row['R2']:.3f}\" if row['R2'] != -1.0 else \"N/A\"\n",
        "                logger.info(f\"  {i:2d}. {row['Phase']:<2} {row['Model']:<20} MAE:{mae_str} RÂ²:{r2_str}\")\n",
        "\n",
        "            # GridSearchCV verification\n",
        "            vp_models = results[results['Phase'] == 'VP']\n",
        "            if len(vp_models) > 0:\n",
        "                logger.info(f\"\\nâœ… GridSearchCV VERIFICATION:\")\n",
        "                logger.info(f\"  VP (optimized) models found: {len(vp_models)}\")\n",
        "                logger.info(f\"  Best VP model MAE: {vp_models['MAE'].min():.3f}\")\n",
        "            else:\n",
        "                logger.warning(f\"\\nâš ï¸ GridSearchCV VERIFICATION:\")\n",
        "                logger.warning(f\"  NO VP (optimized) models found!\")\n",
        "                logger.warning(f\"  This indicates GridSearchCV may not have run properly\")\n",
        "        else:\n",
        "            logger.error(\"âŒ No results generated\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"âŒ Debug pipeline failed: {str(e)}\")\n",
        "        logger.error(f\"Full traceback: {traceback.format_exc()}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "print(\"ðŸŽ¯ COMPLETE ML FORECASTING SYSTEM LOADED\")\n",
        "print(\"=\" * 80)\n",
        "print(\"Ready to execute!\")\n",
        "print(\"\")\n",
        "print(\"To run the pipeline:\")\n",
        "print(\"  results = run_debug_pipeline(data_size=200, quick_test=True)  # Quick test\")\n",
        "print(\"  results = run_debug_pipeline()  # Full execution\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-aVxaW562E1",
        "outputId": "d22cd16a-2324-4082-be7a-c4bcba18f0c9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŽ¯ COMPLETE ML FORECASTING SYSTEM LOADED\n",
            "================================================================================\n",
            "Ready to execute!\n",
            "\n",
            "To run the pipeline:\n",
            "  results = run_debug_pipeline(data_size=200, quick_test=True)  # Quick test\n",
            "  results = run_debug_pipeline()  # Full execution\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WHx7SP3U-8Xn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# COMPLETE ML PIPELINE EXECUTION\n",
        "# ============================================================================\n",
        "\n",
        "# CSV FILE CONFIGURATION - MODIFY THESE SETTINGS FOR YOUR DATA\n",
        "CSV_FILE_PATH = \"enhanced_eda_data.csv\"  # Path to your CSV file\n",
        "TARGET_COLUMN = \"calls\"                  # Name of your target column to forecast\n",
        "DATE_COLUMN = \"date\"                     # Name of your date column (set to None if no date column)\n",
        "QUICK_TEST = True                        # Set to False for full execution with all models\n",
        "\n",
        "# ============================================================================\n",
        "# ROBUST CSV DATA LOADING\n",
        "# ============================================================================\n",
        "\n",
        "def load_csv_data_robust(csv_path: str, target_column: str = 'calls', date_column: str = None) -> pd.DataFrame:\n",
        "    \"\"\"Load and prepare CSV data - completely robust version\"\"\"\n",
        "\n",
        "    logger.info(f\"Loading CSV data from: {csv_path}\")\n",
        "\n",
        "    try:\n",
        "        # Load CSV\n",
        "        data = pd.read_csv(csv_path)\n",
        "        logger.info(f\"  Raw data shape: {data.shape}\")\n",
        "        logger.info(f\"  Columns: {list(data.columns)}\")\n",
        "\n",
        "        # Handle date column if specified\n",
        "        if date_column and date_column in data.columns:\n",
        "            logger.info(f\"  Converting {date_column} to datetime index\")\n",
        "            data[date_column] = pd.to_datetime(data[date_column])\n",
        "            data = data.set_index(date_column).sort_index()\n",
        "\n",
        "        # Validate target column\n",
        "        if target_column not in data.columns:\n",
        "            logger.error(f\"  Target column '{target_column}' not found!\")\n",
        "            logger.info(f\"  Available columns: {list(data.columns)}\")\n",
        "            raise ValueError(f\"Target column '{target_column}' not found\")\n",
        "\n",
        "        logger.info(f\"  Processing data for ML pipeline...\")\n",
        "\n",
        "        # Remove rows where target is null\n",
        "        initial_length = len(data)\n",
        "        data = data.dropna(subset=[target_column])\n",
        "        removed_rows = initial_length - len(data)\n",
        "\n",
        "        if removed_rows > 0:\n",
        "            logger.info(f\"    Removed {removed_rows} rows with null target values\")\n",
        "\n",
        "        # Convert target to numeric\n",
        "        data[target_column] = pd.to_numeric(data[target_column], errors='coerce')\n",
        "\n",
        "        # Process ALL other columns - simple numeric conversion only\n",
        "        logger.info(f\"    Converting all columns to numeric...\")\n",
        "\n",
        "        columns_to_drop = []\n",
        "        conversion_success = 0\n",
        "\n",
        "        for col in data.columns:\n",
        "            if col == target_column:\n",
        "                continue\n",
        "            if data.index.name == col:\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                # Simple numeric conversion - no string operations\n",
        "                data[col] = pd.to_numeric(data[col], errors='coerce')\n",
        "\n",
        "                # Fill NaN values\n",
        "                if data[col].isna().any():\n",
        "                    median_val = data[col].median()\n",
        "                    if pd.isna(median_val):\n",
        "                        median_val = 0.0\n",
        "                    data[col] = data[col].fillna(median_val)\n",
        "\n",
        "                # Convert to float64\n",
        "                data[col] = data[col].astype(np.float64)\n",
        "\n",
        "                conversion_success += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"    Could not convert {col}, will drop: {str(e)}\")\n",
        "                columns_to_drop.append(col)\n",
        "\n",
        "        # Drop problematic columns\n",
        "        if columns_to_drop:\n",
        "            data = data.drop(columns=columns_to_drop)\n",
        "            logger.info(f\"    Dropped {len(columns_to_drop)} non-convertible columns\")\n",
        "\n",
        "        logger.info(f\"    Successfully converted {conversion_success} columns to numeric\")\n",
        "\n",
        "        # Final cleanup\n",
        "        data = data.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "        for col in data.columns:\n",
        "            if data[col].isna().any():\n",
        "                median_val = data[col].median()\n",
        "                if pd.isna(median_val):\n",
        "                    median_val = 0.0\n",
        "                data[col] = data[col].fillna(median_val)\n",
        "\n",
        "        # Verify all columns are numeric\n",
        "        all_numeric = True\n",
        "        for col in data.columns:\n",
        "            if not np.issubdtype(data[col].dtype, np.number):\n",
        "                all_numeric = False\n",
        "                logger.warning(f\"    Column {col} is still not numeric: {data[col].dtype}\")\n",
        "\n",
        "        if not all_numeric:\n",
        "            # Force numeric conversion as last resort\n",
        "            numeric_data = data.select_dtypes(include=[np.number])\n",
        "            logger.warning(f\"    Keeping only numeric columns: {numeric_data.shape}\")\n",
        "            data = numeric_data\n",
        "\n",
        "        # Validate target survived\n",
        "        if target_column not in data.columns:\n",
        "            raise ValueError(f\"Target column '{target_column}' was lost during processing\")\n",
        "\n",
        "        logger.info(f\"  Data loaded successfully: {data.shape}\")\n",
        "        logger.info(f\"  Target range: {data[target_column].min():.2f} - {data[target_column].max():.2f}\")\n",
        "        logger.info(f\"  All columns numeric: {all(np.issubdtype(data[col].dtype, np.number) for col in data.columns)}\")\n",
        "\n",
        "        # Set market data detection for your columns\n",
        "        detected_market_data = {}\n",
        "        column_mapping = {\n",
        "            '^VIX_close': 'vix',\n",
        "            'SPY_close': 'sp500',\n",
        "            'SPY_volume': 'sp500_volume',\n",
        "            'QQQ_close': 'nasdaq',\n",
        "            'DX-Y.NYB_close': 'dollar',\n",
        "            'GC=F_close': 'gold',\n",
        "            'BTC-USD_close': 'bitcoin',\n",
        "            'ETH-USD_close': 'ethereum'\n",
        "        }\n",
        "\n",
        "        for csv_col, market_type in column_mapping.items():\n",
        "            if csv_col in data.columns:\n",
        "                detected_market_data[market_type] = csv_col\n",
        "\n",
        "        if detected_market_data:\n",
        "            logger.info(f\"  Market data detected: {list(detected_market_data.keys())}\")\n",
        "\n",
        "        data._detected_market_data = detected_market_data\n",
        "\n",
        "        return data\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"  Failed to load CSV: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "# ============================================================================\n",
        "# ENHANCED MODEL FITTING WITH ROBUST DATA HANDLING\n",
        "# ============================================================================\n",
        "\n",
        "class RobustMLForecaster(DebugMLForecaster):\n",
        "    \"\"\"Enhanced forecaster with bulletproof data type handling\"\"\"\n",
        "\n",
        "    def fit(self, X: pd.DataFrame, y: pd.Series) -> 'RobustMLForecaster':\n",
        "        \"\"\"Fit model with bulletproof data type conversion\"\"\"\n",
        "\n",
        "        fit_start = time.time()\n",
        "\n",
        "        try:\n",
        "            if self.debug_mode:\n",
        "                logger.debug(f\"Fitting {self.name} on data shape: {X.shape}\")\n",
        "\n",
        "            # Validate input\n",
        "            if X.empty or y.empty:\n",
        "                raise ValueError(f\"Empty input data for {self.name}\")\n",
        "\n",
        "            if len(X) != len(y):\n",
        "                raise ValueError(f\"Feature/target length mismatch for {self.name}: {len(X)} vs {len(y)}\")\n",
        "\n",
        "            # BULLETPROOF data conversion\n",
        "            logger.debug(f\"{self.name}: Converting data to safe numeric format...\")\n",
        "\n",
        "            # Convert features\n",
        "            if isinstance(X, pd.DataFrame):\n",
        "                X_clean = X.copy()\n",
        "                for col in X_clean.columns:\n",
        "                    if not np.issubdtype(X_clean[col].dtype, np.number):\n",
        "                        X_clean[col] = pd.to_numeric(X_clean[col], errors='coerce')\n",
        "                    X_clean[col] = X_clean[col].fillna(0.0)\n",
        "                X_array = X_clean.values.astype(np.float64)\n",
        "            else:\n",
        "                X_array = np.asarray(X, dtype=np.float64)\n",
        "\n",
        "            # Convert target\n",
        "            if isinstance(y, pd.Series):\n",
        "                y_clean = pd.to_numeric(y, errors='coerce')\n",
        "                y_clean = y_clean.fillna(y_clean.median())\n",
        "                if y_clean.isna().any():\n",
        "                    y_clean = y_clean.fillna(0.0)\n",
        "                y_array = y_clean.values.astype(np.float64)\n",
        "            else:\n",
        "                y_array = np.asarray(y, dtype=np.float64)\n",
        "\n",
        "            # Verify arrays are proper\n",
        "            if X_array.size == 0 or y_array.size == 0:\n",
        "                raise ValueError(f\"Empty arrays after conversion\")\n",
        "\n",
        "            # Clean arrays\n",
        "            X_array = np.nan_to_num(X_array, nan=0.0, posinf=1e6, neginf=-1e6)\n",
        "            y_array = np.nan_to_num(y_array, nan=0.0, posinf=1e6, neginf=-1e6)\n",
        "\n",
        "            # Create and fit pipeline\n",
        "            self.pipeline = Pipeline([\n",
        "                ('scaler', StandardScaler()),\n",
        "                ('model', clone(self.model))\n",
        "            ])\n",
        "\n",
        "            self.pipeline.fit(X_array, y_array.ravel())\n",
        "            self.is_fitted = True\n",
        "\n",
        "            # Test prediction\n",
        "            test_pred = self.pipeline.predict(X_array[:min(5, len(X_array))])\n",
        "            if len(test_pred) == 0 or np.all(np.isnan(test_pred)):\n",
        "                logger.warning(f\"{self.name}: Model produces invalid predictions\")\n",
        "                self.is_fitted = False\n",
        "\n",
        "        except Exception as e:\n",
        "            self.fit_error = str(e)\n",
        "            logger.error(f\"{self.name} fit failed: {self.fit_error}\")\n",
        "            self.is_fitted = False\n",
        "\n",
        "        finally:\n",
        "            self.training_time = time.time() - fit_start\n",
        "            status = \"SUCCESS\" if self.is_fitted else \"FAILED\"\n",
        "            logger.info(f\"{self.name}: {status} ({self.training_time:.2f}s)\")\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X: pd.DataFrame) -> np.ndarray:\n",
        "        \"\"\"Make predictions with robust data handling\"\"\"\n",
        "\n",
        "        if not self.is_fitted:\n",
        "            logger.error(f\"{self.name}: Cannot predict - model not fitted\")\n",
        "            return np.zeros(len(X))\n",
        "\n",
        "        try:\n",
        "            # Convert input data safely\n",
        "            if isinstance(X, pd.DataFrame):\n",
        "                X_clean = X.copy()\n",
        "                for col in X_clean.columns:\n",
        "                    if not np.issubdtype(X_clean[col].dtype, np.number):\n",
        "                        X_clean[col] = pd.to_numeric(X_clean[col], errors='coerce')\n",
        "                    X_clean[col] = X_clean[col].fillna(0.0)\n",
        "                X_array = X_clean.values.astype(np.float64)\n",
        "            else:\n",
        "                X_array = np.asarray(X, dtype=np.float64)\n",
        "\n",
        "            # Clean array\n",
        "            X_array = np.nan_to_num(X_array, nan=0.0, posinf=1e6, neginf=-1e6)\n",
        "\n",
        "            # Make predictions\n",
        "            predictions = self.pipeline.predict(X_array)\n",
        "            predictions = np.nan_to_num(predictions, nan=0.0, posinf=1e6, neginf=-1e6)\n",
        "\n",
        "            return predictions.flatten()\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"{self.name} prediction failed: {str(e)}\")\n",
        "            return np.zeros(len(X))\n",
        "\n",
        "# ============================================================================\n",
        "# ROBUST MODEL FACTORY\n",
        "# ============================================================================\n",
        "\n",
        "def create_robust_models(config: DebugMLForecastingConfig) -> List[RobustMLForecaster]:\n",
        "    \"\"\"Create models with robust forecasters\"\"\"\n",
        "\n",
        "    logger.info(\"Creating robust ML models...\")\n",
        "\n",
        "    models = []\n",
        "\n",
        "    # Linear models\n",
        "    models.extend([\n",
        "        RobustMLForecaster(\"LinearRegression\", LinearRegression(), config.debug_mode),\n",
        "        RobustMLForecaster(\"Ridge_1.0\", Ridge(alpha=1.0), config.debug_mode),\n",
        "        RobustMLForecaster(\"Lasso_1.0\", Lasso(alpha=1.0, max_iter=2000), config.debug_mode),\n",
        "    ])\n",
        "\n",
        "    # Tree models\n",
        "    models.extend([\n",
        "        RobustMLForecaster(\"RandomForest_100\", RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=1), config.debug_mode),\n",
        "        RobustMLForecaster(\"ExtraTrees_100\", ExtraTreesRegressor(n_estimators=100, random_state=42, n_jobs=1), config.debug_mode),\n",
        "        RobustMLForecaster(\"GradientBoosting_100\", GradientBoostingRegressor(n_estimators=100, random_state=42), config.debug_mode),\n",
        "    ])\n",
        "\n",
        "    # Add XGBoost and LightGBM if available\n",
        "    if XGB_AVAILABLE:\n",
        "        models.append(RobustMLForecaster(\"XGBoost_100\", xgb.XGBRegressor(n_estimators=100, random_state=42, n_jobs=1), config.debug_mode))\n",
        "\n",
        "    if LGB_AVAILABLE:\n",
        "        models.append(RobustMLForecaster(\"LightGBM_100\", lgb.LGBMRegressor(n_estimators=100, random_state=42, verbose=-1, n_jobs=1), config.debug_mode))\n",
        "\n",
        "    # Other models if not quick test\n",
        "    if not config.quick_search:\n",
        "        models.extend([\n",
        "            RobustMLForecaster(\"SVR_rbf\", SVR(kernel='rbf', C=1.0), config.debug_mode),\n",
        "            RobustMLForecaster(\"KNeighbors_5\", KNeighborsRegressor(n_neighbors=5), config.debug_mode),\n",
        "        ])\n",
        "\n",
        "    logger.info(f\"Created {len(models)} robust models\")\n",
        "    return models\n",
        "\n",
        "# ============================================================================\n",
        "# SIMPLIFIED PIPELINE EXECUTION\n",
        "# ============================================================================\n",
        "\n",
        "def run_robust_pipeline(csv_path: str, target_column: str, date_column: str = None, quick_test: bool = True) -> pd.DataFrame:\n",
        "    \"\"\"Run ML pipeline with robust error handling\"\"\"\n",
        "\n",
        "    logger.info(\"ROBUST ML FORECASTING PIPELINE\")\n",
        "    logger.info(\"=\" * 60)\n",
        "\n",
        "    try:\n",
        "        # 1. Load data\n",
        "        logger.info(\"Step 1: Loading CSV data...\")\n",
        "        data = load_csv_data_robust(csv_path, target_column, date_column)\n",
        "\n",
        "        # 2. Basic feature engineering\n",
        "        logger.info(\"Step 2: Creating features...\")\n",
        "        features_df = data.copy()\n",
        "\n",
        "        # Add simple lag features\n",
        "        for lag in [1, 2, 3, 7]:\n",
        "            if lag < len(data):\n",
        "                features_df[f'lag_{lag}'] = data[target_column].shift(lag)\n",
        "\n",
        "        # Add rolling features\n",
        "        for window in [3, 7]:\n",
        "            if window < len(data):\n",
        "                features_df[f'rolling_mean_{window}'] = data[target_column].rolling(window, min_periods=1).mean()\n",
        "                features_df[f'rolling_std_{window}'] = data[target_column].rolling(window, min_periods=1).std()\n",
        "\n",
        "        # Clean features\n",
        "        features_df = features_df.fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
        "\n",
        "        # Remove target from features\n",
        "        if target_column in features_df.columns:\n",
        "            features_df = features_df.drop(columns=[target_column])\n",
        "\n",
        "        # 3. Create supervised dataset\n",
        "        logger.info(\"Step 3: Creating supervised dataset...\")\n",
        "        target_series = data[target_column].shift(-1)  # Forecast next period\n",
        "\n",
        "        # Align data\n",
        "        common_index = features_df.index.intersection(target_series.index)\n",
        "        X = features_df.loc[common_index]\n",
        "        y = target_series.loc[common_index]\n",
        "\n",
        "        # Remove last row (no target available)\n",
        "        X = X.iloc[:-1]\n",
        "        y = y.iloc[:-1]\n",
        "\n",
        "        # Remove NaN targets\n",
        "        valid_mask = ~y.isna()\n",
        "        X = X[valid_mask]\n",
        "        y = y[valid_mask]\n",
        "\n",
        "        logger.info(f\"  Final dataset: {X.shape} features, {y.shape} targets\")\n",
        "\n",
        "        # 4. Split data\n",
        "        logger.info(\"Step 4: Splitting data...\")\n",
        "        train_size = int(len(X) * 0.75)\n",
        "        X_train, X_test = X.iloc[:train_size], X.iloc[train_size:]\n",
        "        y_train, y_test = y.iloc[:train_size], y.iloc[train_size:]\n",
        "\n",
        "        logger.info(f\"  Train: {X_train.shape}, Test: {X_test.shape}\")\n",
        "\n",
        "        # 5. Create and train models\n",
        "        logger.info(\"Step 5: Training models...\")\n",
        "        config = DebugMLForecastingConfig(\n",
        "            target_column=target_column,\n",
        "            quick_search=quick_test,\n",
        "            debug_mode=True\n",
        "        )\n",
        "\n",
        "        models = create_robust_models(config)\n",
        "        results = []\n",
        "\n",
        "        for i, model in enumerate(models, 1):\n",
        "            logger.info(f\"  [{i}/{len(models)}] Training {model.name}...\")\n",
        "\n",
        "            try:\n",
        "                model.fit(X_train, y_train)\n",
        "\n",
        "                if model.is_fitted:\n",
        "                    predictions = model.predict(X_test)\n",
        "\n",
        "                    if len(predictions) > 0 and not np.all(np.isnan(predictions)):\n",
        "                        mae = mean_absolute_error(y_test.values, predictions)\n",
        "                        rmse = np.sqrt(mean_squared_error(y_test.values, predictions))\n",
        "\n",
        "                        results.append({\n",
        "                            'Model': model.name,\n",
        "                            'MAE': mae,\n",
        "                            'RMSE': rmse,\n",
        "                            'Status': 'Success'\n",
        "                        })\n",
        "\n",
        "                        logger.info(f\"    SUCCESS - MAE: {mae:.3f}\")\n",
        "                    else:\n",
        "                        logger.warning(f\"    FAILED - Invalid predictions\")\n",
        "                else:\n",
        "                    logger.warning(f\"    FAILED - {model.fit_error}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"    FAILED - {str(e)}\")\n",
        "\n",
        "        # 6. Results\n",
        "        if results:\n",
        "            results_df = pd.DataFrame(results)\n",
        "            results_df = results_df.sort_values('MAE')\n",
        "\n",
        "            logger.info(\"RESULTS:\")\n",
        "            logger.info(\"=\" * 40)\n",
        "            for i, (_, row) in enumerate(results_df.head(5).iterrows(), 1):\n",
        "                logger.info(f\"  {i}. {row['Model']}: MAE {row['MAE']:.3f}\")\n",
        "\n",
        "            return results_df\n",
        "        else:\n",
        "            logger.error(\"No successful models!\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Pipeline failed: {str(e)}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# ============================================================================\n",
        "# AUTOMATIC EXECUTION\n",
        "# ============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"ROBUST ML FORECASTING SYSTEM\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"CSV File: {CSV_FILE_PATH}\")\n",
        "    print(f\"Target: {TARGET_COLUMN}\")\n",
        "    print(f\"Date Column: {DATE_COLUMN}\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    try:\n",
        "        results = run_robust_pipeline(\n",
        "            csv_path=CSV_FILE_PATH,\n",
        "            target_column=TARGET_COLUMN,\n",
        "            date_column=DATE_COLUMN,\n",
        "            quick_test=QUICK_TEST\n",
        "        )\n",
        "\n",
        "        if not results.empty:\n",
        "            print(\"\\nTOP MODELS:\")\n",
        "            print(\"-\" * 30)\n",
        "            for i, (_, row) in enumerate(results.head(5).iterrows(), 1):\n",
        "                print(f\"{i}. {row['Model']}: MAE {row['MAE']:.3f}\")\n",
        "\n",
        "            # Save results\n",
        "            output_file = f\"ml_results_{TARGET_COLUMN}.csv\"\n",
        "            results.to_csv(output_file, index=False)\n",
        "            print(f\"\\nResults saved to: {output_file}\")\n",
        "        else:\n",
        "            print(\"\\nNo results generated\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Execution failed: {str(e)}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"MANUAL EXECUTION:\")\n",
        "print(\"=\"*40)\n",
        "print(\"# To run manually:\")\n",
        "print(f'results = run_robust_pipeline(\"{CSV_FILE_PATH}\", \"{TARGET_COLUMN}\", \"{DATE_COLUMN}\")')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQ0o4CufBjP4",
        "outputId": "06de4dbc-2fc1-4382-8737-3932fa0b8c44"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROBUST ML FORECASTING SYSTEM\n",
            "==================================================\n",
            "CSV File: enhanced_eda_data.csv\n",
            "Target: calls\n",
            "Date Column: date\n",
            "==================================================\n",
            "\n",
            "TOP MODELS:\n",
            "------------------------------\n",
            "1. ExtraTrees_100: MAE 688.027\n",
            "2. LightGBM_100: MAE 810.669\n",
            "3. RandomForest_100: MAE 836.143\n",
            "4. XGBoost_100: MAE 960.436\n",
            "5. Ridge_1.0: MAE 1196.221\n",
            "\n",
            "Results saved to: ml_results_calls.csv\n",
            "\n",
            "========================================\n",
            "MANUAL EXECUTION:\n",
            "========================================\n",
            "# To run manually:\n",
            "results = run_robust_pipeline(\"enhanced_eda_data.csv\", \"calls\", \"date\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RMheNMSKExBT"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# GUARANTEED 30+ MODELS PIPELINE\n",
        "# ============================================================================\n",
        "\n",
        "def create_all_30_models() -> List[RobustMLForecaster]:\n",
        "    \"\"\"Create exactly 30+ models - no shortcuts\"\"\"\n",
        "\n",
        "    print(\"Creating ALL 30+ ML models...\")\n",
        "\n",
        "    models = []\n",
        "\n",
        "    # LINEAR MODELS (10 models)\n",
        "    print(\"  Adding Linear Models...\")\n",
        "    models.extend([\n",
        "        RobustMLForecaster(\"LinearRegression\", LinearRegression(), True),\n",
        "        RobustMLForecaster(\"Ridge_0.1\", Ridge(alpha=0.1), True),\n",
        "        RobustMLForecaster(\"Ridge_1.0\", Ridge(alpha=1.0), True),\n",
        "        RobustMLForecaster(\"Ridge_10.0\", Ridge(alpha=10.0), True),\n",
        "        RobustMLForecaster(\"Lasso_0.1\", Lasso(alpha=0.1, max_iter=2000), True),\n",
        "        RobustMLForecaster(\"Lasso_1.0\", Lasso(alpha=1.0, max_iter=2000), True),\n",
        "        RobustMLForecaster(\"ElasticNet_0.1\", ElasticNet(alpha=0.1, max_iter=2000), True),\n",
        "        RobustMLForecaster(\"ElasticNet_1.0\", ElasticNet(alpha=1.0, max_iter=2000), True),\n",
        "        RobustMLForecaster(\"BayesianRidge\", BayesianRidge(), True),\n",
        "        RobustMLForecaster(\"HuberRegressor\", HuberRegressor(max_iter=200), True),\n",
        "    ])\n",
        "\n",
        "    # TREE MODELS (9 models)\n",
        "    print(\"  Adding Tree Models...\")\n",
        "    models.extend([\n",
        "        RobustMLForecaster(\"RandomForest_50\", RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=1), True),\n",
        "        RobustMLForecaster(\"RandomForest_100\", RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=1), True),\n",
        "        RobustMLForecaster(\"RandomForest_200\", RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=1), True),\n",
        "        RobustMLForecaster(\"ExtraTrees_50\", ExtraTreesRegressor(n_estimators=50, random_state=42, n_jobs=1), True),\n",
        "        RobustMLForecaster(\"ExtraTrees_100\", ExtraTreesRegressor(n_estimators=100, random_state=42, n_jobs=1), True),\n",
        "        RobustMLForecaster(\"ExtraTrees_200\", ExtraTreesRegressor(n_estimators=200, random_state=42, n_jobs=1), True),\n",
        "        RobustMLForecaster(\"GradientBoosting_50\", GradientBoostingRegressor(n_estimators=50, random_state=42), True),\n",
        "        RobustMLForecaster(\"GradientBoosting_100\", GradientBoostingRegressor(n_estimators=100, random_state=42), True),\n",
        "        RobustMLForecaster(\"DecisionTree\", DecisionTreeRegressor(random_state=42, max_depth=10), True),\n",
        "    ])\n",
        "\n",
        "    # XGBOOST MODELS (3 models)\n",
        "    if XGB_AVAILABLE:\n",
        "        print(\"  Adding XGBoost Models...\")\n",
        "        models.extend([\n",
        "            RobustMLForecaster(\"XGBoost_50\", xgb.XGBRegressor(n_estimators=50, random_state=42, n_jobs=1), True),\n",
        "            RobustMLForecaster(\"XGBoost_100\", xgb.XGBRegressor(n_estimators=100, random_state=42, n_jobs=1), True),\n",
        "            RobustMLForecaster(\"XGBoost_200\", xgb.XGBRegressor(n_estimators=200, random_state=42, n_jobs=1), True),\n",
        "        ])\n",
        "\n",
        "    # LIGHTGBM MODELS (3 models)\n",
        "    if LGB_AVAILABLE:\n",
        "        print(\"  Adding LightGBM Models...\")\n",
        "        models.extend([\n",
        "            RobustMLForecaster(\"LightGBM_50\", lgb.LGBMRegressor(n_estimators=50, random_state=42, verbose=-1, n_jobs=1), True),\n",
        "            RobustMLForecaster(\"LightGBM_100\", lgb.LGBMRegressor(n_estimators=100, random_state=42, verbose=-1, n_jobs=1), True),\n",
        "            RobustMLForecaster(\"LightGBM_200\", lgb.LGBMRegressor(n_estimators=200, random_state=42, verbose=-1, n_jobs=1), True),\n",
        "        ])\n",
        "\n",
        "    # NEURAL NETWORK MODELS (3 models)\n",
        "    print(\"  Adding Neural Network Models...\")\n",
        "    models.extend([\n",
        "        RobustMLForecaster(\"MLP_50\", MLPRegressor(hidden_layer_sizes=(50,), random_state=42, max_iter=1000, early_stopping=True, validation_fraction=0.1), True),\n",
        "        RobustMLForecaster(\"MLP_100\", MLPRegressor(hidden_layer_sizes=(100,), random_state=42, max_iter=1000, early_stopping=True, validation_fraction=0.1), True),\n",
        "        RobustMLForecaster(\"MLP_100_50\", MLPRegressor(hidden_layer_sizes=(100, 50), random_state=42, max_iter=1000, early_stopping=True, validation_fraction=0.1), True),\n",
        "    ])\n",
        "\n",
        "    # ENSEMBLE MODELS (2 models)\n",
        "    print(\"  Adding Ensemble Models...\")\n",
        "    models.extend([\n",
        "        RobustMLForecaster(\"BaggingRegressor\", BaggingRegressor(random_state=42, n_jobs=1), True),\n",
        "        RobustMLForecaster(\"AdaBoostRegressor\", AdaBoostRegressor(random_state=42, n_estimators=50), True),\n",
        "    ])\n",
        "\n",
        "    # OTHER MODELS (7 models)\n",
        "    print(\"  Adding Other Models...\")\n",
        "    models.extend([\n",
        "        RobustMLForecaster(\"SVR_linear\", SVR(kernel='linear', C=1.0), True),\n",
        "        RobustMLForecaster(\"SVR_rbf\", SVR(kernel='rbf', C=1.0), True),\n",
        "        RobustMLForecaster(\"SVR_poly\", SVR(kernel='poly', C=1.0, degree=3), True),\n",
        "        RobustMLForecaster(\"KNeighbors_3\", KNeighborsRegressor(n_neighbors=3), True),\n",
        "        RobustMLForecaster(\"KNeighbors_5\", KNeighborsRegressor(n_neighbors=5), True),\n",
        "        RobustMLForecaster(\"KNeighbors_10\", KNeighborsRegressor(n_neighbors=10), True),\n",
        "        RobustMLForecaster(\"KernelRidge\", KernelRidge(alpha=1.0), True),\n",
        "    ])\n",
        "\n",
        "    print(f\"âœ… Created {len(models)} total models\")\n",
        "\n",
        "    # Count by type\n",
        "    linear_count = len([m for m in models if any(x in m.name for x in ['Linear', 'Ridge', 'Lasso', 'Elastic', 'Bayesian', 'Huber'])])\n",
        "    tree_count = len([m for m in models if any(x in m.name for x in ['Forest', 'Extra', 'Gradient', 'Decision'])])\n",
        "    xgb_count = len([m for m in models if 'XGBoost' in m.name])\n",
        "    lgb_count = len([m for m in models if 'LightGBM' in m.name])\n",
        "    neural_count = len([m for m in models if 'MLP' in m.name])\n",
        "    ensemble_count = len([m for m in models if any(x in m.name for x in ['Bagging', 'Ada'])])\n",
        "    other_count = len([m for m in models if any(x in m.name for x in ['SVR', 'KNeighbors', 'Kernel'])])\n",
        "\n",
        "    print(f\"  Linear models: {linear_count}\")\n",
        "    print(f\"  Tree models: {tree_count}\")\n",
        "    print(f\"  XGBoost models: {xgb_count}\")\n",
        "    print(f\"  LightGBM models: {lgb_count}\")\n",
        "    print(f\"  Neural networks: {neural_count}\")\n",
        "    print(f\"  Ensemble models: {ensemble_count}\")\n",
        "    print(f\"  Other models: {other_count}\")\n",
        "\n",
        "    return models\n",
        "\n",
        "def run_all_30_models_pipeline():\n",
        "    \"\"\"Guaranteed pipeline that runs ALL 30+ models\"\"\"\n",
        "\n",
        "    print(\"ðŸš€ RUNNING GUARANTEED 30+ MODELS PIPELINE\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    try:\n",
        "        # 1. Load data\n",
        "        print(\"Step 1: Loading CSV data...\")\n",
        "        data = load_csv_data_robust(CSV_FILE_PATH, TARGET_COLUMN, DATE_COLUMN)\n",
        "\n",
        "        # 2. Feature engineering\n",
        "        print(\"\\nStep 2: Creating features...\")\n",
        "        features_df = data.copy()\n",
        "\n",
        "        # Add lag features\n",
        "        for lag in [1, 2, 3, 7, 14]:\n",
        "            if lag < len(data):\n",
        "                features_df[f'lag_{lag}'] = data[TARGET_COLUMN].shift(lag)\n",
        "\n",
        "        # Add rolling features\n",
        "        for window in [3, 7, 14]:\n",
        "            if window < len(data):\n",
        "                features_df[f'rolling_mean_{window}'] = data[TARGET_COLUMN].rolling(window, min_periods=1).mean()\n",
        "                features_df[f'rolling_std_{window}'] = data[TARGET_COLUMN].rolling(window, min_periods=1).std()\n",
        "\n",
        "        # Add simple market features if available\n",
        "        if '^VIX_close' in data.columns:\n",
        "            features_df['vix_lag1'] = data['^VIX_close'].shift(1)\n",
        "            features_df['vix_change'] = data['^VIX_close'].diff()\n",
        "\n",
        "        if 'SPY_close' in data.columns:\n",
        "            features_df['spy_return'] = data['SPY_close'].pct_change()\n",
        "\n",
        "        # Clean features\n",
        "        features_df = features_df.fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
        "\n",
        "        # Remove target from features\n",
        "        if TARGET_COLUMN in features_df.columns:\n",
        "            features_df = features_df.drop(columns=[TARGET_COLUMN])\n",
        "\n",
        "        print(f\"  Created {features_df.shape[1]} features\")\n",
        "\n",
        "        # 3. Create supervised dataset\n",
        "        print(\"\\nStep 3: Creating supervised dataset...\")\n",
        "        target_series = data[TARGET_COLUMN].shift(-1)  # Forecast next period\n",
        "\n",
        "        # Align data\n",
        "        common_index = features_df.index.intersection(target_series.index)\n",
        "        X = features_df.loc[common_index]\n",
        "        y = target_series.loc[common_index]\n",
        "\n",
        "        # Remove last row (no target available) and NaN targets\n",
        "        X = X.iloc[:-1]\n",
        "        y = y.iloc[:-1]\n",
        "        valid_mask = ~y.isna()\n",
        "        X = X[valid_mask]\n",
        "        y = y[valid_mask]\n",
        "\n",
        "        print(f\"  Final dataset: {X.shape} features, {y.shape} targets\")\n",
        "\n",
        "        # 4. Split data\n",
        "        print(\"\\nStep 4: Splitting data...\")\n",
        "        train_size = int(len(X) * 0.75)\n",
        "        X_train, X_test = X.iloc[:train_size], X.iloc[train_size:]\n",
        "        y_train, y_test = y.iloc[:train_size], y.iloc[train_size:]\n",
        "\n",
        "        print(f\"  Train: {X_train.shape}, Test: {X_test.shape}\")\n",
        "\n",
        "        # 5. Create ALL models\n",
        "        print(\"\\nStep 5: Creating ALL 30+ models...\")\n",
        "        all_models = create_all_30_models()\n",
        "\n",
        "        # 6. Train ALL models\n",
        "        print(f\"\\nStep 6: Training ALL {len(all_models)} models...\")\n",
        "        results = []\n",
        "\n",
        "        for i, model in enumerate(all_models, 1):\n",
        "            print(f\"  [{i:2d}/{len(all_models):2d}] Training {model.name}...\")\n",
        "\n",
        "            try:\n",
        "                model.fit(X_train, y_train)\n",
        "\n",
        "                if model.is_fitted:\n",
        "                    predictions = model.predict(X_test)\n",
        "\n",
        "                    if len(predictions) > 0 and not np.all(np.isnan(predictions)):\n",
        "                        mae = mean_absolute_error(y_test.values, predictions)\n",
        "                        rmse = np.sqrt(mean_squared_error(y_test.values, predictions))\n",
        "\n",
        "                        results.append({\n",
        "                            'Model': model.name,\n",
        "                            'MAE': mae,\n",
        "                            'RMSE': rmse,\n",
        "                            'Status': 'Success'\n",
        "                        })\n",
        "\n",
        "                        print(f\"    âœ… SUCCESS - MAE: {mae:.3f}\")\n",
        "                    else:\n",
        "                        print(f\"    âŒ FAILED - Invalid predictions\")\n",
        "                        results.append({\n",
        "                            'Model': model.name,\n",
        "                            'MAE': 9999.0,\n",
        "                            'RMSE': 9999.0,\n",
        "                            'Status': 'Failed'\n",
        "                        })\n",
        "                else:\n",
        "                    print(f\"    âŒ FAILED - {model.fit_error or 'Unknown error'}\")\n",
        "                    results.append({\n",
        "                        'Model': model.name,\n",
        "                        'MAE': 9999.0,\n",
        "                        'RMSE': 9999.0,\n",
        "                        'Status': 'Failed'\n",
        "                    })\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"    âŒ FAILED - {str(e)}\")\n",
        "                results.append({\n",
        "                    'Model': model.name,\n",
        "                    'MAE': 9999.0,\n",
        "                    'RMSE': 9999.0,\n",
        "                    'Status': 'Failed'\n",
        "                })\n",
        "\n",
        "        # 7. Results\n",
        "        print(f\"\\nStep 7: Processing results...\")\n",
        "        if results:\n",
        "            results_df = pd.DataFrame(results)\n",
        "            results_df = results_df.sort_values('MAE')\n",
        "\n",
        "            # Save results\n",
        "            output_file = f\"all_models_results_{TARGET_COLUMN}.csv\"\n",
        "            results_df.to_csv(output_file, index=False)\n",
        "\n",
        "            successful = len(results_df[results_df['Status'] == 'Success'])\n",
        "            total = len(results_df)\n",
        "\n",
        "            print(f\"âœ… TRAINING COMPLETE!\")\n",
        "            print(f\"  Total models: {total}\")\n",
        "            print(f\"  Successful: {successful}\")\n",
        "            print(f\"  Failed: {total - successful}\")\n",
        "            print(f\"  Results saved to: {output_file}\")\n",
        "\n",
        "            return results_df\n",
        "        else:\n",
        "            print(\"âŒ No successful models!\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Pipeline failed: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# ============================================================================\n",
        "# RUN THE 30+ MODELS PIPELINE\n",
        "# ============================================================================\n",
        "\n",
        "print(\"ABOUT TO RUN ALL 30+ MODELS...\")\n",
        "print(\"This will take several minutes but you'll get the complete results.\")\n",
        "print()\n",
        "\n",
        "# Run the guaranteed pipeline\n",
        "all_results = run_all_30_models_pipeline()\n",
        "\n",
        "if not all_results.empty:\n",
        "    print(f\"\\nðŸŽ‰ SUCCESS! Trained {len(all_results)} models\")\n",
        "    print(\"\\nTop 5 models:\")\n",
        "    for i, (_, row) in enumerate(all_results.head(5).iterrows(), 1):\n",
        "        print(f\"  {i}. {row['Model']}: MAE {row['MAE']:.3f}\")\n",
        "else:\n",
        "    print(\"\\nâŒ Pipeline failed to generate results\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"NOW RUN THE ANALYSIS CELL TO SEE ALL MODELS VS BASELINE!\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIC2Bwv-F978",
        "outputId": "a58d2186-575f-464b-e26c-f6238e2f0a7e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ABOUT TO RUN ALL 30+ MODELS...\n",
            "This will take several minutes but you'll get the complete results.\n",
            "\n",
            "ðŸš€ RUNNING GUARANTEED 30+ MODELS PIPELINE\n",
            "============================================================\n",
            "Step 1: Loading CSV data...\n",
            "\n",
            "Step 2: Creating features...\n",
            "  Created 33 features\n",
            "\n",
            "Step 3: Creating supervised dataset...\n",
            "  Final dataset: (975, 33) features, (975,) targets\n",
            "\n",
            "Step 4: Splitting data...\n",
            "  Train: (731, 33), Test: (244, 33)\n",
            "\n",
            "Step 5: Creating ALL 30+ models...\n",
            "Creating ALL 30+ ML models...\n",
            "  Adding Linear Models...\n",
            "  Adding Tree Models...\n",
            "  Adding XGBoost Models...\n",
            "  Adding LightGBM Models...\n",
            "  Adding Neural Network Models...\n",
            "  Adding Ensemble Models...\n",
            "  Adding Other Models...\n",
            "âœ… Created 37 total models\n",
            "  Linear models: 11\n",
            "  Tree models: 9\n",
            "  XGBoost models: 3\n",
            "  LightGBM models: 3\n",
            "  Neural networks: 3\n",
            "  Ensemble models: 2\n",
            "  Other models: 7\n",
            "\n",
            "Step 6: Training ALL 37 models...\n",
            "  [ 1/37] Training LinearRegression...\n",
            "    âœ… SUCCESS - MAE: 1294.918\n",
            "  [ 2/37] Training Ridge_0.1...\n",
            "    âœ… SUCCESS - MAE: 1278.036\n",
            "  [ 3/37] Training Ridge_1.0...\n",
            "    âœ… SUCCESS - MAE: 1178.273\n",
            "  [ 4/37] Training Ridge_10.0...\n",
            "    âœ… SUCCESS - MAE: 1068.587\n",
            "  [ 5/37] Training Lasso_0.1...\n",
            "    âœ… SUCCESS - MAE: 1281.252\n",
            "  [ 6/37] Training Lasso_1.0...\n",
            "    âœ… SUCCESS - MAE: 1177.566\n",
            "  [ 7/37] Training ElasticNet_0.1...\n",
            "    âœ… SUCCESS - MAE: 1124.754\n",
            "  [ 8/37] Training ElasticNet_1.0...\n",
            "    âœ… SUCCESS - MAE: 1283.333\n",
            "  [ 9/37] Training BayesianRidge...\n",
            "    âœ… SUCCESS - MAE: 1141.870\n",
            "  [10/37] Training HuberRegressor...\n",
            "    âœ… SUCCESS - MAE: 1172.589\n",
            "  [11/37] Training RandomForest_50...\n",
            "    âœ… SUCCESS - MAE: 794.245\n",
            "  [12/37] Training RandomForest_100...\n",
            "    âœ… SUCCESS - MAE: 793.945\n",
            "  [13/37] Training RandomForest_200...\n",
            "    âœ… SUCCESS - MAE: 808.563\n",
            "  [14/37] Training ExtraTrees_50...\n",
            "    âœ… SUCCESS - MAE: 675.019\n",
            "  [15/37] Training ExtraTrees_100...\n",
            "    âœ… SUCCESS - MAE: 690.292\n",
            "  [16/37] Training ExtraTrees_200...\n",
            "    âœ… SUCCESS - MAE: 682.715\n",
            "  [17/37] Training GradientBoosting_50...\n",
            "    âœ… SUCCESS - MAE: 1046.767\n",
            "  [18/37] Training GradientBoosting_100...\n",
            "    âœ… SUCCESS - MAE: 1447.137\n",
            "  [19/37] Training DecisionTree...\n",
            "    âœ… SUCCESS - MAE: 1184.249\n",
            "  [20/37] Training XGBoost_50...\n",
            "    âœ… SUCCESS - MAE: 1108.370\n",
            "  [21/37] Training XGBoost_100...\n",
            "    âœ… SUCCESS - MAE: 1118.553\n",
            "  [22/37] Training XGBoost_200...\n",
            "    âœ… SUCCESS - MAE: 1117.693\n",
            "  [23/37] Training LightGBM_50...\n",
            "    âœ… SUCCESS - MAE: 691.070\n",
            "  [24/37] Training LightGBM_100...\n",
            "    âœ… SUCCESS - MAE: 733.969\n",
            "  [25/37] Training LightGBM_200...\n",
            "    âœ… SUCCESS - MAE: 773.011\n",
            "  [26/37] Training MLP_50...\n",
            "    âœ… SUCCESS - MAE: 2937.307\n",
            "  [27/37] Training MLP_100...\n",
            "    âœ… SUCCESS - MAE: 2834.402\n",
            "  [28/37] Training MLP_100_50...\n",
            "    âœ… SUCCESS - MAE: 3180.578\n",
            "  [29/37] Training BaggingRegressor...\n",
            "    âœ… SUCCESS - MAE: 755.787\n",
            "  [30/37] Training AdaBoostRegressor...\n",
            "    âœ… SUCCESS - MAE: 1043.514\n",
            "  [31/37] Training SVR_linear...\n",
            "    âœ… SUCCESS - MAE: 1470.199\n",
            "  [32/37] Training SVR_rbf...\n",
            "    âœ… SUCCESS - MAE: 1720.220\n",
            "  [33/37] Training SVR_poly...\n",
            "    âœ… SUCCESS - MAE: 1697.294\n",
            "  [34/37] Training KNeighbors_3...\n",
            "    âœ… SUCCESS - MAE: 1469.392\n",
            "  [35/37] Training KNeighbors_5...\n",
            "    âœ… SUCCESS - MAE: 1524.048\n",
            "  [36/37] Training KNeighbors_10...\n",
            "    âœ… SUCCESS - MAE: 1541.689\n",
            "  [37/37] Training KernelRidge...\n",
            "    âœ… SUCCESS - MAE: 7601.597\n",
            "\n",
            "Step 7: Processing results...\n",
            "âœ… TRAINING COMPLETE!\n",
            "  Total models: 37\n",
            "  Successful: 37\n",
            "  Failed: 0\n",
            "  Results saved to: all_models_results_calls.csv\n",
            "\n",
            "ðŸŽ‰ SUCCESS! Trained 37 models\n",
            "\n",
            "Top 5 models:\n",
            "  1. ExtraTrees_50: MAE 675.019\n",
            "  2. ExtraTrees_200: MAE 682.715\n",
            "  3. ExtraTrees_100: MAE 690.292\n",
            "  4. LightGBM_50: MAE 691.070\n",
            "  5. LightGBM_100: MAE 733.969\n",
            "\n",
            "============================================================\n",
            "NOW RUN THE ANALYSIS CELL TO SEE ALL MODELS VS BASELINE!\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# FINAL ANALYSIS - ALL 30+ MODELS vs SEASONAL BASELINE\n",
        "# ============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"FINAL COMPREHENSIVE ANALYSIS - ALL MODELS vs SEASONAL BASELINE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Load the data to calculate baseline\n",
        "data = pd.read_csv(\"enhanced_eda_data.csv\")\n",
        "if \"date\" in data.columns:\n",
        "    data[\"date\"] = pd.to_datetime(data[\"date\"])\n",
        "    data = data.set_index(\"date\").sort_index()\n",
        "\n",
        "# Calculate seasonal baseline (7-day naive)\n",
        "print(\"Calculating Seasonal Baseline...\")\n",
        "target_series = data[\"calls\"]\n",
        "train_size = int(len(target_series) * 0.75)\n",
        "train_data = target_series.iloc[:train_size]\n",
        "test_data = target_series.iloc[train_size:]\n",
        "\n",
        "# Create seasonal predictions\n",
        "seasonal_predictions = []\n",
        "for i in range(len(test_data)):\n",
        "    lookup_idx = train_size + i - 7  # 7-day seasonal\n",
        "    if lookup_idx >= 0 and lookup_idx < len(target_series):\n",
        "        seasonal_predictions.append(target_series.iloc[lookup_idx])\n",
        "    else:\n",
        "        seasonal_predictions.append(train_data.iloc[-1])\n",
        "\n",
        "seasonal_predictions = np.array(seasonal_predictions)\n",
        "baseline_mae = mean_absolute_error(test_data.values, seasonal_predictions)\n",
        "baseline_rmse = np.sqrt(mean_squared_error(test_data.values, seasonal_predictions))\n",
        "\n",
        "print(f\"Seasonal Baseline (7-day):\")\n",
        "print(f\"  MAE: {baseline_mae:.4f}\")\n",
        "print(f\"  RMSE: {baseline_rmse:.4f}\")\n",
        "print()\n",
        "\n",
        "# Load ML results\n",
        "print(\"Loading ML model results...\")\n",
        "try:\n",
        "    ml_results = pd.read_csv(\"all_models_results_calls.csv\")\n",
        "    print(f\"Loaded {len(ml_results)} model results\")\n",
        "except FileNotFoundError:\n",
        "    print(\"ERROR: all_models_results_calls.csv not found!\")\n",
        "    print(\"Please run the 30+ models pipeline first.\")\n",
        "    exit()\n",
        "\n",
        "# Add baseline comparison\n",
        "ml_results['Baseline_MAE'] = baseline_mae\n",
        "ml_results['MAE_Improvement'] = baseline_mae - ml_results['MAE']\n",
        "ml_results['Improvement_Pct'] = ((baseline_mae - ml_results['MAE']) / baseline_mae) * 100\n",
        "ml_results['Beats_Baseline'] = ml_results['MAE'] < baseline_mae\n",
        "ml_results['Performance'] = ml_results['Beats_Baseline'].apply(lambda x: 'âœ“ BEAT' if x else 'âœ— FAILED')\n",
        "\n",
        "# Sort by MAE (best first)\n",
        "ml_results = ml_results.sort_values('MAE')\n",
        "\n",
        "print(\"ALL MODELS DETAILED RESULTS:\")\n",
        "print(\"=\"*85)\n",
        "print(f\"{'Rank':<4} {'Model':<25} {'MAE':<8} {'vs Baseline':<12} {'Improvement':<12} {'Status':<8}\")\n",
        "print(\"-\"*85)\n",
        "\n",
        "for i, (_, row) in enumerate(ml_results.iterrows(), 1):\n",
        "    rank = f\"{i}.\"\n",
        "    model = row['Model'][:24]\n",
        "    mae = f\"{row['MAE']:.4f}\"\n",
        "    improvement = f\"{row['Improvement_Pct']:+.1f}%\"\n",
        "    vs_baseline = f\"{row['MAE_Improvement']:+.4f}\"\n",
        "    status = row['Performance']\n",
        "\n",
        "    print(f\"{rank:<4} {model:<25} {mae:<8} {vs_baseline:<12} {improvement:<12} {status:<8}\")\n",
        "\n",
        "# Summary statistics\n",
        "total_models = len(ml_results)\n",
        "successful_models = ml_results['Beats_Baseline'].sum()\n",
        "failed_models = total_models - successful_models\n",
        "best_model = ml_results.iloc[0]\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PERFORMANCE SUMMARY:\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Seasonal Baseline MAE: {baseline_mae:.4f}\")\n",
        "print(f\"Total ML Models: {total_models}\")\n",
        "print(f\"Models that BEAT baseline: {successful_models} ({successful_models/total_models*100:.1f}%)\")\n",
        "print(f\"Models that FAILED vs baseline: {failed_models} ({failed_models/total_models*100:.1f}%)\")\n",
        "print()\n",
        "\n",
        "print(\"CHAMPION MODEL:\")\n",
        "print(\"-\" * 30)\n",
        "print(f\"Model: {best_model['Model']}\")\n",
        "print(f\"MAE: {best_model['MAE']:.4f}\")\n",
        "print(f\"Improvement over baseline: {best_model['Improvement_Pct']:+.1f}%\")\n",
        "print(f\"Absolute improvement: {best_model['MAE_Improvement']:+.4f}\")\n",
        "print()\n",
        "\n",
        "# Model type performance\n",
        "print(\"MODEL TYPE PERFORMANCE:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "model_types = {\n",
        "    'Linear': ['Linear', 'Ridge', 'Lasso', 'Elastic', 'Bayesian', 'Huber'],\n",
        "    'Tree': ['Forest', 'Extra', 'Gradient', 'Decision'],\n",
        "    'XGBoost': ['XGBoost'],\n",
        "    'LightGBM': ['LightGBM'],\n",
        "    'Neural': ['MLP'],\n",
        "    'Ensemble': ['Bagging', 'Ada'],\n",
        "    'Other': ['SVR', 'KNeighbors', 'Kernel']\n",
        "}\n",
        "\n",
        "for category, keywords in model_types.items():\n",
        "    category_models = ml_results[ml_results['Model'].str.contains('|'.join(keywords), case=False)]\n",
        "    if len(category_models) > 0:\n",
        "        category_success = category_models['Beats_Baseline'].sum()\n",
        "        category_total = len(category_models)\n",
        "        success_rate = (category_success / category_total) * 100\n",
        "        best_in_category = category_models.iloc[0]\n",
        "\n",
        "        print(f\"{category:>10}: {category_success:2d}/{category_total:2d} beat baseline ({success_rate:5.1f}%) | Best: {best_in_category['Model']:<20} (MAE: {best_in_category['MAE']:.4f})\")\n",
        "\n",
        "# Top performers\n",
        "print(\"\\nTOP 10 PERFORMERS:\")\n",
        "print(\"-\" * 60)\n",
        "for i, (_, row) in enumerate(ml_results.head(10).iterrows(), 1):\n",
        "    status_icon = \"âœ“\" if row['Beats_Baseline'] else \"âœ—\"\n",
        "    print(f\"{i:2d}. {status_icon} {row['Model']:<25} MAE: {row['MAE']:.4f} ({row['Improvement_Pct']:+.1f}%)\")\n",
        "\n",
        "# Final insights\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"KEY INSIGHTS:\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "if successful_models == 0:\n",
        "    print(\"ðŸš¨ CRITICAL: No ML models beat the seasonal baseline!\")\n",
        "    print(\"   â†’ The 7-day seasonal pattern is extremely strong\")\n",
        "    print(\"   â†’ Consider ensemble methods or seasonal decomposition\")\n",
        "    print(\"   â†’ Stick with simple seasonal forecasting for now\")\n",
        "elif successful_models < total_models * 0.3:\n",
        "    print(f\"âš ï¸  MIXED: Only {successful_models}/{total_models} models beat baseline\")\n",
        "    print(\"   â†’ Most models are not adding value over simple forecasting\")\n",
        "    print(\"   â†’ Focus on the successful models for deployment\")\n",
        "    print(\"   â†’ Consider why other models failed\")\n",
        "else:\n",
        "    print(f\"âœ… SUCCESS: {successful_models}/{total_models} models beat baseline!\")\n",
        "    print(\"   â†’ ML is adding significant value over naive forecasting\")\n",
        "    print(\"   â†’ You have multiple good model options\")\n",
        "    print(\"   â†’ Advanced ML is worthwhile for your use case\")\n",
        "\n",
        "best_improvement = ml_results['Improvement_Pct'].max()\n",
        "if best_improvement > 20:\n",
        "    print(f\"\\nðŸŽ¯ OUTSTANDING: Best model improves baseline by {best_improvement:.1f}%!\")\n",
        "elif best_improvement > 10:\n",
        "    print(f\"\\nðŸ‘ GOOD: Best model improves baseline by {best_improvement:.1f}%\")\n",
        "elif best_improvement > 5:\n",
        "    print(f\"\\nðŸ“ˆ MODEST: Best model improves baseline by {best_improvement:.1f}%\")\n",
        "else:\n",
        "    print(f\"\\nðŸ˜ MINIMAL: Best improvement is only {best_improvement:.1f}%\")\n",
        "\n",
        "# Save enhanced results\n",
        "enhanced_file = \"final_enhanced_results_calls.csv\"\n",
        "ml_results.to_csv(enhanced_file, index=False)\n",
        "print(f\"\\nðŸ’¾ Complete results saved to: {enhanced_file}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ANALYSIS COMPLETE!\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4KnBOswI8jI",
        "outputId": "0d61e0dc-3024-4b26-daa7-6765525e6826"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "FINAL COMPREHENSIVE ANALYSIS - ALL MODELS vs SEASONAL BASELINE\n",
            "================================================================================\n",
            "Calculating Seasonal Baseline...\n",
            "Seasonal Baseline (7-day):\n",
            "  MAE: 767.6025\n",
            "  RMSE: 1022.0483\n",
            "\n",
            "Loading ML model results...\n",
            "Loaded 37 model results\n",
            "ALL MODELS DETAILED RESULTS:\n",
            "=====================================================================================\n",
            "Rank Model                     MAE      vs Baseline  Improvement  Status  \n",
            "-------------------------------------------------------------------------------------\n",
            "1.   ExtraTrees_50             675.0193 +92.5831     +12.1%       âœ“ BEAT  \n",
            "2.   ExtraTrees_200            682.7147 +84.8877     +11.1%       âœ“ BEAT  \n",
            "3.   ExtraTrees_100            690.2918 +77.3107     +10.1%       âœ“ BEAT  \n",
            "4.   LightGBM_50               691.0704 +76.5320     +10.0%       âœ“ BEAT  \n",
            "5.   LightGBM_100              733.9691 +33.6333     +4.4%        âœ“ BEAT  \n",
            "6.   BaggingRegressor          755.7873 +11.8152     +1.5%        âœ“ BEAT  \n",
            "7.   LightGBM_200              773.0110 -5.4086      -0.7%        âœ— FAILED\n",
            "8.   RandomForest_100          793.9450 -26.3426     -3.4%        âœ— FAILED\n",
            "9.   RandomForest_50           794.2450 -26.6425     -3.5%        âœ— FAILED\n",
            "10.  RandomForest_200          808.5635 -40.9610     -5.3%        âœ— FAILED\n",
            "11.  AdaBoostRegressor         1043.5141 -275.9117    -35.9%       âœ— FAILED\n",
            "12.  GradientBoosting_50       1046.7669 -279.1644    -36.4%       âœ— FAILED\n",
            "13.  Ridge_10.0                1068.5870 -300.9846    -39.2%       âœ— FAILED\n",
            "14.  XGBoost_50                1108.3703 -340.7679    -44.4%       âœ— FAILED\n",
            "15.  XGBoost_200               1117.6929 -350.0905    -45.6%       âœ— FAILED\n",
            "16.  XGBoost_100               1118.5532 -350.9507    -45.7%       âœ— FAILED\n",
            "17.  ElasticNet_0.1            1124.7543 -357.1519    -46.5%       âœ— FAILED\n",
            "18.  BayesianRidge             1141.8705 -374.2680    -48.8%       âœ— FAILED\n",
            "19.  HuberRegressor            1172.5886 -404.9861    -52.8%       âœ— FAILED\n",
            "20.  Lasso_1.0                 1177.5664 -409.9639    -53.4%       âœ— FAILED\n",
            "21.  Ridge_1.0                 1178.2731 -410.6706    -53.5%       âœ— FAILED\n",
            "22.  DecisionTree              1184.2493 -416.6468    -54.3%       âœ— FAILED\n",
            "23.  Ridge_0.1                 1278.0365 -510.4340    -66.5%       âœ— FAILED\n",
            "24.  Lasso_0.1                 1281.2520 -513.6495    -66.9%       âœ— FAILED\n",
            "25.  ElasticNet_1.0            1283.3330 -515.7305    -67.2%       âœ— FAILED\n",
            "26.  LinearRegression          1294.9181 -527.3156    -68.7%       âœ— FAILED\n",
            "27.  GradientBoosting_100      1447.1369 -679.5344    -88.5%       âœ— FAILED\n",
            "28.  KNeighbors_3              1469.3921 -701.7896    -91.4%       âœ— FAILED\n",
            "29.  SVR_linear                1470.1985 -702.5960    -91.5%       âœ— FAILED\n",
            "30.  KNeighbors_5              1524.0484 -756.4459    -98.5%       âœ— FAILED\n",
            "31.  KNeighbors_10             1541.6885 -774.0861    -100.8%      âœ— FAILED\n",
            "32.  SVR_poly                  1697.2943 -929.6919    -121.1%      âœ— FAILED\n",
            "33.  SVR_rbf                   1720.2198 -952.6173    -124.1%      âœ— FAILED\n",
            "34.  MLP_100                   2834.4023 -2066.7999   -269.3%      âœ— FAILED\n",
            "35.  MLP_50                    2937.3075 -2169.7050   -282.7%      âœ— FAILED\n",
            "36.  MLP_100_50                3180.5782 -2412.9757   -314.4%      âœ— FAILED\n",
            "37.  KernelRidge               7601.5974 -6833.9950   -890.3%      âœ— FAILED\n",
            "\n",
            "================================================================================\n",
            "PERFORMANCE SUMMARY:\n",
            "================================================================================\n",
            "Seasonal Baseline MAE: 767.6025\n",
            "Total ML Models: 37\n",
            "Models that BEAT baseline: 6 (16.2%)\n",
            "Models that FAILED vs baseline: 31 (83.8%)\n",
            "\n",
            "CHAMPION MODEL:\n",
            "------------------------------\n",
            "Model: ExtraTrees_50\n",
            "MAE: 675.0193\n",
            "Improvement over baseline: +12.1%\n",
            "Absolute improvement: +92.5831\n",
            "\n",
            "MODEL TYPE PERFORMANCE:\n",
            "--------------------------------------------------\n",
            "    Linear:  0/12 beat baseline (  0.0%) | Best: Ridge_10.0           (MAE: 1068.5870)\n",
            "      Tree:  3/ 9 beat baseline ( 33.3%) | Best: ExtraTrees_50        (MAE: 675.0193)\n",
            "   XGBoost:  0/ 3 beat baseline (  0.0%) | Best: XGBoost_50           (MAE: 1108.3703)\n",
            "  LightGBM:  2/ 3 beat baseline ( 66.7%) | Best: LightGBM_50          (MAE: 691.0704)\n",
            "    Neural:  0/ 3 beat baseline (  0.0%) | Best: MLP_100              (MAE: 2834.4023)\n",
            "  Ensemble:  1/ 2 beat baseline ( 50.0%) | Best: BaggingRegressor     (MAE: 755.7873)\n",
            "     Other:  0/ 7 beat baseline (  0.0%) | Best: KNeighbors_3         (MAE: 1469.3921)\n",
            "\n",
            "TOP 10 PERFORMERS:\n",
            "------------------------------------------------------------\n",
            " 1. âœ“ ExtraTrees_50             MAE: 675.0193 (+12.1%)\n",
            " 2. âœ“ ExtraTrees_200            MAE: 682.7147 (+11.1%)\n",
            " 3. âœ“ ExtraTrees_100            MAE: 690.2918 (+10.1%)\n",
            " 4. âœ“ LightGBM_50               MAE: 691.0704 (+10.0%)\n",
            " 5. âœ“ LightGBM_100              MAE: 733.9691 (+4.4%)\n",
            " 6. âœ“ BaggingRegressor          MAE: 755.7873 (+1.5%)\n",
            " 7. âœ— LightGBM_200              MAE: 773.0110 (-0.7%)\n",
            " 8. âœ— RandomForest_100          MAE: 793.9450 (-3.4%)\n",
            " 9. âœ— RandomForest_50           MAE: 794.2450 (-3.5%)\n",
            "10. âœ— RandomForest_200          MAE: 808.5635 (-5.3%)\n",
            "\n",
            "================================================================================\n",
            "KEY INSIGHTS:\n",
            "================================================================================\n",
            "âš ï¸  MIXED: Only 6/37 models beat baseline\n",
            "   â†’ Most models are not adding value over simple forecasting\n",
            "   â†’ Focus on the successful models for deployment\n",
            "   â†’ Consider why other models failed\n",
            "\n",
            "ðŸ‘ GOOD: Best model improves baseline by 12.1%\n",
            "\n",
            "ðŸ’¾ Complete results saved to: final_enhanced_results_calls.csv\n",
            "\n",
            "================================================================================\n",
            "ANALYSIS COMPLETE!\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Reality Check:\n",
        "Only 6 out of 37 sophisticated ML models (16.2%) managed to beat a simple \"use last week's value\" forecast. This tells us your call volume data has extremely strong weekly seasonal patterns that are difficult for machine learning to improve upon.\n",
        "What This Means:\n",
        "\n",
        "Your 7-day seasonal pattern is so consistent that most advanced algorithms can't add value\n",
        "The seasonal baseline (MAE: 767.60) is actually quite good for this type of data\n",
        "ExtraTrees models and LightGBM are the only algorithms consistently finding patterns beyond seasonality\n",
        "\n",
        "Model Type Insights:\n",
        "\n",
        "Tree models performed best (3/9 success rate) - they can capture non-linear seasonal interactions\n",
        "LightGBM was effective (2/3 success rate) - good at handling seasonal features\n",
        "All linear models failed (0/12) - suggests non-linear patterns in the data\n",
        "Neural networks performed terribly - likely overfitting on the complex seasonal patterns\n",
        "XGBoost surprisingly failed despite usually being strong for time series\n",
        "\n",
        "Practical Recommendations:\n",
        "\n",
        "Use ExtraTrees_50 as your production model (12.1% improvement is meaningful)\n",
        "Keep the seasonal baseline as a backup - it's surprisingly robust\n",
        "Consider ensemble approaches combining the top 3-4 tree models\n",
        "Focus on tree-based algorithms for future improvements rather than linear or neural approaches\n",
        "\n",
        "The fact that most models failed isn't a failure of your analysis - it's valuable intelligence showing that your call patterns are highly predictable seasonally, and simple methods work well for this use case."
      ],
      "metadata": {
        "id": "9xJ4QE0QJR0O"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}