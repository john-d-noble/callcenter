{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/john-d-noble/callcenter/blob/main/CX_CB_ML_Implementation_(Random_Forest%2C_XGBoost%2C_LightGBM%2C_CatBoost%2C_LSTM%2C_GRU%2C_Prophet).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cabfdabe",
      "metadata": {
        "id": "cabfdabe"
      },
      "source": [
        "\n",
        "# Call Center ML Forecasting Pipeline - Phase 4\n",
        "## Properly Cell-Structured Implementation\n",
        "\n",
        "This notebook implements 7 ML models with proper cell structure for easy debugging and rerunning.\n",
        "- All previous bugs fixed\n",
        "- Checkpointing enabled\n",
        "- GPU optimized\n",
        "- 70+ features including holidays and market data\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "        !nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KTmvWcH1BwF",
        "outputId": "10233551-d336-4865-c5d2-5f2f5b859dc4"
      },
      "id": "0KTmvWcH1BwF",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Sep 19 21:27:06 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check if CUDA (GPU) is available\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Using CPU\")\n",
        "\n",
        "# Example: Move a tensor to the GPU\n",
        "x = torch.randn(10, 10).to(device)\n",
        "\n",
        "# Example: Move a model to the GPU\n",
        "# model = YourModel().to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CtWi2TK1CEx",
        "outputId": "ab491708-1d0c-4c2b-a618-0b92da7027d4"
      },
      "id": "7CtWi2TK1CEx",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e9a4b2da",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9a4b2da",
        "outputId": "d585cea0-9415-447c-d45f-89f35cb21d4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.12/dist-packages (1.2.8)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.12/dist-packages (4.5.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.16.5)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.12/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.43)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (8.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "âœ… GPU Available: 1 GPU(s) detected\n",
            "âœ… All libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\"\"\"\n",
        "Cell 1: Import all required libraries and configure GPU\n",
        "\"\"\"\n",
        "\n",
        "!pip install catboost optuna\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Core libraries\n",
        "from datetime import datetime, timedelta\n",
        "import json\n",
        "import pickle\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "import holidays\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "\n",
        "# ML Libraries\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "# Gradient Boosting\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from catboost import CatBoostRegressor\n",
        "\n",
        "# Deep Learning\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Prophet\n",
        "from prophet import Prophet\n",
        "\n",
        "# Hyperparameter tuning\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import optuna\n",
        "\n",
        "# Configure GPU\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(f\"âœ… GPU Available: {len(gpus)} GPU(s) detected\")\n",
        "    except RuntimeError as e:\n",
        "        print(f\"âš ï¸ GPU initialization error: {e}\")\n",
        "else:\n",
        "    print(\"âš ï¸ No GPU detected, using CPU\")\n",
        "\n",
        "# Set seeds\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "print(\"âœ… All libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "49b16c90",
      "metadata": {
        "id": "49b16c90"
      },
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "Cell 2: Define data loading function\n",
        "\"\"\"\n",
        "def load_call_center_data_v1_expanded(file_path='enhanced_eda_data.csv'):\n",
        "    \"\"\"\n",
        "    Load call center data with market integration\n",
        "    \"\"\"\n",
        "    print(\"ðŸ“ LOADING CALL CENTER DATA\")\n",
        "    print(\"=\" * 45)\n",
        "\n",
        "    try:\n",
        "        # Load main data file\n",
        "        df = pd.read_csv(file_path, index_col='Date', parse_dates=True)\n",
        "        print(f\"âœ… Loaded {len(df)} records from {file_path}\")\n",
        "\n",
        "        # Auto-detect call volume column\n",
        "        volume_cols = ['calls', 'Calls', 'call_volume', 'Call_Volume', 'volume', 'Volume']\n",
        "        volume_col = None\n",
        "\n",
        "        for col in volume_cols:\n",
        "            if col in df.columns:\n",
        "                volume_col = col\n",
        "                break\n",
        "\n",
        "        if volume_col is None:\n",
        "            numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "            volume_col = numeric_cols[0] if len(numeric_cols) > 0 else df.columns[0]\n",
        "\n",
        "        print(f\"ðŸŽ¯ Call volume column: {volume_col}\")\n",
        "\n",
        "        # Standardize column name\n",
        "        if volume_col != 'calls':\n",
        "            df = df.rename(columns={volume_col: 'calls'})\n",
        "\n",
        "        # DATA CLEANING: Remove first and last rows\n",
        "        print(\"ðŸ§¹ DATA CLEANING: Removing first and last rows\")\n",
        "        original_len = len(df)\n",
        "        if len(df) > 2:\n",
        "            df = df.iloc[1:-1]\n",
        "            print(f\"   âœ… Cleaned: {original_len} â†’ {len(df)} rows\")\n",
        "\n",
        "        # Market data integration\n",
        "        expected_market_cols = [\n",
        "            '^VIX_close', 'SPY_close', 'SPY_volume', 'QQQ_close', 'QQQ_volume',\n",
        "            'DX-Y.NYB_close', 'GC=F_close', 'GC=F_volume', 'BTC-USD_close',\n",
        "            'BTC-USD_volume', 'ETH-USD_close', 'ETH-USD_volume'\n",
        "        ]\n",
        "\n",
        "        existing_market_cols = [col for col in expected_market_cols if col in df.columns]\n",
        "\n",
        "        if existing_market_cols:\n",
        "            print(f\"âœ… Market data found: {len(existing_market_cols)} columns\")\n",
        "\n",
        "            # Enhanced market features\n",
        "            if '^VIX_close' in df.columns:\n",
        "                df['vix_high'] = (df['^VIX_close'] > df['^VIX_close'].quantile(0.8)).astype(int)\n",
        "                df['vix_spike'] = (df['^VIX_close'].pct_change() > 0.2).astype(int)\n",
        "                df['vix_returns'] = df['^VIX_close'].pct_change()\n",
        "                df['vix_volatility'] = df['vix_returns'].rolling(7).std()\n",
        "\n",
        "            if 'SPY_close' in df.columns:\n",
        "                df['spy_returns'] = df['SPY_close'].pct_change()\n",
        "                df['market_stress'] = (df['spy_returns'] < -0.02).astype(int)\n",
        "                df['spy_volatility'] = df['spy_returns'].rolling(7).std()\n",
        "                df['spy_momentum'] = df['SPY_close'].rolling(5).mean() / df['SPY_close'].rolling(20).mean()\n",
        "\n",
        "            if 'BTC-USD_close' in df.columns:\n",
        "                df['btc_returns'] = df['BTC-USD_close'].pct_change()\n",
        "                df['crypto_volatility'] = df['btc_returns'].rolling(7).std()\n",
        "                df['btc_extreme_move'] = (abs(df['btc_returns']) > 0.1).astype(int)\n",
        "\n",
        "        print(f\"\\nðŸ“Š FINAL DATASET OVERVIEW\")\n",
        "        print(f\"   Date range: {df.index.min().strftime('%Y-%m-%d')} to {df.index.max().strftime('%Y-%m-%d')}\")\n",
        "        print(f\"   Total days: {len(df)}\")\n",
        "        print(f\"   Call volume range: {df['calls'].min():.0f} to {df['calls'].max():.0f}\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error loading data: {e}\")\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f933c2f2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f933c2f2",
        "outputId": "a0c59fc9-2397-4bc7-ac19-f86242b4c604"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ LOADING CALL CENTER DATA\n",
            "=============================================\n",
            "âœ… Loaded 978 records from enhanced_eda_data.csv\n",
            "ðŸŽ¯ Call volume column: calls\n",
            "ðŸ§¹ DATA CLEANING: Removing first and last rows\n",
            "   âœ… Cleaned: 978 â†’ 976 rows\n",
            "âœ… Market data found: 12 columns\n",
            "\n",
            "ðŸ“Š FINAL DATASET OVERVIEW\n",
            "   Date range: 2023-01-02 to 2025-09-03\n",
            "   Total days: 976\n",
            "   Call volume range: 3462 to 24724\n",
            "âœ… Data loaded successfully! Shape: (976, 30)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\"\"\"\n",
        "Cell 3: Load the actual data\n",
        "\"\"\"\n",
        "df = load_call_center_data_v1_expanded('enhanced_eda_data.csv')\n",
        "\n",
        "if df is None:\n",
        "    print(\"âš ï¸ ERROR: Could not load data!\")\n",
        "    print(\"Please ensure 'enhanced_eda_data.csv' exists in the current directory.\")\n",
        "else:\n",
        "    print(f\"âœ… Data loaded successfully! Shape: {df.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7101e3d3",
      "metadata": {
        "id": "7101e3d3"
      },
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "Cell 4: Define feature engineering function\n",
        "\"\"\"\n",
        "def create_features(df: pd.DataFrame, target_col: str = 'calls',\n",
        "                    country: str = 'US', state: str = None) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Create comprehensive features for ML models\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # Handle Date index/column ambiguity - FIXED VERSION\n",
        "    if df.index.name == 'Date' and 'Date' in df.columns:\n",
        "        df = df.drop(columns=['Date']).reset_index()\n",
        "    elif df.index.name == 'Date':\n",
        "        df = df.reset_index()\n",
        "    elif 'Date' not in df.columns:\n",
        "        raise ValueError(\"No Date column or index found\")\n",
        "\n",
        "    df['Date'] = pd.to_datetime(df['Date'])\n",
        "    df = df.sort_values('Date').reset_index(drop=True)\n",
        "\n",
        "    # Basic temporal features\n",
        "    df['year'] = df['Date'].dt.year\n",
        "    df['month'] = df['Date'].dt.month\n",
        "    df['day'] = df['Date'].dt.day\n",
        "    df['dayofweek'] = df['Date'].dt.dayofweek\n",
        "    df['quarter'] = df['Date'].dt.quarter\n",
        "    df['dayofyear'] = df['Date'].dt.dayofyear\n",
        "    df['weekofyear'] = df['Date'].dt.isocalendar().week\n",
        "    df['is_weekend'] = (df['dayofweek'] >= 5).astype(int)\n",
        "    df['is_month_start'] = df['Date'].dt.is_month_start.astype(int)\n",
        "    df['is_month_end'] = df['Date'].dt.is_month_end.astype(int)\n",
        "\n",
        "    # Cyclical encoding\n",
        "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
        "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
        "    df['day_sin'] = np.sin(2 * np.pi * df['day'] / 31)\n",
        "    df['day_cos'] = np.cos(2 * np.pi * df['day'] / 31)\n",
        "    df['dayofweek_sin'] = np.sin(2 * np.pi * df['dayofweek'] / 7)\n",
        "    df['dayofweek_cos'] = np.cos(2 * np.pi * df['dayofweek'] / 7)\n",
        "\n",
        "    # Holiday features\n",
        "    print(\"ðŸ—“ï¸ Adding holiday features...\")\n",
        "    years = df['Date'].dt.year.unique()\n",
        "\n",
        "    if country == 'US':\n",
        "        holiday_list = holidays.US(state=state, years=years.tolist()) if state else holidays.US(years=years.tolist())\n",
        "    else:\n",
        "        holiday_list = holidays.CountryHoliday(country, years=years.tolist())\n",
        "\n",
        "    df['is_holiday'] = df['Date'].dt.date.isin(holiday_list.keys()).astype(int)\n",
        "\n",
        "    holiday_dates = pd.to_datetime(list(holiday_list.keys()))\n",
        "\n",
        "    def days_to_nearest_holiday(date):\n",
        "        if len(holiday_dates) == 0:\n",
        "            return 999\n",
        "        return min(abs((date - holiday_dates).days).min(), 30)\n",
        "\n",
        "    df['days_to_nearest_holiday'] = df['Date'].apply(days_to_nearest_holiday)\n",
        "\n",
        "    print(f\"   âœ… Added {df['is_holiday'].sum()} holidays\")\n",
        "\n",
        "    # Lag features\n",
        "    lag_features = [1, 2, 3, 7, 14, 21, 28, 30, 60, 90]\n",
        "    for lag in lag_features:\n",
        "        df[f'lag_{lag}'] = df[target_col].shift(lag)\n",
        "\n",
        "    # Rolling window statistics\n",
        "    rolling_windows = [7, 14, 21, 28, 60, 90]\n",
        "    for window in rolling_windows:\n",
        "        df[f'rolling_mean_{window}'] = df[target_col].shift(1).rolling(window=window, min_periods=1).mean()\n",
        "        df[f'rolling_std_{window}'] = df[target_col].shift(1).rolling(window=window, min_periods=1).std()\n",
        "        df[f'rolling_min_{window}'] = df[target_col].shift(1).rolling(window=window, min_periods=1).min()\n",
        "        df[f'rolling_max_{window}'] = df[target_col].shift(1).rolling(window=window, min_periods=1).max()\n",
        "\n",
        "    # Expanding features\n",
        "    df['expanding_mean'] = df[target_col].shift(1).expanding(min_periods=1).mean()\n",
        "    df['expanding_std'] = df[target_col].shift(1).expanding(min_periods=1).std()\n",
        "\n",
        "    # Difference features\n",
        "    df['diff_1'] = df[target_col].diff(1)\n",
        "    df['diff_7'] = df[target_col].diff(7)\n",
        "    df['diff_30'] = df[target_col].diff(30)\n",
        "\n",
        "    # Trend features\n",
        "    df['days_since_start'] = (df['Date'] - df['Date'].min()).dt.days\n",
        "\n",
        "    # Interaction features\n",
        "    df['dayofweek_month'] = df['dayofweek'] * df['month']\n",
        "    df['is_weekend_month'] = df['is_weekend'] * df['month']\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "5b1b9ee5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b1b9ee5",
        "outputId": "ded46275-565e-4d60-9d21-73568b2080e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ—“ï¸ Adding holiday features...\n",
            "   âœ… Added 30 holidays\n",
            "âœ… Features created. Shape: (976, 90)\n",
            "Total features: 88\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\"\"\"\n",
        "Cell 5: Create features\n",
        "\"\"\"\n",
        "df_features = create_features(df, target_col='calls', country='US', state=None)\n",
        "print(f\"âœ… Features created. Shape: {df_features.shape}\")\n",
        "print(f\"Total features: {len([col for col in df_features.columns if col not in ['Date', 'calls']])}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6eca6430",
      "metadata": {
        "id": "6eca6430"
      },
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "Cell 6: Define train/test split function\n",
        "\"\"\"\n",
        "def prepare_train_test_split(df: pd.DataFrame,\n",
        "                             test_size: int = 180,\n",
        "                             target_col: str = 'calls') -> Tuple:\n",
        "    \"\"\"\n",
        "    Prepare train/test split matching previous time series work\n",
        "    \"\"\"\n",
        "    # Remove NaN values\n",
        "    df_clean = df.dropna()\n",
        "\n",
        "    # Split data\n",
        "    train_size = len(df_clean) - test_size\n",
        "\n",
        "    train_data = df_clean.iloc[:train_size].copy()\n",
        "    test_data = df_clean.iloc[train_size:].copy()\n",
        "\n",
        "    # Prepare features and targets\n",
        "    feature_cols = [col for col in df_clean.columns if col not in ['Date', target_col]]\n",
        "\n",
        "    X_train = train_data[feature_cols]\n",
        "    y_train = train_data[target_col]\n",
        "    X_test = test_data[feature_cols]\n",
        "    y_test = test_data[target_col]\n",
        "\n",
        "    # Store dates for plotting\n",
        "    train_dates = train_data['Date']\n",
        "    test_dates = test_data['Date']\n",
        "\n",
        "    print(f\"Train shape: X={X_train.shape}, y={y_train.shape}\")\n",
        "    print(f\"Test shape: X={X_test.shape}, y={y_test.shape}\")\n",
        "    print(f\"Train period: {train_dates.min()} to {train_dates.max()}\")\n",
        "    print(f\"Test period: {test_dates.min()} to {test_dates.max()}\")\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, train_dates, test_dates\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "41505dd1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41505dd1",
        "outputId": "4a092d59-a537-4334-90c3-1afb06d63e34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: X=(706, 88), y=(706,)\n",
            "Test shape: X=(180, 88), y=(180,)\n",
            "Train period: 2023-04-02 00:00:00 to 2025-03-07 00:00:00\n",
            "Test period: 2025-03-08 00:00:00 to 2025-09-03 00:00:00\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\"\"\"\n",
        "Cell 7: Create train/test split\n",
        "\"\"\"\n",
        "X_train, X_test, y_train, y_test, train_dates, test_dates = prepare_train_test_split(df_features, test_size=180)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "6d18e525",
      "metadata": {
        "id": "6d18e525"
      },
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "Cell 8: Define the main ML forecasting pipeline class\n",
        "\"\"\"\n",
        "class MLForecastingPipeline:\n",
        "    \"\"\"Comprehensive ML forecasting pipeline\"\"\"\n",
        "\n",
        "    def __init__(self, X_train, X_test, y_train, y_test, train_dates=None, test_dates=None):\n",
        "        self.X_train = X_train\n",
        "        self.X_test = X_test\n",
        "        self.y_train = y_train\n",
        "        self.y_test = y_test\n",
        "        self.train_dates = train_dates  # Fixed: Added dates\n",
        "        self.test_dates = test_dates    # Fixed: Added dates\n",
        "        self.models = {}\n",
        "        self.predictions = {}\n",
        "        self.metrics = {}\n",
        "        self.best_params = {}\n",
        "\n",
        "        # Scalers for neural networks\n",
        "        self.scaler_X = StandardScaler()\n",
        "        self.scaler_y = MinMaxScaler()\n",
        "\n",
        "    def calculate_metrics(self, y_true, y_pred, model_name):\n",
        "        \"\"\"Calculate comprehensive metrics\"\"\"\n",
        "        mae = mean_absolute_error(y_true, y_pred)\n",
        "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "        mape = mean_absolute_percentage_error(y_true, y_pred) * 100\n",
        "\n",
        "        return {\n",
        "            'Model': model_name,\n",
        "            'MAE': mae,\n",
        "            'RMSE': rmse,\n",
        "            'MAPE': mape,\n",
        "            'R2': 1 - (np.sum((y_true - y_pred) ** 2) / np.sum((y_true - y_true.mean()) ** 2))\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "12d3f301",
      "metadata": {
        "id": "12d3f301"
      },
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "Cell 9: Add Random Forest training method to pipeline\n",
        "\"\"\"\n",
        "def train_random_forest(self, tune_hyperparams=True):\n",
        "    \"\"\"Train Random Forest with optional hyperparameter tuning\"\"\"\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"Training Random Forest...\")\n",
        "\n",
        "    if tune_hyperparams:\n",
        "        param_dist = {\n",
        "            'n_estimators': [100, 200, 300],\n",
        "            'max_depth': [10, 20, 30, None],\n",
        "            'min_samples_split': [2, 5, 10],\n",
        "            'min_samples_leaf': [1, 2, 4]\n",
        "        }\n",
        "\n",
        "        rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
        "        tscv = TimeSeriesSplit(n_splits=3)\n",
        "\n",
        "        rf_search = RandomizedSearchCV(\n",
        "            rf, param_dist, n_iter=10, cv=tscv,\n",
        "            scoring='neg_mean_absolute_error',\n",
        "            random_state=42, n_jobs=-1\n",
        "        )\n",
        "        rf_search.fit(self.X_train, self.y_train)\n",
        "\n",
        "        self.models['RandomForest'] = rf_search.best_estimator_\n",
        "        self.best_params['RandomForest'] = rf_search.best_params_\n",
        "        print(f\"Best params: {rf_search.best_params_}\")\n",
        "    else:\n",
        "        self.models['RandomForest'] = RandomForestRegressor(\n",
        "            n_estimators=200, max_depth=20, random_state=42, n_jobs=-1\n",
        "        )\n",
        "        self.models['RandomForest'].fit(self.X_train, self.y_train)\n",
        "\n",
        "    self.predictions['RandomForest'] = self.models['RandomForest'].predict(self.X_test)\n",
        "    self.metrics['RandomForest'] = self.calculate_metrics(\n",
        "        self.y_test, self.predictions['RandomForest'], 'RandomForest'\n",
        "    )\n",
        "    print(f\"RandomForest MAE: {self.metrics['RandomForest']['MAE']:.2f}\")\n",
        "\n",
        "# Attach method to class\n",
        "MLForecastingPipeline.train_random_forest = train_random_forest\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "38b2de54",
      "metadata": {
        "id": "38b2de54"
      },
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "Cell 10: Add XGBoost training method\n",
        "\"\"\"\n",
        "def train_xgboost(self, tune_hyperparams=True):\n",
        "    \"\"\"Train XGBoost with optional hyperparameter tuning\"\"\"\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"Training XGBoost...\")\n",
        "\n",
        "    if tune_hyperparams:\n",
        "        def objective(trial):\n",
        "            params = {\n",
        "                'n_estimators': trial.suggest_int('n_estimators', 100, 300),\n",
        "                'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
        "                'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
        "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
        "            }\n",
        "\n",
        "            model = xgb.XGBRegressor(**params, random_state=42)\n",
        "\n",
        "            tscv = TimeSeriesSplit(n_splits=3)\n",
        "            scores = []\n",
        "            for train_idx, val_idx in tscv.split(self.X_train):\n",
        "                X_fold_train = self.X_train.iloc[train_idx]\n",
        "                y_fold_train = self.y_train.iloc[train_idx]\n",
        "                X_fold_val = self.X_train.iloc[val_idx]\n",
        "                y_fold_val = self.y_train.iloc[val_idx]\n",
        "\n",
        "                model.fit(X_fold_train, y_fold_train, eval_set=[(X_fold_val, y_fold_val)],\n",
        "                          verbose=False)\n",
        "                pred = model.predict(X_fold_val)\n",
        "                scores.append(mean_absolute_error(y_fold_val, pred))\n",
        "\n",
        "            return np.mean(scores)\n",
        "\n",
        "        study = optuna.create_study(direction='minimize')\n",
        "        optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "        study.optimize(objective, n_trials=10, show_progress_bar=False)\n",
        "\n",
        "        self.best_params['XGBoost'] = study.best_params\n",
        "        self.models['XGBoost'] = xgb.XGBRegressor(**study.best_params, random_state=42)\n",
        "        self.models['XGBoost'].fit(self.X_train, self.y_train)\n",
        "        print(f\"Best params: {study.best_params}\")\n",
        "    else:\n",
        "        self.models['XGBoost'] = xgb.XGBRegressor(\n",
        "            n_estimators=200, max_depth=6, learning_rate=0.1, random_state=42\n",
        "        )\n",
        "        self.models['XGBoost'].fit(self.X_train, self.y_train)\n",
        "\n",
        "    self.predictions['XGBoost'] = self.models['XGBoost'].predict(self.X_test)\n",
        "    self.metrics['XGBoost'] = self.calculate_metrics(\n",
        "        self.y_test, self.predictions['XGBoost'], 'XGBoost'\n",
        "    )\n",
        "    print(f\"XGBoost MAE: {self.metrics['XGBoost']['MAE']:.2f}\")\n",
        "\n",
        "MLForecastingPipeline.train_xgboost = train_xgboost\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "5d367190",
      "metadata": {
        "id": "5d367190"
      },
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "Cell 11: Add LightGBM training method\n",
        "\"\"\"\n",
        "def train_lightgbm(self, tune_hyperparams=True):\n",
        "    \"\"\"Train LightGBM with optional hyperparameter tuning\"\"\"\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"Training LightGBM...\")\n",
        "\n",
        "    if tune_hyperparams:\n",
        "        def objective(trial):\n",
        "            params = {\n",
        "                'n_estimators': trial.suggest_int('n_estimators', 100, 300),\n",
        "                'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
        "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
        "                'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
        "            }\n",
        "\n",
        "            model = lgb.LGBMRegressor(**params, random_state=42, verbose=-1)\n",
        "\n",
        "            tscv = TimeSeriesSplit(n_splits=3)\n",
        "            scores = []\n",
        "            for train_idx, val_idx in tscv.split(self.X_train):\n",
        "                model.fit(self.X_train.iloc[train_idx], self.y_train.iloc[train_idx])\n",
        "                pred = model.predict(self.X_train.iloc[val_idx])\n",
        "                scores.append(mean_absolute_error(self.y_train.iloc[val_idx], pred))\n",
        "\n",
        "            return np.mean(scores)\n",
        "\n",
        "        study = optuna.create_study(direction='minimize')\n",
        "        optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "        study.optimize(objective, n_trials=10)\n",
        "\n",
        "        self.best_params['LightGBM'] = study.best_params\n",
        "        self.models['LightGBM'] = lgb.LGBMRegressor(**study.best_params, random_state=42, verbose=-1)\n",
        "        self.models['LightGBM'].fit(self.X_train, self.y_train)\n",
        "        print(f\"Best params: {study.best_params}\")\n",
        "    else:\n",
        "        self.models['LightGBM'] = lgb.LGBMRegressor(\n",
        "            n_estimators=200, max_depth=10, learning_rate=0.1, random_state=42, verbose=-1\n",
        "        )\n",
        "        self.models['LightGBM'].fit(self.X_train, self.y_train)\n",
        "\n",
        "    self.predictions['LightGBM'] = self.models['LightGBM'].predict(self.X_test)\n",
        "    self.metrics['LightGBM'] = self.calculate_metrics(\n",
        "        self.y_test, self.predictions['LightGBM'], 'LightGBM'\n",
        "    )\n",
        "    print(f\"LightGBM MAE: {self.metrics['LightGBM']['MAE']:.2f}\")\n",
        "\n",
        "MLForecastingPipeline.train_lightgbm = train_lightgbm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "9cb2ac05",
      "metadata": {
        "id": "9cb2ac05"
      },
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "Cell 12: Add CatBoost training method\n",
        "\"\"\"\n",
        "def train_catboost(self, tune_hyperparams=True):\n",
        "    \"\"\"Train CatBoost with optional hyperparameter tuning\"\"\"\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"Training CatBoost...\")\n",
        "\n",
        "    cat_features = ['dayofweek', 'month', 'quarter', 'is_weekend', 'is_holiday']\n",
        "    cat_indices = [self.X_train.columns.get_loc(col) for col in cat_features\n",
        "                   if col in self.X_train.columns]\n",
        "\n",
        "    if tune_hyperparams:\n",
        "        def objective(trial):\n",
        "            params = {\n",
        "                'iterations': trial.suggest_int('iterations', 100, 300),\n",
        "                'depth': trial.suggest_int('depth', 4, 10),\n",
        "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
        "            }\n",
        "\n",
        "            model = CatBoostRegressor(**params, random_state=42, verbose=False)\n",
        "\n",
        "            tscv = TimeSeriesSplit(n_splits=3)\n",
        "            scores = []\n",
        "            for train_idx, val_idx in tscv.split(self.X_train):\n",
        "                model.fit(self.X_train.iloc[train_idx], self.y_train.iloc[train_idx], cat_features=cat_indices)\n",
        "                pred = model.predict(self.X_train.iloc[val_idx])\n",
        "                scores.append(mean_absolute_error(self.y_train.iloc[val_idx], pred))\n",
        "\n",
        "            return np.mean(scores)\n",
        "\n",
        "        study = optuna.create_study(direction='minimize')\n",
        "        optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "        study.optimize(objective, n_trials=10)\n",
        "\n",
        "        self.best_params['CatBoost'] = study.best_params\n",
        "        self.models['CatBoost'] = CatBoostRegressor(**study.best_params, random_state=42, verbose=False)\n",
        "        self.models['CatBoost'].fit(self.X_train, self.y_train, cat_features=cat_indices)\n",
        "        print(f\"Best params: {study.best_params}\")\n",
        "    else:\n",
        "        self.models['CatBoost'] = CatBoostRegressor(\n",
        "            iterations=200, depth=6, learning_rate=0.1, random_state=42, verbose=False\n",
        "        )\n",
        "        self.models['CatBoost'].fit(self.X_train, self.y_train, cat_features=cat_indices)\n",
        "\n",
        "    self.predictions['CatBoost'] = self.models['CatBoost'].predict(self.X_test)\n",
        "    self.metrics['CatBoost'] = self.calculate_metrics(\n",
        "        self.y_test, self.predictions['CatBoost'], 'CatBoost'\n",
        "    )\n",
        "    print(f\"CatBoost MAE: {self.metrics['CatBoost']['MAE']:.2f}\")\n",
        "\n",
        "MLForecastingPipeline.train_catboost = train_catboost\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "421de91e",
      "metadata": {
        "id": "421de91e"
      },
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "Cell 13: Add LSTM training method with sequence optimization\n",
        "\"\"\"\n",
        "def prepare_sequences(self, X, y, sequence_length=30):\n",
        "    \"\"\"Prepare sequences for LSTM/GRU models\"\"\"\n",
        "    X_scaled = self.scaler_X.fit_transform(X)\n",
        "    y_scaled = self.scaler_y.fit_transform(y.values.reshape(-1, 1)).flatten()\n",
        "\n",
        "    X_seq, y_seq = [], []\n",
        "    for i in range(sequence_length, len(X_scaled)):\n",
        "        X_seq.append(X_scaled[i-sequence_length:i])\n",
        "        y_seq.append(y_scaled[i])\n",
        "\n",
        "    return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "def train_lstm(self, tune_hyperparams=False):\n",
        "    \"\"\"Train LSTM model\"\"\"\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"Training LSTM...\")\n",
        "    print(\"ðŸš€ Using GPU\" if len(tf.config.list_physical_devices('GPU')) > 0 else \"Using CPU\")\n",
        "\n",
        "    sequence_length = 30  # Fixed for simplicity\n",
        "\n",
        "    # Prepare sequences\n",
        "    X_train_seq, y_train_seq = self.prepare_sequences(self.X_train, self.y_train, sequence_length)\n",
        "\n",
        "    # Prepare test sequences\n",
        "    X_combined = pd.concat([self.X_train, self.X_test])\n",
        "    y_combined = pd.concat([self.y_train, self.y_test])\n",
        "\n",
        "    X_combined_scaled = self.scaler_X.fit_transform(X_combined)\n",
        "\n",
        "    test_start_idx = len(self.X_train)\n",
        "\n",
        "    X_test_seq = []\n",
        "    for i in range(test_start_idx, len(X_combined_scaled)):\n",
        "        if i >= sequence_length:\n",
        "            X_test_seq.append(X_combined_scaled[i-sequence_length:i])\n",
        "\n",
        "    X_test_seq = np.array(X_test_seq)\n",
        "\n",
        "    # Build model\n",
        "    model = Sequential([\n",
        "        LSTM(64, return_sequences=True, input_shape=(X_train_seq.shape[1], X_train_seq.shape[2])),\n",
        "        Dropout(0.2),\n",
        "        LSTM(32),\n",
        "        Dropout(0.2),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1)\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
        "\n",
        "    early_stop = EarlyStopping(patience=10, restore_best_weights=True, verbose=0)\n",
        "\n",
        "    model.fit(\n",
        "        X_train_seq, y_train_seq,\n",
        "        epochs=50,\n",
        "        batch_size=32,\n",
        "        validation_split=0.2,\n",
        "        callbacks=[early_stop],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    self.models['LSTM'] = model\n",
        "\n",
        "    # Predictions\n",
        "    lstm_pred_scaled = model.predict(X_test_seq, verbose=0)\n",
        "    lstm_pred = self.scaler_y.inverse_transform(lstm_pred_scaled).flatten()\n",
        "\n",
        "    y_test_aligned = self.y_test.iloc[-len(lstm_pred):].values\n",
        "\n",
        "    self.predictions['LSTM'] = lstm_pred\n",
        "    self.metrics['LSTM'] = self.calculate_metrics(y_test_aligned, lstm_pred, 'LSTM')\n",
        "    print(f\"LSTM MAE: {self.metrics['LSTM']['MAE']:.2f}\")\n",
        "\n",
        "    self.y_test_lstm = y_test_aligned\n",
        "\n",
        "MLForecastingPipeline.prepare_sequences = prepare_sequences\n",
        "MLForecastingPipeline.train_lstm = train_lstm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "c9cf38bf",
      "metadata": {
        "id": "c9cf38bf"
      },
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "Cell 14: Add GRU training method\n",
        "\"\"\"\n",
        "def train_gru(self, tune_hyperparams=False):\n",
        "    \"\"\"Train GRU model\"\"\"\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"Training GRU...\")\n",
        "    print(\"ðŸš€ Using GPU\" if len(tf.config.list_physical_devices('GPU')) > 0 else \"Using CPU\")\n",
        "\n",
        "    sequence_length = 30\n",
        "\n",
        "    # Prepare sequences\n",
        "    X_train_seq, y_train_seq = self.prepare_sequences(self.X_train, self.y_train, sequence_length)\n",
        "\n",
        "    # Prepare test sequences\n",
        "    X_combined = pd.concat([self.X_train, self.X_test])\n",
        "    X_combined_scaled = self.scaler_X.fit_transform(X_combined)\n",
        "\n",
        "    test_start_idx = len(self.X_train)\n",
        "\n",
        "    X_test_seq = []\n",
        "    for i in range(test_start_idx, len(X_combined_scaled)):\n",
        "        if i >= sequence_length:\n",
        "            X_test_seq.append(X_combined_scaled[i-sequence_length:i])\n",
        "\n",
        "    X_test_seq = np.array(X_test_seq)\n",
        "\n",
        "    # Build model\n",
        "    model = Sequential([\n",
        "        GRU(64, return_sequences=True, input_shape=(X_train_seq.shape[1], X_train_seq.shape[2])),\n",
        "        Dropout(0.2),\n",
        "        GRU(32),\n",
        "        Dropout(0.2),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1)\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
        "\n",
        "    early_stop = EarlyStopping(patience=10, restore_best_weights=True, verbose=0)\n",
        "\n",
        "    model.fit(\n",
        "        X_train_seq, y_train_seq,\n",
        "        epochs=50,\n",
        "        batch_size=32,\n",
        "        validation_split=0.2,\n",
        "        callbacks=[early_stop],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    self.models['GRU'] = model\n",
        "\n",
        "    # Predictions\n",
        "    gru_pred_scaled = model.predict(X_test_seq, verbose=0)\n",
        "    gru_pred = self.scaler_y.inverse_transform(gru_pred_scaled).flatten()\n",
        "\n",
        "    y_test_aligned = self.y_test.iloc[-len(gru_pred):].values\n",
        "\n",
        "    self.predictions['GRU'] = gru_pred\n",
        "    self.metrics['GRU'] = self.calculate_metrics(y_test_aligned, gru_pred, 'GRU')\n",
        "    print(f\"GRU MAE: {self.metrics['GRU']['MAE']:.2f}\")\n",
        "\n",
        "    self.y_test_gru = y_test_aligned\n",
        "\n",
        "MLForecastingPipeline.train_gru = train_gru\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "697dce10",
      "metadata": {
        "id": "697dce10"
      },
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "Cell 15: Add Prophet training method - with all fixes applied\n",
        "\"\"\"\n",
        "def train_prophet(self, tune_hyperparams=False):\n",
        "    \"\"\"Train Prophet model - FIXED VERSION\"\"\"\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"Training Prophet...\")\n",
        "\n",
        "    # Prepare data for Prophet - FIXED: using self.train_dates\n",
        "    train_prophet = pd.DataFrame({\n",
        "        'ds': self.train_dates,\n",
        "        'y': self.y_train.values\n",
        "    })\n",
        "\n",
        "    # Suppress Prophet output\n",
        "    import logging\n",
        "    logging.getLogger('prophet').setLevel(logging.WARNING)\n",
        "    logging.getLogger('cmdstanpy').setLevel(logging.WARNING)\n",
        "\n",
        "    self.models['Prophet'] = Prophet(\n",
        "        changepoint_prior_scale=0.05,\n",
        "        seasonality_prior_scale=1.0,\n",
        "        daily_seasonality=False,\n",
        "        weekly_seasonality=True,\n",
        "        yearly_seasonality=True\n",
        "    )\n",
        "\n",
        "    # Fit model - FIXED: no verbose parameter\n",
        "    self.models['Prophet'].fit(train_prophet)\n",
        "\n",
        "    # Make predictions - FIXED: using self.test_dates\n",
        "    future = pd.DataFrame({'ds': self.test_dates})\n",
        "    forecast = self.models['Prophet'].predict(future)\n",
        "\n",
        "    self.predictions['Prophet'] = forecast['yhat'].values\n",
        "    self.metrics['Prophet'] = self.calculate_metrics(\n",
        "        self.y_test, self.predictions['Prophet'], 'Prophet'\n",
        "    )\n",
        "    print(f\"Prophet MAE: {self.metrics['Prophet']['MAE']:.2f}\")\n",
        "\n",
        "MLForecastingPipeline.train_prophet = train_prophet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "d1046463",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1046463",
        "outputId": "f1efd0a7-8ec3-4e14-d0b7-4f2b15795311"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Pipeline initialized successfully!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\"\"\"\n",
        "Cell 16: Initialize the ML pipeline with dates\n",
        "\"\"\"\n",
        "pipeline = MLForecastingPipeline(\n",
        "    X_train, X_test, y_train, y_test,\n",
        "    train_dates, test_dates  # Fixed: passing dates\n",
        ")\n",
        "print(\"âœ… Pipeline initialized successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "44fd9ecf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44fd9ecf",
        "outputId": "972b214f-3c8c-422f-ffaf-79c1044c376e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Training Random Forest...\n",
            "Best params: {'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': 10}\n",
            "RandomForest MAE: 193.39\n"
          ]
        }
      ],
      "source": [
        "pipeline.train_random_forest(tune_hyperparams=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "e688cf19",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e688cf19",
        "outputId": "0a5c39c5-92eb-4724-e944-6b7dcec559fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-09-19 21:28:59,305] A new study created in memory with name: no-name-ecfda0b0-ff95-4870-aea8-df6a566e941f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Training XGBoost...\n",
            "Best params: {'n_estimators': 249, 'max_depth': 6, 'learning_rate': 0.1098640499537224, 'subsample': 0.6816336126201117, 'colsample_bytree': 0.8922509087161615}\n",
            "XGBoost MAE: 184.71\n"
          ]
        }
      ],
      "source": [
        "pipeline.train_xgboost(tune_hyperparams=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "679d6633",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "679d6633",
        "outputId": "d14d9bdd-0d13-4fe4-f5b5-8fa0dca50dfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Training LightGBM...\n",
            "Best params: {'n_estimators': 255, 'max_depth': 3, 'learning_rate': 0.06708713270745811, 'num_leaves': 84}\n",
            "LightGBM MAE: 170.80\n"
          ]
        }
      ],
      "source": [
        "pipeline.train_lightgbm(tune_hyperparams=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "2b565334",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b565334",
        "outputId": "b25cca40-3c1d-4886-ef66-9a3657ff9e26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Training CatBoost...\n",
            "Best params: {'iterations': 170, 'depth': 5, 'learning_rate': 0.04173487655191767}\n",
            "CatBoost MAE: 291.12\n"
          ]
        }
      ],
      "source": [
        "pipeline.train_catboost(tune_hyperparams=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "9e8389e4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e8389e4",
        "outputId": "8737f7c3-0ed2-4e7f-c18d-dbb30565b60f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Tree models checkpoint saved!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\"\"\"\n",
        "Cell 21: Save checkpoint after tree models\n",
        "\"\"\"\n",
        "checkpoint = {\n",
        "    'models': pipeline.models.copy(),\n",
        "    'predictions': pipeline.predictions.copy(),\n",
        "    'metrics': pipeline.metrics.copy(),\n",
        "    'best_params': pipeline.best_params.copy()\n",
        "}\n",
        "\n",
        "with open('tree_models_checkpoint.pkl', 'wb') as f:\n",
        "    pickle.dump(checkpoint, f)\n",
        "print(\"âœ… Tree models checkpoint saved!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "a323d4c1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a323d4c1",
        "outputId": "ef2e802a-2df5-40bf-e700-1df4878c0578"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Training LSTM...\n",
            "ðŸš€ Using GPU\n",
            "Epoch 1/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - loss: 0.0775 - mae: 0.2088 - val_loss: 0.0487 - val_mae: 0.1756\n",
            "Epoch 2/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0158 - mae: 0.0972 - val_loss: 0.0533 - val_mae: 0.1841\n",
            "Epoch 3/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0131 - mae: 0.0874 - val_loss: 0.0480 - val_mae: 0.1716\n",
            "Epoch 4/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0130 - mae: 0.0876 - val_loss: 0.0509 - val_mae: 0.1768\n",
            "Epoch 5/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0103 - mae: 0.0794 - val_loss: 0.0431 - val_mae: 0.1632\n",
            "Epoch 6/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0099 - mae: 0.0768 - val_loss: 0.0438 - val_mae: 0.1640\n",
            "Epoch 7/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0087 - mae: 0.0723 - val_loss: 0.0453 - val_mae: 0.1654\n",
            "Epoch 8/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0085 - mae: 0.0689 - val_loss: 0.0442 - val_mae: 0.1643\n",
            "Epoch 9/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0074 - mae: 0.0650 - val_loss: 0.0451 - val_mae: 0.1646\n",
            "Epoch 10/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0082 - mae: 0.0698 - val_loss: 0.0452 - val_mae: 0.1650\n",
            "Epoch 11/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0076 - mae: 0.0673 - val_loss: 0.0448 - val_mae: 0.1651\n",
            "Epoch 12/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0067 - mae: 0.0621 - val_loss: 0.0438 - val_mae: 0.1619\n",
            "Epoch 13/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0071 - mae: 0.0645 - val_loss: 0.0414 - val_mae: 0.1569\n",
            "Epoch 14/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0054 - mae: 0.0579 - val_loss: 0.0431 - val_mae: 0.1600\n",
            "Epoch 15/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0049 - mae: 0.0549 - val_loss: 0.0462 - val_mae: 0.1642\n",
            "Epoch 16/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0054 - mae: 0.0559 - val_loss: 0.0466 - val_mae: 0.1664\n",
            "Epoch 17/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0053 - mae: 0.0552 - val_loss: 0.0433 - val_mae: 0.1610\n",
            "Epoch 18/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0046 - mae: 0.0530 - val_loss: 0.0418 - val_mae: 0.1551\n",
            "Epoch 19/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0053 - mae: 0.0560 - val_loss: 0.0357 - val_mae: 0.1428\n",
            "Epoch 20/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0046 - mae: 0.0510 - val_loss: 0.0352 - val_mae: 0.1422\n",
            "Epoch 21/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0048 - mae: 0.0530 - val_loss: 0.0315 - val_mae: 0.1351\n",
            "Epoch 22/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0047 - mae: 0.0522 - val_loss: 0.0323 - val_mae: 0.1376\n",
            "Epoch 23/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0041 - mae: 0.0508 - val_loss: 0.0335 - val_mae: 0.1389\n",
            "Epoch 24/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0037 - mae: 0.0480 - val_loss: 0.0332 - val_mae: 0.1382\n",
            "Epoch 25/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0039 - mae: 0.0480 - val_loss: 0.0316 - val_mae: 0.1346\n",
            "Epoch 26/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0038 - mae: 0.0476 - val_loss: 0.0308 - val_mae: 0.1324\n",
            "Epoch 27/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0035 - mae: 0.0449 - val_loss: 0.0279 - val_mae: 0.1268\n",
            "Epoch 28/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0034 - mae: 0.0450 - val_loss: 0.0253 - val_mae: 0.1220\n",
            "Epoch 29/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0035 - mae: 0.0451 - val_loss: 0.0258 - val_mae: 0.1257\n",
            "Epoch 30/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0037 - mae: 0.0461 - val_loss: 0.0305 - val_mae: 0.1359\n",
            "Epoch 31/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0034 - mae: 0.0446 - val_loss: 0.0288 - val_mae: 0.1281\n",
            "Epoch 32/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0034 - mae: 0.0434 - val_loss: 0.0273 - val_mae: 0.1259\n",
            "Epoch 33/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0030 - mae: 0.0411 - val_loss: 0.0295 - val_mae: 0.1349\n",
            "Epoch 34/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0031 - mae: 0.0402 - val_loss: 0.0300 - val_mae: 0.1348\n",
            "Epoch 35/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0031 - mae: 0.0398 - val_loss: 0.0273 - val_mae: 0.1235\n",
            "Epoch 36/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0025 - mae: 0.0383 - val_loss: 0.0244 - val_mae: 0.1169\n",
            "Epoch 37/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0031 - mae: 0.0397 - val_loss: 0.0276 - val_mae: 0.1231\n",
            "Epoch 38/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0027 - mae: 0.0376 - val_loss: 0.0253 - val_mae: 0.1218\n",
            "Epoch 39/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0028 - mae: 0.0384 - val_loss: 0.0225 - val_mae: 0.1120\n",
            "Epoch 40/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0024 - mae: 0.0353 - val_loss: 0.0232 - val_mae: 0.1138\n",
            "Epoch 41/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0026 - mae: 0.0381 - val_loss: 0.0223 - val_mae: 0.1109\n",
            "Epoch 42/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0022 - mae: 0.0342 - val_loss: 0.0224 - val_mae: 0.1137\n",
            "Epoch 43/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0030 - mae: 0.0397 - val_loss: 0.0207 - val_mae: 0.1063\n",
            "Epoch 44/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0023 - mae: 0.0367 - val_loss: 0.0194 - val_mae: 0.1024\n",
            "Epoch 45/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0023 - mae: 0.0356 - val_loss: 0.0194 - val_mae: 0.1046\n",
            "Epoch 46/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0023 - mae: 0.0367 - val_loss: 0.0187 - val_mae: 0.1024\n",
            "Epoch 47/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0025 - mae: 0.0338 - val_loss: 0.0197 - val_mae: 0.1030\n",
            "Epoch 48/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0023 - mae: 0.0344 - val_loss: 0.0188 - val_mae: 0.1007\n",
            "Epoch 49/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0020 - mae: 0.0338 - val_loss: 0.0206 - val_mae: 0.1068\n",
            "Epoch 50/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0021 - mae: 0.0340 - val_loss: 0.0181 - val_mae: 0.0984\n",
            "LSTM MAE: 2173.52\n"
          ]
        }
      ],
      "source": [
        "pipeline.train_lstm(tune_hyperparams=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "7bbb3754",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bbb3754",
        "outputId": "72051ffc-277e-4019-98fe-52e33fc28bd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Training GRU...\n",
            "ðŸš€ Using GPU\n",
            "Epoch 1/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.0913 - mae: 0.2369 - val_loss: 0.1132 - val_mae: 0.2995\n",
            "Epoch 2/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0289 - mae: 0.1365 - val_loss: 0.0899 - val_mae: 0.2640\n",
            "Epoch 3/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0243 - mae: 0.1198 - val_loss: 0.0535 - val_mae: 0.1967\n",
            "Epoch 4/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0199 - mae: 0.1102 - val_loss: 0.0492 - val_mae: 0.1903\n",
            "Epoch 5/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0120 - mae: 0.0873 - val_loss: 0.0391 - val_mae: 0.1678\n",
            "Epoch 6/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0134 - mae: 0.0890 - val_loss: 0.0326 - val_mae: 0.1534\n",
            "Epoch 7/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0129 - mae: 0.0861 - val_loss: 0.0286 - val_mae: 0.1404\n",
            "Epoch 8/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0107 - mae: 0.0800 - val_loss: 0.0310 - val_mae: 0.1485\n",
            "Epoch 9/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0112 - mae: 0.0819 - val_loss: 0.0331 - val_mae: 0.1537\n",
            "Epoch 10/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0097 - mae: 0.0754 - val_loss: 0.0368 - val_mae: 0.1637\n",
            "Epoch 11/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0086 - mae: 0.0731 - val_loss: 0.0335 - val_mae: 0.1520\n",
            "Epoch 12/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0075 - mae: 0.0691 - val_loss: 0.0407 - val_mae: 0.1705\n",
            "Epoch 13/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0089 - mae: 0.0768 - val_loss: 0.0383 - val_mae: 0.1666\n",
            "Epoch 14/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0087 - mae: 0.0703 - val_loss: 0.0352 - val_mae: 0.1603\n",
            "Epoch 15/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0074 - mae: 0.0665 - val_loss: 0.0274 - val_mae: 0.1378\n",
            "Epoch 16/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0065 - mae: 0.0633 - val_loss: 0.0300 - val_mae: 0.1460\n",
            "Epoch 17/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0064 - mae: 0.0625 - val_loss: 0.0337 - val_mae: 0.1570\n",
            "Epoch 18/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0063 - mae: 0.0608 - val_loss: 0.0291 - val_mae: 0.1407\n",
            "Epoch 19/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0069 - mae: 0.0637 - val_loss: 0.0309 - val_mae: 0.1476\n",
            "Epoch 20/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0056 - mae: 0.0587 - val_loss: 0.0238 - val_mae: 0.1278\n",
            "Epoch 21/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0060 - mae: 0.0590 - val_loss: 0.0228 - val_mae: 0.1246\n",
            "Epoch 22/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0061 - mae: 0.0601 - val_loss: 0.0226 - val_mae: 0.1219\n",
            "Epoch 23/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0065 - mae: 0.0607 - val_loss: 0.0267 - val_mae: 0.1327\n",
            "Epoch 24/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0053 - mae: 0.0568 - val_loss: 0.0233 - val_mae: 0.1248\n",
            "Epoch 25/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0059 - mae: 0.0598 - val_loss: 0.0268 - val_mae: 0.1341\n",
            "Epoch 26/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0050 - mae: 0.0550 - val_loss: 0.0229 - val_mae: 0.1256\n",
            "Epoch 27/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0047 - mae: 0.0516 - val_loss: 0.0187 - val_mae: 0.1112\n",
            "Epoch 28/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0047 - mae: 0.0522 - val_loss: 0.0223 - val_mae: 0.1228\n",
            "Epoch 29/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0043 - mae: 0.0489 - val_loss: 0.0232 - val_mae: 0.1272\n",
            "Epoch 30/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0036 - mae: 0.0469 - val_loss: 0.0178 - val_mae: 0.1116\n",
            "Epoch 31/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0043 - mae: 0.0501 - val_loss: 0.0188 - val_mae: 0.1126\n",
            "Epoch 32/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0043 - mae: 0.0505 - val_loss: 0.0151 - val_mae: 0.1014\n",
            "Epoch 33/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0040 - mae: 0.0470 - val_loss: 0.0143 - val_mae: 0.1008\n",
            "Epoch 34/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0036 - mae: 0.0451 - val_loss: 0.0118 - val_mae: 0.0908\n",
            "Epoch 35/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0037 - mae: 0.0476 - val_loss: 0.0090 - val_mae: 0.0795\n",
            "Epoch 36/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0034 - mae: 0.0446 - val_loss: 0.0078 - val_mae: 0.0738\n",
            "Epoch 37/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0038 - mae: 0.0473 - val_loss: 0.0087 - val_mae: 0.0778\n",
            "Epoch 38/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0038 - mae: 0.0445 - val_loss: 0.0104 - val_mae: 0.0846\n",
            "Epoch 39/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0037 - mae: 0.0449 - val_loss: 0.0095 - val_mae: 0.0795\n",
            "Epoch 40/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0032 - mae: 0.0430 - val_loss: 0.0084 - val_mae: 0.0768\n",
            "Epoch 41/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0038 - mae: 0.0448 - val_loss: 0.0080 - val_mae: 0.0750\n",
            "Epoch 42/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0028 - mae: 0.0421 - val_loss: 0.0070 - val_mae: 0.0692\n",
            "Epoch 43/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0033 - mae: 0.0444 - val_loss: 0.0066 - val_mae: 0.0676\n",
            "Epoch 44/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0034 - mae: 0.0412 - val_loss: 0.0053 - val_mae: 0.0597\n",
            "Epoch 45/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0028 - mae: 0.0417 - val_loss: 0.0054 - val_mae: 0.0596\n",
            "Epoch 46/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0032 - mae: 0.0422 - val_loss: 0.0061 - val_mae: 0.0640\n",
            "Epoch 47/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0029 - mae: 0.0401 - val_loss: 0.0057 - val_mae: 0.0615\n",
            "Epoch 48/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0028 - mae: 0.0399 - val_loss: 0.0056 - val_mae: 0.0620\n",
            "Epoch 49/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0025 - mae: 0.0391 - val_loss: 0.0053 - val_mae: 0.0604\n",
            "Epoch 50/50\n",
            "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0025 - mae: 0.0399 - val_loss: 0.0056 - val_mae: 0.0619\n",
            "GRU MAE: 1061.04\n"
          ]
        }
      ],
      "source": [
        "pipeline.train_gru(tune_hyperparams=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "8d26628c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d26628c",
        "outputId": "c836ced6-d143-4e6a-b7c3-8d71ce96f7d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpz01qihwv/3sz2bg00.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpz01qihwv/c7l5ns3o.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.12/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=92295', 'data', 'file=/tmp/tmpz01qihwv/3sz2bg00.json', 'init=/tmp/tmpz01qihwv/c7l5ns3o.json', 'output', 'file=/tmp/tmpz01qihwv/prophet_modelhzyyor3d/prophet_model-20250919213406.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "21:34:06 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "21:34:06 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Training Prophet...\n",
            "Prophet MAE: 2471.75\n"
          ]
        }
      ],
      "source": [
        "pipeline.train_prophet(tune_hyperparams=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "7acf5ac7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "7acf5ac7",
        "outputId": "893730f4-479d-4f00-9f65-e3dcd64de3b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "MODEL PERFORMANCE COMPARISON\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                     Model          MAE         RMSE       MAPE        R2\n",
              "LightGBM          LightGBM   170.804606   223.139681   2.313382  0.986293\n",
              "XGBoost            XGBoost    184.71196   259.562026   2.506934  0.981453\n",
              "RandomForest  RandomForest    193.39313   251.502817   2.730669  0.982587\n",
              "CatBoost          CatBoost   291.123734   373.741418   3.996613  0.961548\n",
              "GRU                    GRU  1061.042847  1307.138191  14.678432  0.529648\n",
              "LSTM                  LSTM  2173.521484   2917.93026  25.854269  -1.34385\n",
              "Prophet            Prophet   2471.75477  2843.530723  31.954086 -1.225849"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4ba737ad-8d4e-40d8-b747-aeca12e36d05\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>MAE</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>MAPE</th>\n",
              "      <th>R2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LightGBM</th>\n",
              "      <td>LightGBM</td>\n",
              "      <td>170.804606</td>\n",
              "      <td>223.139681</td>\n",
              "      <td>2.313382</td>\n",
              "      <td>0.986293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGBoost</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>184.71196</td>\n",
              "      <td>259.562026</td>\n",
              "      <td>2.506934</td>\n",
              "      <td>0.981453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForest</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>193.39313</td>\n",
              "      <td>251.502817</td>\n",
              "      <td>2.730669</td>\n",
              "      <td>0.982587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CatBoost</th>\n",
              "      <td>CatBoost</td>\n",
              "      <td>291.123734</td>\n",
              "      <td>373.741418</td>\n",
              "      <td>3.996613</td>\n",
              "      <td>0.961548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GRU</th>\n",
              "      <td>GRU</td>\n",
              "      <td>1061.042847</td>\n",
              "      <td>1307.138191</td>\n",
              "      <td>14.678432</td>\n",
              "      <td>0.529648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LSTM</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>2173.521484</td>\n",
              "      <td>2917.93026</td>\n",
              "      <td>25.854269</td>\n",
              "      <td>-1.34385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Prophet</th>\n",
              "      <td>Prophet</td>\n",
              "      <td>2471.75477</td>\n",
              "      <td>2843.530723</td>\n",
              "      <td>31.954086</td>\n",
              "      <td>-1.225849</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ba737ad-8d4e-40d8-b747-aeca12e36d05')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4ba737ad-8d4e-40d8-b747-aeca12e36d05 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4ba737ad-8d4e-40d8-b747-aeca12e36d05');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "\"\"\"\n",
        "Cell 25: Create metrics summary DataFrame\n",
        "\"\"\"\n",
        "metrics_df = pd.DataFrame(pipeline.metrics).T\n",
        "metrics_df = metrics_df.sort_values('MAE')\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"MODEL PERFORMANCE COMPARISON\")\n",
        "print(\"=\"*50)\n",
        "display(metrics_df.round(2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "89c93089",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89c93089",
        "outputId": "6c0b2ac0-3297-4595-8a34-8c1ecfd47d9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "CREATING ENSEMBLE MODELS\n",
            "==================================================\n",
            "Debugging metrics_df structure:\n",
            "metrics_df shape: (7, 5)\n",
            "metrics_df columns: ['Model', 'MAE', 'RMSE', 'MAPE', 'R2']\n",
            "metrics_df index: ['LightGBM', 'XGBoost', 'RandomForest', 'CatBoost', 'GRU', 'LSTM', 'Prophet']\n",
            "\n",
            "Top 3 models by MAE: ['LightGBM', 'XGBoost', 'RandomForest']\n",
            "Min prediction length: 180\n",
            "LightGBM prediction length: 180\n",
            "XGBoost prediction length: 180\n",
            "RandomForest prediction length: 180\n",
            "\n",
            "Ensemble (Average Top 3) MAE: 154.40\n",
            "LightGBM MAE: 170.8046055777117, type: <class 'float'>\n",
            "XGBoost MAE: 184.7119598388672, type: <class 'float'>\n",
            "RandomForest MAE: 193.39313039179444, type: <class 'float'>\n",
            "MAE array: [170.80460558 184.71195984 193.39313039]\n",
            "Raw weights: [0.35613717 0.32932285 0.31453997]\n",
            "Weights for top 3 models: {'LightGBM': 0.356, 'XGBoost': 0.329, 'RandomForest': 0.315}\n",
            "Ensemble (Weighted) MAE: 153.52\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Cell 26: Create ensemble models - DEBUGGED VERSION\n",
        "\"\"\"\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"CREATING ENSEMBLE MODELS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# First, let's debug what we're working with\n",
        "print(\"Debugging metrics_df structure:\")\n",
        "print(f\"metrics_df shape: {metrics_df.shape}\")\n",
        "print(f\"metrics_df columns: {metrics_df.columns.tolist()}\")\n",
        "print(f\"metrics_df index: {metrics_df.index.tolist()}\")\n",
        "\n",
        "# Simple averaging ensemble (top 3 models)\n",
        "top_3_models = metrics_df.head(3).index.tolist()\n",
        "print(f\"\\nTop 3 models by MAE: {top_3_models}\")\n",
        "\n",
        "ensemble_predictions = {}\n",
        "\n",
        "# 1. Simple Average of Top 3\n",
        "if len(top_3_models) >= 3:\n",
        "    aligned_preds = []\n",
        "    min_length = min([len(pipeline.predictions[m]) for m in top_3_models])\n",
        "    print(f\"Min prediction length: {min_length}\")\n",
        "\n",
        "    for model in top_3_models:\n",
        "        pred_len = len(pipeline.predictions[model])\n",
        "        print(f\"{model} prediction length: {pred_len}\")\n",
        "        aligned_preds.append(pipeline.predictions[model][-min_length:])\n",
        "\n",
        "    ensemble_predictions['Ensemble_Avg_Top3'] = np.mean(aligned_preds, axis=0)\n",
        "\n",
        "    y_test_ensemble = y_test.iloc[-min_length:].values\n",
        "    mae_ensemble = mean_absolute_error(y_test_ensemble, ensemble_predictions['Ensemble_Avg_Top3'])\n",
        "    print(f\"\\nEnsemble (Average Top 3) MAE: {mae_ensemble:.2f}\")\n",
        "\n",
        "    # 2. Weighted Average - COMPLETELY FIXED\n",
        "    # Extract MAE values more carefully\n",
        "    mae_list = []\n",
        "    for model in top_3_models:\n",
        "        mae_val = metrics_df.loc[model, 'MAE']\n",
        "        print(f\"{model} MAE: {mae_val}, type: {type(mae_val)}\")\n",
        "        mae_list.append(float(mae_val))  # Ensure it's a float\n",
        "\n",
        "    mae_array = np.array(mae_list)\n",
        "    print(f\"MAE array: {mae_array}\")\n",
        "\n",
        "    # Calculate weights\n",
        "    weights = 1.0 / mae_array\n",
        "    weights = weights / weights.sum()\n",
        "    print(f\"Raw weights: {weights}\")\n",
        "\n",
        "    # Display weights without using np.round\n",
        "    weights_display = {model: float(f\"{w:.3f}\") for model, w in zip(top_3_models, weights)}\n",
        "    print(f\"Weights for top 3 models: {weights_display}\")\n",
        "\n",
        "    # Calculate weighted ensemble\n",
        "    weighted_ensemble = np.average(np.array(aligned_preds), axis=0, weights=weights)\n",
        "    ensemble_predictions['Ensemble_Weighted'] = weighted_ensemble\n",
        "\n",
        "    mae_weighted = mean_absolute_error(y_test_ensemble, weighted_ensemble)\n",
        "    print(f\"Ensemble (Weighted) MAE: {mae_weighted:.2f}\")\n",
        "else:\n",
        "    print(f\"âš ï¸ Only {len(top_3_models)} models available, need at least 3 for ensemble\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "0a9e0a76",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "0a9e0a76",
        "outputId": "975355a4-f432-4474-8b04-30835a1e04bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "FINAL RESULTS SUMMARY\n",
            "============================================================\n",
            "\n",
            "Final Performance Ranking (by MAE):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                               Model          MAE         RMSE       MAPE  \\\n",
              "Ensemble_Weighted  Ensemble_Weighted   153.522629   203.487639   2.116483   \n",
              "Ensemble_Avg_Top3  Ensemble_Avg_Top3   154.399304   204.775165   2.129251   \n",
              "LightGBM                    LightGBM   170.804606   223.139681   2.313382   \n",
              "XGBoost                      XGBoost    184.71196   259.562026   2.506934   \n",
              "RandomForest            RandomForest    193.39313   251.502817   2.730669   \n",
              "CatBoost                    CatBoost   291.123734   373.741418   3.996613   \n",
              "GRU                              GRU  1061.042847  1307.138191  14.678432   \n",
              "LSTM                            LSTM  2173.521484   2917.93026  25.854269   \n",
              "Prophet                      Prophet   2471.75477  2843.530723  31.954086   \n",
              "\n",
              "                         R2  \n",
              "Ensemble_Weighted  0.988601  \n",
              "Ensemble_Avg_Top3  0.988457  \n",
              "LightGBM           0.986293  \n",
              "XGBoost            0.981453  \n",
              "RandomForest       0.982587  \n",
              "CatBoost           0.961548  \n",
              "GRU                0.529648  \n",
              "LSTM               -1.34385  \n",
              "Prophet           -1.225849  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9feae1ab-4501-49fd-94b8-bb2438dec5ec\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>MAE</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>MAPE</th>\n",
              "      <th>R2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Ensemble_Weighted</th>\n",
              "      <td>Ensemble_Weighted</td>\n",
              "      <td>153.522629</td>\n",
              "      <td>203.487639</td>\n",
              "      <td>2.116483</td>\n",
              "      <td>0.988601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ensemble_Avg_Top3</th>\n",
              "      <td>Ensemble_Avg_Top3</td>\n",
              "      <td>154.399304</td>\n",
              "      <td>204.775165</td>\n",
              "      <td>2.129251</td>\n",
              "      <td>0.988457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LightGBM</th>\n",
              "      <td>LightGBM</td>\n",
              "      <td>170.804606</td>\n",
              "      <td>223.139681</td>\n",
              "      <td>2.313382</td>\n",
              "      <td>0.986293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGBoost</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>184.71196</td>\n",
              "      <td>259.562026</td>\n",
              "      <td>2.506934</td>\n",
              "      <td>0.981453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForest</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>193.39313</td>\n",
              "      <td>251.502817</td>\n",
              "      <td>2.730669</td>\n",
              "      <td>0.982587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CatBoost</th>\n",
              "      <td>CatBoost</td>\n",
              "      <td>291.123734</td>\n",
              "      <td>373.741418</td>\n",
              "      <td>3.996613</td>\n",
              "      <td>0.961548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GRU</th>\n",
              "      <td>GRU</td>\n",
              "      <td>1061.042847</td>\n",
              "      <td>1307.138191</td>\n",
              "      <td>14.678432</td>\n",
              "      <td>0.529648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LSTM</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>2173.521484</td>\n",
              "      <td>2917.93026</td>\n",
              "      <td>25.854269</td>\n",
              "      <td>-1.34385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Prophet</th>\n",
              "      <td>Prophet</td>\n",
              "      <td>2471.75477</td>\n",
              "      <td>2843.530723</td>\n",
              "      <td>31.954086</td>\n",
              "      <td>-1.225849</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9feae1ab-4501-49fd-94b8-bb2438dec5ec')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9feae1ab-4501-49fd-94b8-bb2438dec5ec button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9feae1ab-4501-49fd-94b8-bb2438dec5ec');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ† BEST MODEL: Ensemble_Weighted\n",
            "   MAE: 153.52\n",
            "\n",
            "ðŸ“Š Improvement over SARIMA (MAE=156): 1.6%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\"\"\"\n",
        "Cell 27: Create final results summary\n",
        "\"\"\"\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FINAL RESULTS SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Combine all metrics\n",
        "all_metrics = pipeline.metrics.copy()\n",
        "\n",
        "# Add ensemble metrics if they exist\n",
        "if 'Ensemble_Avg_Top3' in ensemble_predictions:\n",
        "    all_metrics['Ensemble_Avg_Top3'] = {\n",
        "        'Model': 'Ensemble_Avg_Top3',\n",
        "        'MAE': mae_ensemble,\n",
        "        'RMSE': np.sqrt(mean_squared_error(y_test_ensemble, ensemble_predictions['Ensemble_Avg_Top3'])),\n",
        "        'MAPE': mean_absolute_percentage_error(y_test_ensemble, ensemble_predictions['Ensemble_Avg_Top3']) * 100,\n",
        "        'R2': 1 - (np.sum((y_test_ensemble - ensemble_predictions['Ensemble_Avg_Top3']) ** 2) /\n",
        "                   np.sum((y_test_ensemble - y_test_ensemble.mean()) ** 2))\n",
        "    }\n",
        "\n",
        "if 'Ensemble_Weighted' in ensemble_predictions:\n",
        "    all_metrics['Ensemble_Weighted'] = {\n",
        "        'Model': 'Ensemble_Weighted',\n",
        "        'MAE': mae_weighted,\n",
        "        'RMSE': np.sqrt(mean_squared_error(y_test_ensemble, ensemble_predictions['Ensemble_Weighted'])),\n",
        "        'MAPE': mean_absolute_percentage_error(y_test_ensemble, ensemble_predictions['Ensemble_Weighted']) * 100,\n",
        "        'R2': 1 - (np.sum((y_test_ensemble - ensemble_predictions['Ensemble_Weighted']) ** 2) /\n",
        "                   np.sum((y_test_ensemble - y_test_ensemble.mean()) ** 2))\n",
        "    }\n",
        "\n",
        "# Final summary table\n",
        "final_results = pd.DataFrame(all_metrics).T\n",
        "final_results = final_results.sort_values('MAE')\n",
        "\n",
        "print(\"\\nFinal Performance Ranking (by MAE):\")\n",
        "display(final_results[['Model', 'MAE', 'RMSE', 'MAPE', 'R2']].round(2))\n",
        "\n",
        "# Best model\n",
        "best_model = final_results.iloc[0]['Model']\n",
        "best_mae = final_results.iloc[0]['MAE']\n",
        "print(f\"\\nðŸ† BEST MODEL: {best_model}\")\n",
        "print(f\"   MAE: {best_mae:.2f}\")\n",
        "\n",
        "# Comparison with SARIMA baseline\n",
        "sarima_mae = 156\n",
        "improvement = ((sarima_mae - best_mae) / sarima_mae) * 100\n",
        "print(f\"\\nðŸ“Š Improvement over SARIMA (MAE=156): {improvement:.1f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "b7decf96",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7decf96",
        "outputId": "790825b2-609f-4bf6-d2fa-40a93c1a6de4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Tree models saved to ml_models_final.pkl\n",
            "âœ… LSTM saved to lstm_model_final.h5\n",
            "âœ… GRU saved to gru_model_final.h5\n",
            "âœ… Results saved to ml_results_final.pkl\n",
            "\n",
            "============================================================\n",
            "ML FORECASTING PIPELINE COMPLETE!\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\"\"\"\n",
        "Cell 28: Save all models and results\n",
        "\"\"\"\n",
        "# Save tree-based models and Prophet\n",
        "models_to_save = {}\n",
        "for model_name, model in pipeline.models.items():\n",
        "    if model_name not in ['LSTM', 'GRU']:\n",
        "        models_to_save[model_name] = model\n",
        "\n",
        "with open('ml_models_final.pkl', 'wb') as f:\n",
        "    pickle.dump(models_to_save, f)\n",
        "print(\"âœ… Tree models saved to ml_models_final.pkl\")\n",
        "\n",
        "# Save neural network models\n",
        "if 'LSTM' in pipeline.models:\n",
        "    pipeline.models['LSTM'].save('lstm_model_final.h5')\n",
        "    print(\"âœ… LSTM saved to lstm_model_final.h5\")\n",
        "\n",
        "if 'GRU' in pipeline.models:\n",
        "    pipeline.models['GRU'].save('gru_model_final.h5')\n",
        "    print(\"âœ… GRU saved to gru_model_final.h5\")\n",
        "\n",
        "# Save results\n",
        "results = {\n",
        "    'metrics': all_metrics,\n",
        "    'predictions': pipeline.predictions,\n",
        "    'best_params': pipeline.best_params,\n",
        "    'final_results': final_results.to_dict()\n",
        "}\n",
        "\n",
        "with open('ml_results_final.pkl', 'wb') as f:\n",
        "    pickle.dump(results, f)\n",
        "print(\"âœ… Results saved to ml_results_final.pkl\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ML FORECASTING PIPELINE COMPLETE!\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "b28efd09",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "b28efd09",
        "outputId": "77c56718-76ab-4dcd-b5d1-bd03cb453e6b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nRECOVERY CELL - Run this after restart to restore progress\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "\n",
        "\"\"\"\n",
        "RECOVERY CELL - Run this after restart to restore progress\n",
        "\"\"\"\n",
        "# # Uncomment below to recover from checkpoint\n",
        "# import pickle\n",
        "#\n",
        "# # Load checkpoint\n",
        "# with open('tree_models_checkpoint.pkl', 'rb') as f:\n",
        "#     checkpoint = pickle.load(f)\n",
        "#\n",
        "# # Reinitialize pipeline\n",
        "# pipeline = MLForecastingPipeline(X_train, X_test, y_train, y_test, train_dates, test_dates)\n",
        "# pipeline.models = checkpoint['models']\n",
        "# pipeline.predictions = checkpoint['predictions']\n",
        "# pipeline.metrics = checkpoint['metrics']\n",
        "# pipeline.best_params = checkpoint['best_params']\n",
        "#\n",
        "# print(f\"âœ… Restored {len(pipeline.models)} models from checkpoint\")\n",
        "# print(f\"Models loaded: {list(pipeline.models.keys())}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}