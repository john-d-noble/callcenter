{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyMYbDGiRIn9c+iFZ2cb8XX9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/john-d-noble/callcenter/blob/main/Latest_Model_Playoff_Version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# STEP 0: ENVIRONMENT SETUP\n",
        "# This block handles installation in the correct order to prevent conflicts.\n",
        "# =============================================================================\n",
        "!pip install numpy==1.26.4 # Pinning numpy version for stability\n",
        "#!pip uninstall pmdarima statsmodels -y\n",
        "!pip install pmdarima tensorflow xgboost yfinance -q\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vd5SI4Iu90F9",
        "outputId": "88add7c2-ea0a-46ff-b365-4030b81f4766"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.12/dist-packages (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rU1HG7gl-QFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# =============================================================================\n",
        "# MASTER SCRIPT: A 4-Way Model Showdown (Version 8.1 - Unified)\n",
        "# =============================================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import xgboost as xgb\n",
        "from pmdarima.arima import auto_arima\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from datetime import date\n",
        "import warnings\n",
        "\n",
        "# Suppress irrelevant warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# --- [SETUP] Data Preparation ---\n",
        "print(\"--- [SETUP] Preparing all necessary data... ---\")\n",
        "# 1. Load Client Data\n",
        "client_data_path = \"agent_contact_volume_wgsd2.csv\"\n",
        "df_calls = pd.read_csv(client_data_path)\n",
        "df_calls.columns = ['Date', 'adjusted_call_volume']\n",
        "df_calls['Date'] = pd.to_datetime(df_calls['Date'])\n",
        "\n",
        "# 2. Fetch Market Data\n",
        "TICKERS = ['BTC-USD', 'ETH-USD', 'SOL-USD', '^VIX']\n",
        "START_DATE = '2021-01-01'\n",
        "END_DATE = date.today().strftime('%Y-%m-%d')\n",
        "full_date_range = pd.date_range(start=START_DATE, end=END_DATE, freq='D')\n",
        "market_data_df = pd.DataFrame(index=full_date_range)\n",
        "market_data_df.index.name = 'Date'\n",
        "TICKER_MAP = {'BTC-USD': 'btc', 'ETH-USD': 'eth', 'SOL-USD': 'sol', '^VIX': 'vix'}\n",
        "for ticker, name in TICKER_MAP.items():\n",
        "    asset_raw_data = yf.download(ticker, start=START_DATE, end=END_DATE, progress=False)\n",
        "    if asset_raw_data.empty:\n",
        "        raise ValueError(f\"No data returned from API for ticker: {ticker}\")\n",
        "    asset_df = asset_raw_data[['Close', 'Volume']]\n",
        "    asset_df.columns = [f'{name}_price', f'{name}_volume']\n",
        "    asset_df = asset_df.reindex(full_date_range).ffill().bfill()\n",
        "    market_data_df = market_data_df.join(asset_df)\n",
        "\n",
        "# 3. Create Final Training DataFrame with Features\n",
        "combined_df = pd.merge(market_data_df.reset_index(), df_calls, on='Date', how='inner')\n",
        "for crypto in ['btc', 'eth', 'sol']:\n",
        "    combined_df[f'{crypto}_volatility_index'] = combined_df[f'{crypto}_price'].pct_change().rolling(window=14).std()\n",
        "combined_df.fillna(0, inplace=True)\n",
        "feature_cols = [col for col in combined_df.columns if col not in ['Date', 'adjusted_call_volume']]\n",
        "combined_df[feature_cols] = combined_df[feature_cols].shift(1)\n",
        "combined_df.dropna(inplace=True)\n",
        "print(\"✅ Data preparation complete.\\n\")\n",
        "\n",
        "# --- Hold out the last 90 days for testing across all models ---\n",
        "test_period = 90\n",
        "train_df = combined_df[:-test_period]\n",
        "test_df = combined_df[-test_period:]\n",
        "results = {}\n",
        "\n",
        "# ==============================================================================\n",
        "# MODEL 1: ARIMA - The Simplest Baseline\n",
        "# ==============================================================================\n",
        "print(\"--- [1/4] Building Model 1: ARIMA (Simple Baseline)... ---\")\n",
        "arima_model = auto_arima(train_df['adjusted_call_volume'], seasonal=False, trace=False, error_action='ignore', suppress_warnings=True, stepwise=True)\n",
        "arima_predictions = arima_model.predict(n_periods=test_period)\n",
        "results['ARIMA'] = mean_absolute_error(test_df['adjusted_call_volume'], arima_predictions)\n",
        "print(f\"✅ ARIMA Complete. MAE: {results['ARIMA']:.2f}\\n\")\n",
        "\n",
        "# ==============================================================================\n",
        "# MODEL 2: SARIMA - The Seasonal Baseline\n",
        "# ==============================================================================\n",
        "print(\"--- [2/4] Building Model 2: SARIMA (Seasonal Baseline)... ---\")\n",
        "sarima_model = auto_arima(train_df['adjusted_call_volume'], seasonal=True, m=7, trace=False, error_action='ignore', suppress_warnings=True, stepwise=True)\n",
        "sarima_predictions = sarima_model.predict(n_periods=test_period)\n",
        "results['SARIMA'] = mean_absolute_error(test_df['adjusted_call_volume'], sarima_predictions)\n",
        "print(f\"✅ SARIMA Complete. MAE: {results['SARIMA']:.2f}\\n\")\n",
        "\n",
        "# ==============================================================================\n",
        "# MODEL 3: LSTM - The Deep Learning Challenger\n",
        "# ==============================================================================\n",
        "print(\"--- [3/4] Building Model 3: LSTM (Deep Learning Challenger)... ---\")\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_volume = scaler.fit_transform(combined_df['adjusted_call_volume'].values.reshape(-1,1))\n",
        "\n",
        "def create_dataset(dataset, look_back=30):\n",
        "    X, Y = [], []\n",
        "    for i in range(len(dataset)-look_back-1):\n",
        "        a = dataset[i:(i+look_back), 0]\n",
        "        X.append(a)\n",
        "        Y.append(dataset[i + look_back, 0])\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "look_back = 30\n",
        "X, y = create_dataset(scaled_volume, look_back)\n",
        "X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
        "X_train, X_test = X[:-test_period], X[-test_period:]\n",
        "y_train, y_test = y[:-test_period], y[-test_period:]\n",
        "\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(LSTM(50, input_shape=(look_back, 1)))\n",
        "lstm_model.add(Dense(1))\n",
        "lstm_model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "lstm_model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=0)\n",
        "\n",
        "lstm_predictions_scaled = lstm_model.predict(X_test, verbose=0)\n",
        "lstm_predictions = scaler.inverse_transform(lstm_predictions_scaled)\n",
        "results['LSTM'] = mean_absolute_error(test_df['adjusted_call_volume'], lstm_predictions)\n",
        "print(f\"✅ LSTM Complete. MAE: {results['LSTM']:.2f}\\n\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# MODEL 4: XGBOOST - The High-Performance External Feature Model\n",
        "# ==============================================================================\n",
        "print(\"--- [4/4] Building Model 4: XGBoost (High-Performance Model)... ---\")\n",
        "features = [col for col in combined_df.columns if col not in ['Date', 'adjusted_call_volume']]\n",
        "X_train, y_train = train_df[features], train_df['adjusted_call_volume']\n",
        "X_test, y_test = test_df[features], test_df['adjusted_call_volume']\n",
        "best_params = {'subsample': 0.9, 'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.01, 'colsample_bytree': 0.8}\n",
        "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', **best_params, random_state=42)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "xgb_predictions = xgb_model.predict(X_test)\n",
        "results['XGBoost'] = mean_absolute_error(y_test, xgb_predictions)\n",
        "print(f\"✅ XGBoost Complete. MAE: {results['XGBoost']:.2f}\\n\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# FINAL COMPARISON & CONCLUSION\n",
        "# ==============================================================================\n",
        "print(\"--- FINAL RESULTS: 4-Way Model Showdown ---\")\n",
        "results_df = pd.DataFrame(list(results.items()), columns=['Model', 'Mean Absolute Error (MAE)'])\n",
        "results_df = results_df.sort_values('Mean Absolute Error (MAE)').reset_index(drop=True)\n",
        "print(results_df)\n",
        "\n",
        "best_baseline_mae = results_df[results_df['Model'] != 'XGBoost']['Mean Absolute Error (MAE)'].min()\n",
        "xgb_mae = results_df[results_df['Model'] == 'XGBoost']['Mean Absolute Error (MAE)'].iloc[0]\n",
        "improvement = ((best_baseline_mae - xgb_mae) / best_baseline_mae) * 100\n",
        "\n",
        "print(\"-\" * 45)\n",
        "print(f\"Improvement of XGBoost over best alternative: {improvement:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ra4t5BR-Us4",
        "outputId": "cce72b0e-bd2b-4114-ae1f-540c27ed2c63"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- [SETUP] Preparing all necessary data... ---\n",
            "✅ Data preparation complete.\n",
            "\n",
            "--- [1/4] Building Model 1: ARIMA (Simple Baseline)... ---\n",
            "✅ ARIMA Complete. MAE: 1208.48\n",
            "\n",
            "--- [2/4] Building Model 2: SARIMA (Seasonal Baseline)... ---\n",
            "✅ SARIMA Complete. MAE: 2299.66\n",
            "\n",
            "--- [3/4] Building Model 3: LSTM (Deep Learning Challenger)... ---\n",
            "✅ LSTM Complete. MAE: 1773.67\n",
            "\n",
            "--- [4/4] Building Model 4: XGBoost (High-Performance Model)... ---\n",
            "✅ XGBoost Complete. MAE: 1657.04\n",
            "\n",
            "--- FINAL RESULTS: 4-Way Model Showdown ---\n",
            "     Model  Mean Absolute Error (MAE)\n",
            "0    ARIMA                1208.481397\n",
            "1  XGBoost                1657.040771\n",
            "2     LSTM                1773.672607\n",
            "3   SARIMA                2299.655239\n",
            "---------------------------------------------\n",
            "Improvement of XGBoost over best alternative: -37.12%\n"
          ]
        }
      ]
    }
  ]
}