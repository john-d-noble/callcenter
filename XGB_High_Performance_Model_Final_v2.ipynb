{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyMXcj4OhV8I73KdNHU3AOXh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/john-d-noble/callcenter/blob/main/XGB_High_Performance_Model_Final_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e416e01",
        "outputId": "c0def5c4-4afc-443d-efaa-a9e25c5b959a"
      },
      "source": [
        "!pip install yfinance"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yfinance\n",
            "  Downloading yfinance-0.2.65-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.32.4)\n",
            "Collecting multitasking>=0.0.7 (from yfinance)\n",
            "  Downloading multitasking-0.0.12.tar.gz (19 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.3.8)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2025.2)\n",
            "Collecting frozendict>=2.3.4 (from yfinance)\n",
            "  Downloading frozendict-2.4.6-py312-none-any.whl.metadata (23 kB)\n",
            "Collecting peewee>=3.16.2 (from yfinance)\n",
            "  Downloading peewee-3.18.2.tar.gz (949 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m949.2/949.2 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.13.4)\n",
            "Collecting curl_cffi>=0.7 (from yfinance)\n",
            "  Downloading curl_cffi-0.13.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (6.32.0)\n",
            "Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (15.0.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (4.14.1)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance) (1.17.1)\n",
            "Requirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->yfinance) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (2.5.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
            "Downloading yfinance-0.2.65-py2.py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading curl_cffi-0.13.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m109.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading frozendict-2.4.6-py312-none-any.whl (16 kB)\n",
            "Building wheels for collected packages: multitasking, peewee\n",
            "  Building wheel for multitasking (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for multitasking: filename=multitasking-0.0.12-py3-none-any.whl size=15636 sha256=925987fb7f0e47a673e515b6221906848bf9cdfd287be397457bb4951ebcffed\n",
            "  Stored in directory: /root/.cache/pip/wheels/cc/bd/6f/664d62c99327abeef7d86489e6631cbf45b56fbf7ef1d6ef00\n",
            "  Building wheel for peewee (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for peewee: filename=peewee-3.18.2-cp312-cp312-linux_x86_64.whl size=936670 sha256=55782272e0deb9e2e573fd2232755b0c2e776e02fdae7f973dd4372f0137234a\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/df/a9/0202b051c65b11c992dd6db9f2babdd2c44ec7d35d511be5d3\n",
            "Successfully built multitasking peewee\n",
            "Installing collected packages: peewee, multitasking, frozendict, curl_cffi, yfinance\n",
            "Successfully installed curl_cffi-0.13.0 frozendict-2.4.6 multitasking-0.0.12 peewee-3.18.2 yfinance-0.2.65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Y399xda3fCS",
        "outputId": "6be16382-4fb3-4404-97e5-76be309fb7a8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xgboost\n",
            "  Downloading xgboost-3.0.4-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.0.2)\n",
            "Collecting nvidia-nccl-cu12 (from xgboost)\n",
            "  Downloading nvidia_nccl_cu12-2.27.7-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.1)\n",
            "Downloading xgboost-3.0.4-py3-none-manylinux_2_28_x86_64.whl (94.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.7-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.5/322.5 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nccl-cu12, xgboost\n",
            "Successfully installed nvidia-nccl-cu12-2.27.7 xgboost-3.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# MASTER SCRIPT: From Data Collection to Live Forecasting (Version 3.1 - With Validation Pause)\n",
        "# This script combines all steps into a single, sequential process with robust data cleaning.\n",
        "#\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
        "from datetime import date, timedelta\n",
        "\n",
        "# --- MASTER CONFIGURATION ---\n",
        "# Data Collection & Simulation\n",
        "TICKERS = ['BTC-USD', 'ETH-USD', 'SOL-USD', '^VIX']\n",
        "START_DATE = '2021-01-01'\n",
        "\n",
        "# Feature Engineering\n",
        "VOLATILITY_WINDOW = 14\n",
        "SPIKE_WINDOW = 30\n",
        "SPIKE_THRESHOLD = 2.0\n",
        "\n",
        "# Model Tuning\n",
        "TUNING_ITERATIONS = 50 # Number of hyperparameter combinations to test\n",
        "\n",
        "# Final Output Files\n",
        "MARKET_DATA_FILE = 'crypto_price_and_volume_data_2021_present.csv'\n",
        "SIMULATED_CALLS_FILE = 'final_simulated_data_with_volatility_2021_present.csv'\n",
        "ADVANCED_TRAINING_FILE = 'advanced_feature_training_data_2021_present.csv'\n",
        "FINAL_MODEL_FILENAME = 'final_advanced_xgboost_model_2021_present.json'\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 1: DATA COLLECTION - Fetch all required price and volume data\n",
        "# ==============================================================================\n",
        "print(\"--- [STEP 1/7] Starting: Data Collection ---\")\n",
        "try:\n",
        "    END_DATE = date.today().strftime('%Y-%m-%d')\n",
        "    raw_data = yf.download(TICKERS, start=START_DATE, end=END_DATE)\n",
        "\n",
        "    # Create a complete daily date range to ensure no gaps\n",
        "    full_date_range = pd.date_range(start=START_DATE, end=END_DATE, freq='D')\n",
        "    market_data_df = pd.DataFrame(index=full_date_range)\n",
        "\n",
        "    # Define a mapping from ticker to a clean name for columns\n",
        "    TICKER_MAP = {\n",
        "        'BTC-USD': 'btc', 'ETH-USD': 'eth',\n",
        "        'SOL-USD': 'sol', '^VIX': 'vix'\n",
        "    }\n",
        "\n",
        "    for ticker, name in TICKER_MAP.items():\n",
        "        price_series = raw_data[('Close', ticker)]\n",
        "        volume_series = raw_data[('Volume', ticker)]\n",
        "        asset_df = pd.DataFrame({f'{name}_price': price_series, f'{name}_volume': volume_series})\n",
        "        asset_df = asset_df.reindex(full_date_range).ffill().bfill()\n",
        "        market_data_df = market_data_df.join(asset_df)\n",
        "\n",
        "    market_data_df.index.name = 'Date'\n",
        "    market_data_df.to_csv(MARKET_DATA_FILE)\n",
        "    print(f\"✅ Success! Market data saved to '{MARKET_DATA_FILE}'\")\n",
        "\n",
        "    # --- MODIFICATION START: Added a data validation and pause point ---\n",
        "    print(\"\\n--- [DATA REVIEW & VALIDATION] ---\")\n",
        "    print(f\"Date Range: {market_data_df.index.min().strftime('%Y-%m-%d')} to {market_data_df.index.max().strftime('%Y-%m-%d')}\")\n",
        "    print(f\"Total Days (Rows) Collected: {market_data_df.shape[0]}\")\n",
        "    print(f\"Total Features (Columns): {market_data_df.shape[1]}\")\n",
        "    print(\"\\n--- Missing Values Check (should all be 0) ---\")\n",
        "    print(market_data_df.isnull().sum())\n",
        "\n",
        "    input(\"\\n--- PAUSED --- \\nReview the counts above. Press Enter to proceed to Step 2 or Ctrl+C to exit.\\n\")\n",
        "    # --- MODIFICATION END ---\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ FAILED: {e}\")\n",
        "    exit()\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 2: SIMULATION - Create the intelligent, volatility-driven call volume\n",
        "# ==============================================================================\n",
        "print(f\"--- [STEP 2/7] Starting: Call Volume Simulation ---\")\n",
        "try:\n",
        "    df_sim = pd.read_csv(MARKET_DATA_FILE, parse_dates=['Date'])\n",
        "\n",
        "    # Baseline simulation parameters\n",
        "    NUMBER_OF_AGENTS = 3000\n",
        "    AVG_WEEKDAY_CALLS_PER_AGENT = 110\n",
        "    AVG_WEEKEND_CALLS_PER_AGENT = 50\n",
        "    RANDOMNESS_FACTOR = 15000\n",
        "\n",
        "    def simulate_base_volume(d):\n",
        "        mean_vol = NUMBER_OF_AGENTS * (AVG_WEEKDAY_CALLS_PER_AGENT if d.dayofweek < 5 else AVG_WEEKEND_CALLS_PER_AGENT)\n",
        "        return abs(int(np.random.normal(loc=mean_vol, scale=RANDOMNESS_FACTOR)))\n",
        "    df_sim['base_call_volume'] = df_sim['Date'].apply(simulate_base_volume)\n",
        "\n",
        "    # Volatility adjustment parameters\n",
        "    VOLATILITY_THRESHOLD = 0.05\n",
        "    VOLATILITY_MULTIPLIER = 1.8\n",
        "    VIX_FEAR_THRESHOLD = 30\n",
        "    VIX_MULTIPLIER = 1.4\n",
        "\n",
        "    for crypto in ['btc', 'eth', 'sol']:\n",
        "        df_sim[f'{crypto}_price_pct_change'] = df_sim[f'{crypto}_price'].pct_change()\n",
        "\n",
        "    def adjust_volume_for_volatility(row):\n",
        "        final_volume = row['base_call_volume']\n",
        "        crypto_volatile = any(abs(row[f'{c}_price_pct_change']) > VOLATILITY_THRESHOLD for c in ['btc', 'eth', 'sol'])\n",
        "        vix_high = row['vix_price'] > VIX_FEAR_THRESHOLD\n",
        "        if crypto_volatile: final_volume *= VOLATILITY_MULTIPLIER\n",
        "        if vix_high: final_volume *= VIX_MULTIPLIER\n",
        "        return int(final_volume)\n",
        "\n",
        "    df_sim.fillna(0, inplace=True)\n",
        "    df_sim['adjusted_call_volume'] = df_sim.apply(adjust_volume_for_volatility, axis=1)\n",
        "\n",
        "    simulated_df = df_sim[['Date', 'btc_price', 'eth_price', 'sol_price', 'vix_price', 'adjusted_call_volume']]\n",
        "    simulated_df.to_csv(SIMULATED_CALLS_FILE, index=False)\n",
        "    print(f\"✅ Success! Simulated call volume data saved to '{SIMULATED_CALLS_FILE}'\\n\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ FAILED: {e}\")\n",
        "    exit()\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 3: ADVANCED FEATURE ENGINEERING - Create the final training data\n",
        "# ==============================================================================\n",
        "print(f\"--- [STEP 3/7] Starting: Advanced Feature Engineering ---\")\n",
        "try:\n",
        "    df_market = pd.read_csv(MARKET_DATA_FILE, parse_dates=['Date'])\n",
        "    df_calls = pd.read_csv(SIMULATED_CALLS_FILE, parse_dates=['Date'])\n",
        "\n",
        "    for crypto in ['btc', 'eth', 'sol']:\n",
        "        df_market[f'{crypto}_price_pct_change'] = df_market[f'{crypto}_price'].pct_change()\n",
        "        df_market[f'{crypto}_volatility_index'] = df_market[f'{crypto}_price_pct_change'].rolling(window=VOLATILITY_WINDOW).std()\n",
        "\n",
        "        rolling_vol_mean = df_market[f'{crypto}_volume'].rolling(window=SPIKE_WINDOW).mean()\n",
        "        rolling_vol_std = df_market[f'{crypto}_volume'].rolling(window=SPIKE_WINDOW).std()\n",
        "        df_market[f'{crypto}_volume_spike'] = (df_market[f'{crypto}_volume'] > (rolling_vol_mean + SPIKE_THRESHOLD * rolling_vol_std)).astype(int)\n",
        "\n",
        "        rolling_price_mean = df_market[f'{crypto}_price_pct_change'].rolling(window=SPIKE_WINDOW).mean()\n",
        "        rolling_price_std = df_market[f'{crypto}_price_pct_change'].rolling(window=SPIKE_WINDOW).std()\n",
        "        df_market[f'{crypto}_price_shock'] = (abs(df_market[f'{crypto}_price_pct_change']) > (rolling_price_mean + SPIKE_THRESHOLD * rolling_price_std)).astype(int)\n",
        "\n",
        "    df_calls_subset = df_calls[['Date', 'adjusted_call_volume']]\n",
        "    combined_df = pd.merge(df_market, df_calls_subset, on='Date', how='inner')\n",
        "    combined_df.drop(columns=[col for col in combined_df.columns if 'pct_change' in col], inplace=True)\n",
        "    combined_df.fillna(0, inplace=True)\n",
        "    combined_df.to_csv(ADVANCED_TRAINING_FILE, index=False)\n",
        "    print(f\"✅ Success! Advanced training file saved as '{ADVANCED_TRAINING_FILE}'\\n\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ FAILED: {e}\")\n",
        "    exit()\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 4: MODEL TUNING - Find the best hyperparameters\n",
        "# ==============================================================================\n",
        "print(f\"--- [STEP 4/7] Starting: Automated Model Tuning (this may take several minutes) ---\")\n",
        "try:\n",
        "    df_tune = pd.read_csv(ADVANCED_TRAINING_FILE, parse_dates=['Date'])\n",
        "    df_tune.set_index('Date', inplace=True)\n",
        "    df_tune.fillna(0, inplace=True)\n",
        "    X = df_tune.drop('adjusted_call_volume', axis=1)\n",
        "    y = df_tune['adjusted_call_volume']\n",
        "\n",
        "    param_grid = {\n",
        "        'n_estimators': [100, 300, 500, 700], 'max_depth': [3, 4, 5, 6, 7],\n",
        "        'learning_rate': [0.01, 0.05, 0.1], 'subsample': [0.7, 0.8, 0.9, 1.0],\n",
        "        'colsample_bytree': [0.7, 0.8, 0.9, 1.0]\n",
        "    }\n",
        "    xgb_model = xgb.XGBRegressor(objective='reg:squarederror', eval_metric='mae')\n",
        "    tscv = TimeSeriesSplit(n_splits=5)\n",
        "    random_search = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_grid, n_iter=TUNING_ITERATIONS,\n",
        "                                   scoring='neg_mean_absolute_error', cv=tscv, n_jobs=-1, verbose=1, random_state=42)\n",
        "    random_search.fit(X, y)\n",
        "\n",
        "    best_params = random_search.best_params_\n",
        "    best_score = -random_search.best_score_\n",
        "\n",
        "    print(\"\\n--- Tuning Complete ---\")\n",
        "    print(f\"✅ Best MAE Score found: {best_score:.2f}\")\n",
        "    print(f\"✅ Best Hyperparameters found: {best_params}\\n\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ FAILED: {e}\")\n",
        "    exit()\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 5: FINAL MODEL TRAINING - Build the model with the best settings\n",
        "# ==============================================================================\n",
        "print(f\"--- [STEP 5/7] Starting: Final Model Training ---\")\n",
        "try:\n",
        "    final_model = xgb.XGBRegressor(\n",
        "        objective='reg:squarederror',\n",
        "        eval_metric='mae',\n",
        "        **best_params,\n",
        "        random_state=42\n",
        "    )\n",
        "    final_model.fit(X, y)\n",
        "    print(\"✅ Success! Final model trained on all available data.\\n\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ FAILED: {e}\")\n",
        "    exit()\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 6: SAVE THE MODEL - Create the final, predictive asset\n",
        "# ==============================================================================\n",
        "print(f\"--- [STEP 6/7] Starting: Saving the Final Model ---\")\n",
        "try:\n",
        "    final_model.save_model(FINAL_MODEL_FILENAME)\n",
        "    print(f\"✅ Success! Final model has been saved as '{FINAL_MODEL_FILENAME}'.\\n\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ FAILED: {e}\")\n",
        "    exit()\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 7: MAKE A PREDICTION - Use the model for a live forecast\n",
        "# ==============================================================================\n",
        "print(f\"--- [STEP 7/7] Starting: Making a Live Forecast ---\")\n",
        "try:\n",
        "    forecast_start_date = date.today() - timedelta(days=35)\n",
        "    forecast_end_date = date.today()\n",
        "    raw_forecast_data = yf.download(TICKERS, start=forecast_start_date, end=forecast_end_date, progress=False)\n",
        "\n",
        "    forecast_full_range = pd.date_range(start=forecast_start_date, end=forecast_end_date, freq='D')\n",
        "    market_df = pd.DataFrame(index=forecast_full_range)\n",
        "\n",
        "    for ticker, name in TICKER_MAP.items():\n",
        "        price_series = raw_forecast_data[('Close', ticker)]\n",
        "        volume_series = raw_forecast_data[('Volume', ticker)]\n",
        "        asset_df = pd.DataFrame({f'{name}_price': price_series, f'{name}_volume': volume_series})\n",
        "        asset_df = asset_df.reindex(forecast_full_range).ffill().bfill()\n",
        "        market_df = market_df.join(asset_df)\n",
        "\n",
        "    market_df.index.name = 'Date'\n",
        "\n",
        "    for crypto in ['btc', 'eth', 'sol']:\n",
        "        market_df[f'{crypto}_price_pct_change'] = market_df[f'{crypto}_price'].pct_change()\n",
        "        market_df[f'{crypto}_volatility_index'] = market_df[f'{crypto}_price_pct_change'].rolling(window=VOLATILITY_WINDOW).std()\n",
        "        rolling_vol_mean = market_df[f'{crypto}_volume'].rolling(window=SPIKE_WINDOW).mean()\n",
        "        rolling_vol_std = market_df[f'{crypto}_volume'].rolling(window=SPIKE_WINDOW).std()\n",
        "        market_df[f'{crypto}_volume_spike'] = (market_df[f'{crypto}_volume'] > (rolling_vol_mean + SPIKE_THRESHOLD * rolling_vol_std)).astype(int)\n",
        "        rolling_price_mean = market_df[f'{crypto}_price_pct_change'].rolling(window=SPIKE_WINDOW).mean()\n",
        "        rolling_price_std = market_df[f'{crypto}_price_pct_change'].rolling(window=SPIKE_WINDOW).std()\n",
        "        market_df[f'{crypto}_price_shock'] = (abs(market_df[f'{crypto}_price_pct_change']) > (rolling_price_mean + SPIKE_THRESHOLD * rolling_price_std)).astype(int)\n",
        "\n",
        "    prediction_input = market_df.tail(1)\n",
        "    training_columns = [col for col in X.columns]\n",
        "    prediction_input = prediction_input[training_columns]\n",
        "\n",
        "    loaded_model = xgb.XGBRegressor()\n",
        "    loaded_model.load_model(FINAL_MODEL_FILENAME)\n",
        "\n",
        "    prediction = loaded_model.predict(prediction_input)\n",
        "    predicted_volume = int(prediction[0])\n",
        "    latest_day = prediction_input.index[0]\n",
        "\n",
        "    print(\"\\n--- Forecast Complete ---\")\n",
        "    print(f\"✅ Based on the latest market data for {latest_day.strftime('%Y-%m-%d')}, the model forecasts a call volume of: {predicted_volume:,}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ FAILED: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv_hdmolhvDT",
        "outputId": "aa4fc475-871b-4e37-ac3d-a558395d97ba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- [STEP 1/7] Starting: Data Collection ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1517842121.py:39: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  raw_data = yf.download(TICKERS, start=START_DATE, end=END_DATE)\n",
            "[*********************100%***********************]  4 of 4 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Success! Market data saved to 'crypto_price_and_volume_data_2021_present.csv'\n",
            "\n",
            "--- [DATA REVIEW & VALIDATION] ---\n",
            "Date Range: 2021-01-01 to 2025-08-25\n",
            "Total Days (Rows) Collected: 1698\n",
            "Total Features (Columns): 8\n",
            "\n",
            "--- Missing Values Check (should all be 0) ---\n",
            "btc_price     0\n",
            "btc_volume    0\n",
            "eth_price     0\n",
            "eth_volume    0\n",
            "sol_price     0\n",
            "sol_volume    0\n",
            "vix_price     0\n",
            "vix_volume    0\n",
            "dtype: int64\n",
            "\n",
            "--- PAUSED --- \n",
            "Review the counts above. Press Enter to proceed to Step 2 or Ctrl+C to exit.\n",
            "\n",
            "--- [STEP 2/7] Starting: Call Volume Simulation ---\n",
            "✅ Success! Simulated call volume data saved to 'final_simulated_data_with_volatility_2021_present.csv'\n",
            "\n",
            "--- [STEP 3/7] Starting: Advanced Feature Engineering ---\n",
            "✅ Success! Advanced training file saved as 'advanced_feature_training_data_2021_present.csv'\n",
            "\n",
            "--- [STEP 4/7] Starting: Automated Model Tuning (this may take several minutes) ---\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "\n",
            "--- Tuning Complete ---\n",
            "✅ Best MAE Score found: 114081.35\n",
            "✅ Best Hyperparameters found: {'subsample': 0.9, 'n_estimators': 700, 'max_depth': 4, 'learning_rate': 0.01, 'colsample_bytree': 0.7}\n",
            "\n",
            "--- [STEP 5/7] Starting: Final Model Training ---\n",
            "✅ Success! Final model trained on all available data.\n",
            "\n",
            "--- [STEP 6/7] Starting: Saving the Final Model ---\n",
            "✅ Success! Final model has been saved as 'final_advanced_xgboost_model_2021_present.json'.\n",
            "\n",
            "--- [STEP 7/7] Starting: Making a Live Forecast ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1517842121.py:219: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  raw_forecast_data = yf.download(TICKERS, start=forecast_start_date, end=forecast_end_date, progress=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Forecast Complete ---\n",
            "✅ Based on the latest market data for 2025-08-25, the model forecasts a call volume of: 320,071\n"
          ]
        }
      ]
    }
  ]
}