{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmWIEef1KHdgVeWyNsXsbH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/john-d-noble/callcenter/blob/main/callcenter%20w/%20call%20volatility.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas scikit-learn xgboost statsmodels tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdcu4OusXOgD",
        "outputId": "02d3f2cf-6e8f-4d15-eb87-78dd62d86fb6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.0.4)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.12/dist-packages (0.14.5)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.3)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels) (1.0.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from statsmodels) (25.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.74.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === DO NOT MANUALLY SELECT THIS TEXT. USE THE COPY BUTTON. ===\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "# Import ML and Stats Libraries\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "import xgboost as xgb\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def run_forecasting_analysis():\n",
        "    \"\"\"\n",
        "    This function encapsulates the entire analysis process.\n",
        "    \"\"\"\n",
        "    # --- 1. Data Loading and Preparation ---\n",
        "    print(\"Step 1: Loading and preparing data...\")\n",
        "\n",
        "    try:\n",
        "        # Find the correct header row number first\n",
        "        header_row_number = 0\n",
        "        with open('/content/final_simulated_data_with_volatility.csv', 'r') as f:\n",
        "            for i, line in enumerate(f):\n",
        "                if line.strip().startswith('date'):\n",
        "                    header_row_number = i\n",
        "                    break\n",
        "\n",
        "        # Load the data using the dynamically found header row\n",
        "        df = pd.read_csv(\n",
        "            '/content/final_simulated_data_with_volatility.csv',\n",
        "            sep='\\s+',\n",
        "            skiprows=header_row_number,\n",
        "            skipfooter=1,\n",
        "            engine='python'\n",
        "        )\n",
        "    except FileNotFoundError:\n",
        "        print(\"\\nERROR: 'final_simulated_data_with_volatility.csv' not found.\")\n",
        "        print(\"Please make sure the data file is in the correct location.\\n\")\n",
        "        return\n",
        "\n",
        "    df.columns = ['date', 'btc_price', 'eth_price', 'sol_price', 'vix_index', 'call_volume']\n",
        "\n",
        "    # Clean the data\n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "    df.set_index('date', inplace=True)\n",
        "    df.drop(['eth_price', 'sol_price'], axis=1, inplace=True)\n",
        "    df.sort_index(inplace=True)\n",
        "    print(\"Data successfully loaded and cleaned.\")\n",
        "\n",
        "    # --- 2. Feature Engineering ---\n",
        "    print(\"Step 2: Engineering features...\")\n",
        "    df['day_of_week'] = df.index.dayofweek\n",
        "    df['month'] = df.index.month\n",
        "    df['week_of_year'] = df.index.isocalendar().week.astype(int)\n",
        "    df['year'] = df.index.year\n",
        "    df['call_volume_lag1'] = df['call_volume'].shift(1)\n",
        "    df['call_volume_lag7'] = df['call_volume'].shift(7)\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    # --- 3. Data Splitting ---\n",
        "    print(\"Step 3: Splitting data into training and testing sets...\")\n",
        "    test_size = 90\n",
        "    train_df = df[:-test_size]\n",
        "    test_df = df[-test_size:]\n",
        "\n",
        "    X_train = train_df.drop('call_volume', axis=1)\n",
        "    y_train = train_df['call_volume']\n",
        "    X_test = test_df.drop('call_volume', axis=1)\n",
        "    y_test = test_df['call_volume']\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    # --- 4. Model Training and Evaluation ---\n",
        "    print(\"\\n--- Running Models & Displaying Inline Results ---\")\n",
        "    header = f\"{'Model':<20} | {'MAE':>8} | {'RMSE':>8} | {'MAPE (%)':>10} | {'Improvement (%)':>18}\"\n",
        "    print(header)\n",
        "    print(\"-\" * len(header))\n",
        "\n",
        "    # Model 1: Baseline (Naive Forecast)\n",
        "    baseline_preds = test_df['call_volume_lag7']\n",
        "    baseline_mae = mean_absolute_error(y_test, baseline_preds)\n",
        "    baseline_rmse = np.sqrt(mean_squared_error(y_test, baseline_preds))\n",
        "    baseline_mape = np.mean(np.abs((y_test - baseline_preds) / y_test)) * 100\n",
        "    results['Baseline (Naive)'] = {'MAE': baseline_mae, 'RMSE': baseline_rmse, 'MAPE (%)': baseline_mape}\n",
        "    print(f\"{'Baseline (Naive)':<20} | {baseline_mae:>8.2f} | {baseline_rmse:>8.2f} | {baseline_mape:>10.2f} | {'N/A':>18}\")\n",
        "\n",
        "    # Model 2: Linear Regression\n",
        "    lr_model = LinearRegression()\n",
        "    lr_model.fit(X_train, y_train)\n",
        "    lr_preds = lr_model.predict(X_test)\n",
        "    lr_mae = mean_absolute_error(y_test, lr_preds)\n",
        "    lr_rmse = np.sqrt(mean_squared_error(y_test, lr_preds))\n",
        "    lr_mape = np.mean(np.abs((y_test - lr_preds) / y_test)) * 100\n",
        "    results['Linear Regression'] = {'MAE': lr_mae, 'RMSE': lr_rmse, 'MAPE (%)': lr_mape}\n",
        "    improvement = 100 * (baseline_mape - lr_mape) / baseline_mape\n",
        "    print(f\"{'Linear Regression':<20} | {lr_mae:>8.2f} | {lr_rmse:>8.2f} | {lr_mape:>10.2f} | {improvement:>18.2f}\")\n",
        "\n",
        "    # Model 3: ARIMA\n",
        "    arima_model = ARIMA(endog=y_train, exog=X_train, order=(5, 1, 0))\n",
        "    arima_results = arima_model.fit()\n",
        "    arima_preds = arima_results.forecast(steps=len(X_test), exog=X_test)\n",
        "    arima_mae = mean_absolute_error(y_test, arima_preds)\n",
        "    arima_rmse = np.sqrt(mean_squared_error(y_test, arima_preds))\n",
        "    arima_mape = np.mean(np.abs((y_test - arima_preds) / y_test)) * 100\n",
        "    results['ARIMA'] = {'MAE': arima_mae, 'RMSE': arima_rmse, 'MAPE (%)': arima_mape}\n",
        "    improvement = 100 * (baseline_mape - arima_mape) / baseline_mape\n",
        "    print(f\"{'ARIMA':<20} | {arima_mae:>8.2f} | {arima_rmse:>8.2f} | {arima_mape:>10.2f} | {improvement:>18.2f}\")\n",
        "\n",
        "    # Model 4: XGBoost\n",
        "    xgb_model = xgb.XGBRegressor(\n",
        "        objective='reg:squarederror', n_estimators=1000, learning_rate=0.01,\n",
        "        max_depth=5, subsample=0.8, colsample_bytree=0.8, random_state=42,\n",
        "        early_stopping_rounds=50\n",
        "    )\n",
        "    xgb_model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
        "    xgb_preds = xgb_model.predict(X_test)\n",
        "    xgb_mae = mean_absolute_error(y_test, xgb_preds)\n",
        "    xgb_rmse = np.sqrt(mean_squared_error(y_test, xgb_preds))\n",
        "    xgb_mape = np.mean(np.abs((y_test - xgb_preds) / y_test)) * 100\n",
        "    results['XGBoost'] = {'MAE': xgb_mae, 'RMSE': xgb_rmse, 'MAPE (%)': xgb_mape}\n",
        "    improvement = 100 * (baseline_mape - xgb_mape) / baseline_mape\n",
        "    print(f\"{'XGBoost':<20} | {xgb_mae:>8.2f} | {xgb_rmse:>8.2f} | {xgb_mape:>10.2f} | {improvement:>18.2f}\")\n",
        "\n",
        "    # Model 5: LSTM\n",
        "    print(\"Running LSTM model (this may take a few minutes)...\")\n",
        "    scaler_features = MinMaxScaler()\n",
        "    scaler_target = MinMaxScaler()\n",
        "    X_train_scaled = scaler_features.fit_transform(X_train)\n",
        "    X_test_scaled = scaler_features.transform(X_test)\n",
        "    y_train_scaled = scaler_target.fit_transform(y_train.values.reshape(-1, 1))\n",
        "\n",
        "    def create_sequences(X, y, time_steps=7):\n",
        "        Xs, ys = [], []\n",
        "        for i in range(len(X) - time_steps):\n",
        "            Xs.append(X[i:(i + time_steps)])\n",
        "            ys.append(y[i + time_steps])\n",
        "        return np.array(Xs), np.array(ys)\n",
        "\n",
        "    TIME_STEPS = 7\n",
        "    X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train_scaled, TIME_STEPS)\n",
        "\n",
        "    lstm_model = Sequential([\n",
        "        LSTM(50, activation='relu', input_shape=(X_train_seq.shape[1], X_train_seq.shape[2])),\n",
        "        Dropout(0.2),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    lstm_model.fit(X_train_seq, y_train_seq, epochs=50, batch_size=32, verbose=0, shuffle=False)\n",
        "\n",
        "    padded_X_test = np.concatenate([X_train_scaled[-TIME_STEPS:], X_test_scaled])\n",
        "    X_test_seq, _ = create_sequences(padded_X_test, np.zeros(len(padded_X_test)), TIME_STEPS)\n",
        "\n",
        "    lstm_preds_scaled = lstm_model.predict(X_test_seq, verbose=0)\n",
        "    lstm_preds = scaler_target.inverse_transform(lstm_preds_scaled).flatten()\n",
        "\n",
        "    lstm_mae = mean_absolute_error(y_test, lstm_preds)\n",
        "    lstm_rmse = np.sqrt(mean_squared_error(y_test, lstm_preds))\n",
        "    lstm_mape = np.mean(np.abs((y_test - lstm_preds) / y_test)) * 100\n",
        "    results['LSTM'] = {'MAE': lstm_mae, 'RMSE': lstm_rmse, 'MAPE (%)': lstm_mape}\n",
        "    improvement = 100 * (baseline_mape - lstm_mape) / baseline_mape\n",
        "    print(f\"{'LSTM':<20} | {lstm_mae:>8.2f} | {lstm_rmse:>8.2f} | {lstm_mape:>10.2f} | {improvement:>18.2f}\")\n",
        "\n",
        "    # --- 5. Generate and Print Final Summary Table ---\n",
        "    print(\"\\n\\n--- Final Summary Table ---\")\n",
        "    results_df = pd.DataFrame.from_dict(results, orient='index')\n",
        "    results_df = results_df.reset_index().rename(columns={'index': 'Model'})\n",
        "    results_df['Improvement over Baseline (%)'] = 100 * (baseline_mape - results_df['MAPE (%)']) / baseline_mape\n",
        "    results_df = results_df.round(2).sort_values(by='MAPE (%)', ascending=True)\n",
        "    print(results_df.to_string(index=False))\n",
        "    print(\"\\n--- Analysis Complete ---\")\n",
        "\n",
        "\n",
        "# --- Execute the entire analysis ---\n",
        "if __name__ == \"__main__\":\n",
        "    run_forecasting_analysis()"
      ],
      "metadata": {
        "id": "sUHwpQL8dwNI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "c0fb3a3f-f7d2-4a5c-86aa-d0f49bcde677"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:38: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:38: SyntaxWarning: invalid escape sequence '\\s'\n",
            "/tmp/ipython-input-1613536554.py:38: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  sep='\\s+',\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: Loading and preparing data...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Length mismatch: Expected axis has 1 elements, new values have 6 elements",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1613536554.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;31m# --- Execute the entire analysis ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0mrun_forecasting_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1613536554.py\u001b[0m in \u001b[0;36mrun_forecasting_analysis\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'btc_price'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'eth_price'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sol_price'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vix_index'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'call_volume'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# Clean the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   6311\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6312\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6313\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6314\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6315\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mproperties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \"\"\"\n\u001b[1;32m    813\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mset_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAxisInt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;31m# Caller is responsible for ensuring we have an Index object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/internals/base.py\u001b[0m in \u001b[0;36m_validate_set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mnew_len\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mold_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m     99\u001b[0m                 \u001b[0;34mf\"Length mismatch: Expected axis has {old_len} elements, new \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;34mf\"values have {new_len} elements\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 1 elements, new values have 6 elements"
          ]
        }
      ]
    }
  ]
}