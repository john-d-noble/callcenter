{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPorPTza54WBiUNStpwYxj8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/john-d-noble/callcenter/blob/main/CB_Step_5_Deep_Learning_and_Hybrid_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas numpy scikit-learn tensorflow prophet xgboost neuralprophet"
      ],
      "metadata": {
        "id": "VA1lpScxlO8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Input\n",
        "from prophet import Prophet\n",
        "from xgboost import XGBRegressor\n",
        "from neuralprophet import NeuralProphet\n",
        "import torch  # Added for safe_globals\n",
        "\n",
        "# Fix for UnpicklingError: Import the actual class and add to safe_globals\n",
        "from neuralprophet.configure import ConfigSeasonality\n",
        "torch.serialization.add_safe_globals([ConfigSeasonality])\n",
        "\n",
        "# Step 1: Load the data from CSV file with explicit date format to suppress parsing warning\n",
        "df = pd.read_csv('updated_final_merged_data.csv', parse_dates=['Date'], date_format='%m/%d/%y', index_col='Date')\n",
        "\n",
        "# Assume 'Calls' is the target column\n",
        "target = 'Calls'\n",
        "\n",
        "# Prepare data: Sort by date if not already\n",
        "df = df.sort_index()\n",
        "\n",
        "# Feature Engineering (similar to ML: lags, rollings, dummies)\n",
        "df['Lag1'] = df[target].shift(1)\n",
        "df['Lag7'] = df[target].shift(7)\n",
        "df['Rolling_Mean_7'] = df[target].rolling(window=7).mean()\n",
        "df['Rolling_Std_7'] = df[target].rolling(window=7).std()\n",
        "df = pd.get_dummies(df, columns=['DayOfWeek'], drop_first=True)\n",
        "\n",
        "# Select features (numeric except target)\n",
        "features = [col for col in df.columns if col != target and df[col].dtype in [np.float64, np.int64, bool]]\n",
        "\n",
        "# Drop NaNs\n",
        "df = df.dropna()\n",
        "\n",
        "# For DL models, scale data\n",
        "scaler = MinMaxScaler()\n",
        "df_scaled = pd.DataFrame(scaler.fit_transform(df[features + [target]]), index=df.index, columns=features + [target])\n",
        "\n",
        "# Time series cross-validation: 5 splits\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "# Function to calculate metrics\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mape = mean_absolute_percentage_error(y_true, y_pred) * 100  # As percentage\n",
        "    return {'MAE': mae, 'RMSE': rmse, 'MAPE': mape}\n",
        "\n",
        "# Dictionary to store average metrics for each model\n",
        "model_metrics = {}\n",
        "\n",
        "# Helper to create sequences for LSTM (timesteps=7)\n",
        "def create_sequences(data, timesteps=7):\n",
        "    X_seq, y_seq = [], []\n",
        "    for i in range(len(data) - timesteps):\n",
        "        X_seq.append(data.iloc[i:i+timesteps].values)\n",
        "        y_seq.append(data.iloc[i+timesteps][target])  # Predict next value\n",
        "    return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "# 1. LSTM Network\n",
        "lstm_preds = []\n",
        "lstm_trues = []\n",
        "for train_idx, test_idx in tscv.split(df_scaled):\n",
        "    train = df_scaled.iloc[train_idx]\n",
        "    test = df_scaled.iloc[test_idx]\n",
        "\n",
        "    # Create sequences\n",
        "    X_train_seq, y_train_seq = create_sequences(train)\n",
        "    X_test_seq, y_test_seq = create_sequences(test)\n",
        "\n",
        "    # Build LSTM model with Input layer to suppress warning\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(7, len(train.columns))))\n",
        "    model.add(LSTM(50, activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "    # Fit (with verbose=1 for debugging if needed; set to 0 for silent)\n",
        "    model.fit(X_train_seq, y_train_seq, epochs=50, batch_size=32, verbose=0)\n",
        "\n",
        "    # Predict (adjust for sequence length)\n",
        "    pred = model.predict(X_test_seq, verbose=0).flatten()\n",
        "\n",
        "    lstm_preds.extend(pred)\n",
        "    lstm_trues.extend(y_test_seq)\n",
        "\n",
        "# Inverse scale predictions and trues\n",
        "lstm_preds_inv = scaler.inverse_transform(np.concatenate((np.zeros((len(lstm_preds), len(features))), np.array(lstm_preds).reshape(-1,1)), axis=1))[:, -1]\n",
        "lstm_trues_inv = scaler.inverse_transform(np.concatenate((np.zeros((len(lstm_trues), len(features))), np.array(lstm_trues).reshape(-1,1)), axis=1))[:, -1]\n",
        "\n",
        "lstm_metrics = calculate_metrics(lstm_trues_inv, lstm_preds_inv)\n",
        "model_metrics['LSTM'] = lstm_metrics\n",
        "\n",
        "# 2. Neural Prophet (with matplotlib backend to avoid Plotly error)\n",
        "np_preds = []\n",
        "np_trues = []\n",
        "for train_idx, test_idx in tscv.split(df):\n",
        "    train_df = df.iloc[train_idx].reset_index().rename(columns={'Date': 'ds', 'Calls': 'y'})\n",
        "    test_df = df.iloc[test_idx].reset_index().rename(columns={'Date': 'ds', 'Calls': 'y'})\n",
        "\n",
        "    # Fit NeuralProphet with matplotlib and explicit seasonalities\n",
        "    model = NeuralProphet(epochs=50, batch_size=32, learning_rate=0.01,  # Manual LR to avoid finder warning\n",
        "                          yearly_seasonality=False, daily_seasonality=False)  # Explicit to suppress auto warnings\n",
        "    model.set_plotting_backend('matplotlib')\n",
        "    model.fit(train_df[['ds', 'y']], freq='D')\n",
        "\n",
        "    # Make future dataframe\n",
        "    future = model.make_future_dataframe(train_df[['ds', 'y']], periods=len(test_df))\n",
        "\n",
        "    # Predict\n",
        "    forecast = model.predict(future)\n",
        "    pred = forecast['yhat1'].tail(len(test_df)).values\n",
        "\n",
        "    np_preds.extend(pred)\n",
        "    np_trues.extend(test_df['y'])\n",
        "\n",
        "np_metrics = calculate_metrics(np_trues, np_preds)\n",
        "model_metrics['Neural Prophet'] = np_metrics\n",
        "\n",
        "# 3. Hybrid: Prophet + XGBoost (Prophet for trend/seasonal, XGBoost on residuals)\n",
        "hybrid_preds = []\n",
        "hybrid_trues = []\n",
        "for train_idx, test_idx in tscv.split(df):\n",
        "    train_df = df.iloc[train_idx].reset_index().rename(columns={'Date': 'ds', 'Calls': 'y'})\n",
        "    test_df = df.iloc[test_idx].reset_index().rename(columns={'Date': 'ds', 'Calls': 'y'})\n",
        "\n",
        "    # Step 1: Fit Prophet\n",
        "    prophet_model = Prophet(weekly_seasonality=True)\n",
        "    prophet_model.fit(train_df[['ds', 'y']])\n",
        "\n",
        "    # Predict on train and test\n",
        "    train_future = prophet_model.make_future_dataframe(periods=0)\n",
        "    train_forecast = prophet_model.predict(train_future)\n",
        "    train_residuals = train_df['y'] - train_forecast['yhat']\n",
        "\n",
        "    test_future = prophet_model.make_future_dataframe(periods=len(test_df))\n",
        "    test_forecast = prophet_model.predict(test_future)\n",
        "    prophet_test_pred = test_forecast['yhat'].tail(len(test_df))\n",
        "\n",
        "    # Step 2: Fit XGBoost on residuals using features\n",
        "    X_train = train_df[features]\n",
        "    y_res_train = train_residuals\n",
        "\n",
        "    xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "    xgb_model.fit(X_train, y_res_train)\n",
        "\n",
        "    # Predict residuals on test\n",
        "    X_test = test_df[features]\n",
        "    res_pred = xgb_model.predict(X_test)\n",
        "\n",
        "    # Combine: Prophet pred + residual pred\n",
        "    pred = prophet_test_pred + res_pred\n",
        "\n",
        "    hybrid_preds.extend(pred)\n",
        "    hybrid_trues.extend(test_df['y'])\n",
        "\n",
        "hybrid_metrics = calculate_metrics(hybrid_trues, hybrid_preds)\n",
        "model_metrics['Prophet + XGBoost Hybrid'] = hybrid_metrics\n",
        "\n",
        "# Summarize performance\n",
        "print(\"\\nModel Performance Summary:\")\n",
        "metrics_df = pd.DataFrame(model_metrics).T\n",
        "print(metrics_df)\n",
        "\n",
        "# Pick winner: Lowest MAE (primary metric)\n",
        "winner = metrics_df['MAE'].idxmin()\n",
        "print(f\"\\nChampion DL/Hybrid Model: {winner}\")\n",
        "print(f\"Metrics: {metrics_df.loc[winner].to_dict()}\")"
      ],
      "metadata": {
        "id": "HakXAQA2pStF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**### Combined Performance Summary: Baseline, Classical, Machine Learning, and Deep Learning/Hybrid Models**\n",
        "\n",
        "To offer a complete evaluation of the forecasting models for call center volume, below are the performance tables for all tiers tested: baselines (simple benchmarks), classical time series (univariate with trend and seasonality), machine learning (multivariate with feature engineering like lags, rollings, day-of-week dummies, and market indicators), and deep learning/hybrids (sequence-based and combined approaches for complex patterns). All models were assessed using time-series cross-validation on the filled dataset, with consistent metrics: Mean Absolute Error (MAE, in call counts), Root Mean Squared Error (RMSE, penalizing larger errors), and Mean Absolute Percentage Error (MAPE, for relative accuracy). This cumulative view tracks progress across increasing complexity, building on EDA insights such as strong weekly seasonality, non-stationarity, outliers, and market correlations (e.g., VIX and CVOL).\n",
        "\n",
        "#### Baseline Models Performance\n",
        "| Model          | MAE       | RMSE      | MAPE     |\n",
        "|----------------|-----------|-----------|----------|\n",
        "| Naive          | 2351.46  | 2942.38  | 24.84%  |\n",
        "| Mean           | 1634.56  | 2154.49  | 18.23%  |\n",
        "| Median         | 1613.91  | 2177.89  | 17.38%  |\n",
        "| Seasonal Naive | 907.70   | 1359.05  | 9.67%   |\n",
        "\n",
        "**Baseline Champion**: Seasonal Naive (strong due to weekly patterns).\n",
        "\n",
        "#### Classical Models Performance\n",
        "| Model   | MAE       | RMSE      | MAPE     |\n",
        "|---------|-----------|-----------|----------|\n",
        "| ARIMA   | 2268.08  | 2860.61  | 24.43%  |\n",
        "| SARIMA  | 2560.83  | 3163.07  | 28.56%  |\n",
        "| ETS     | 2233.64  | 2882.92  | 22.57%  |\n",
        "\n",
        "**Classical Champion**: ETS (modest handling of trends but underperforms baselines).\n",
        "\n",
        "#### Machine Learning Models Performance\n",
        "| Model         | MAE       | RMSE      | MAPE     |\n",
        "|---------------|-----------|-----------|----------|\n",
        "| Ridge         | 1011.39  | 1392.16  | 10.89%  |\n",
        "| Random Forest | 1080.18  | 1700.63  | 11.13%  |\n",
        "| XGBoost       | 1338.68  | 1955.16  | 14.52%  |\n",
        "| SVR           | 1925.28  | 2607.63  | 20.17%  |\n",
        "\n",
        "**ML Champion**: Ridge (benefits from regularization and features, nearing baseline levels).\n",
        "\n",
        "#### Deep Learning/Hybrid Models Performance\n",
        "| Model                     | MAE       | RMSE      | MAPE     |\n",
        "|---------------------------|-----------|-----------|----------|\n",
        "| LSTM                      | 2143.27  | 2893.43  | 24.44%  |\n",
        "| Neural Prophet            | 3626.81  | 4798.90  | 43.38%  |\n",
        "| Prophet + XGBoost Hybrid  | 3867.73  | 4738.37  | 44.67%  |\n",
        "\n",
        "**DL/Hybrid Champion**: LSTM (best in tier for sequence learning, but higher errors overall).\n",
        "\n",
        "### Full Narrative Analysis\n",
        "The baseline models provide an essential foundation, demonstrating that even simple methods can effectively capture key patterns in the call volume data. The Naive approach, which persists the last value, yields high errors (MAE ~2,351, MAPE 25%) amid daily fluctuations, while Mean and Median improve modestly (MAEs ~1,614-1,635, MAPEs 17-18%) by focusing on central tendencies, aligning with the EDA's slightly skewed distribution. The Seasonal Naive excels (MAE 908, MAPE under 10%), directly leveraging the EDA's decomposed weekly seasonality and day-of-week variations for reliable periodic forecasts, even after imputing non-business days.\n",
        "\n",
        "Classical models, emphasizing univariate trends and seasonality, show inconsistent gains. ARIMA addresses non-stationarity (per EDA's ADF test) with an MAE of 2,268 and MAPE of 24%, but overlooks cycles. SARIMA, incorporating weekly terms, performs worst (MAE 2,561, MAPE 29%), possibly overfitting to outliers or filled data noise. ETS offers the best classical results (MAE 2,234, MAPE 23%) through smoothing of trends and additive seasonality, consistent with EDA rolling stats, but remains outperformed by baselines, suggesting limited added value from parameterization.\n",
        "\n",
        "Machine learning models advance by integrating multivariate features (e.g., lags for autocorrelation, rollings for volatility, dummies for days, and market vars like VIX/CVOL per EDA correlations >0.2), yielding clearer improvements. Ridge leads (MAE 1,011, MAPE 11%) with regularization handling collinearity and outliers. Random Forest (MAE 1,080, MAPE 11%) captures non-linear interactions via ensembles, while XGBoost (MAE 1,339, MAPE 15%) boosts performance but risks overfitting. SVR trails (MAE 1,925, MAPE 20%), less suited for this tabular time-series data. Overall, ML reduces classical errors by ~50% (e.g., Ridge vs. ETS), approaching baseline efficiency through feature-driven predictions.\n",
        "\n",
        "The deep learning/hybrid tier, designed for complex sequences and combinations, introduces neural architectures but yields mixed outcomes. LSTM, processing scaled sequences with lags, achieves the tier's best (MAE 2,143, MAPE 24%), capturing long dependencies from EDA autocorrelation but struggling with the dataset's scale or noise, performing similarly to classical ARIMA. Neural Prophet, extending Prophet with nets, ranks worst (MAE 3,627, MAPE 43%), potentially due to insufficient data for deep learning or sensitivity to imputation. The Prophet + XGBoost hybrid (MAE 3,868, MAPE 45%) combines trend/seasonality with residual boosting on features, but high errors suggest the univariate base limits multivariate gains.\n",
        "\n",
        "Cumulatively, errors decrease from baselines/classical (MAEs >2,000) to ML (~1,000), but DL/hybrids regress (>2,000), indicating overfitting, data scarcity for deep models, or suboptimal tuning amid EDA-noted outliers and volatility. The overall champion remains Seasonal Naive (MAPE <10%), as more complex tiers haven't surpassed itâ€”highlighting that the dominant weekly rhythm (per decomposition) favors simplicity. ML's Ridge comes closest, validating feature engineering's value for market ties. To progress, consider hyperparameter tuning, ensembles (e.g., stacking Ridge + Seasonal Naive), or more data; otherwise, deploy the baseline for efficient, interpretable forecasting in call center planning."
      ],
      "metadata": {
        "id": "APjAEHoqqmtw"
      }
    }
  ]
}