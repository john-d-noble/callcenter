{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/john-d-noble/callcenter/blob/main/CB_Step_5_Deep_Learning_and_Hybrid_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas numpy scikit-learn tensorflow prophet xgboost neuralprophet"
      ],
      "metadata": {
        "id": "VA1lpScxlO8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Input\n",
        "from prophet import Prophet\n",
        "from xgboost import XGBRegressor\n",
        "from neuralprophet import NeuralProphet\n",
        "import torch\n",
        "\n",
        "# Fix for UnpicklingError\n",
        "from neuralprophet.configure import ConfigSeasonality\n",
        "torch.serialization.add_safe_globals([ConfigSeasonality])\n",
        "\n",
        "# Step 1: Load the data\n",
        "df = pd.read_csv('enhanced_eda_data.csv', parse_dates=['Date'], date_format='%m/%d/%y', index_col='Date')\n",
        "\n",
        "# Assume 'calls' is the target column\n",
        "target = 'calls'\n",
        "\n",
        "# Prepare data\n",
        "df = df.sort_index()\n",
        "\n",
        "# Feature Engineering\n",
        "df['Lag1'] = df[target].shift(1)\n",
        "df['Lag7'] = df[target].shift(7)\n",
        "df['Rolling_Mean_7'] = df[target].rolling(window=7).mean()\n",
        "df['Rolling_Std_7'] = df[target].rolling(window=7).std()\n",
        "df = pd.get_dummies(df, columns=['DayOfWeek'], drop_first=True)\n",
        "\n",
        "# Select features\n",
        "features = [col for col in df.columns if col != target and df[col].dtype in [np.float64, np.int64, bool]]\n",
        "\n",
        "# Drop NaNs\n",
        "df = df.dropna()\n",
        "\n",
        "# Scale data for DL models\n",
        "scaler = MinMaxScaler()\n",
        "df_scaled = pd.DataFrame(scaler.fit_transform(df[features + [target]]), index=df.index, columns=features + [target])\n",
        "\n",
        "# Time series cross-validation\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "# Function to calculate metrics\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mape = mean_absolute_percentage_error(y_true, y_pred) * 100\n",
        "    return {'MAE': mae, 'RMSE': rmse, 'MAPE': mape}\n",
        "\n",
        "# Dictionary to store metrics\n",
        "model_metrics = {}\n",
        "\n",
        "# Helper to create sequences for LSTM\n",
        "def create_sequences(data, timesteps=7):\n",
        "    X_seq, y_seq = [], []\n",
        "    for i in range(len(data) - timesteps):\n",
        "        X_seq.append(data.iloc[i:i+timesteps].values)\n",
        "        y_seq.append(data.iloc[i+timesteps][target])\n",
        "    return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "# 1. LSTM Network\n",
        "lstm_preds = []\n",
        "lstm_trues = []\n",
        "for train_idx, test_idx in tscv.split(df_scaled):\n",
        "    train = df_scaled.iloc[train_idx]\n",
        "    test = df_scaled.iloc[test_idx]\n",
        "    X_train_seq, y_train_seq = create_sequences(train)\n",
        "    X_test_seq, y_test_seq = create_sequences(test)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(7, len(train.columns))))\n",
        "    model.add(LSTM(50, activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    model.fit(X_train_seq, y_train_seq, epochs=50, batch_size=32, verbose=0)\n",
        "\n",
        "    pred = model.predict(X_test_seq, verbose=0).flatten()\n",
        "    lstm_preds.extend(pred)\n",
        "    lstm_trues.extend(y_test_seq)\n",
        "\n",
        "lstm_preds_inv = scaler.inverse_transform(np.concatenate((np.zeros((len(lstm_preds), len(features))), np.array(lstm_preds).reshape(-1,1)), axis=1))[:, -1]\n",
        "lstm_trues_inv = scaler.inverse_transform(np.concatenate((np.zeros((len(lstm_trues), len(features))), np.array(lstm_trues).reshape(-1,1)), axis=1))[:, -1]\n",
        "model_metrics['LSTM'] = calculate_metrics(lstm_trues_inv, lstm_preds_inv)\n",
        "\n",
        "# 2. Neural Prophet\n",
        "np_preds = []\n",
        "np_trues = []\n",
        "for train_idx, test_idx in tscv.split(df):\n",
        "    train_df = df.iloc[train_idx].reset_index().rename(columns={'Date': 'ds', target: 'y'})\n",
        "    test_df = df.iloc[test_idx].reset_index().rename(columns={'Date': 'ds', target: 'y'})\n",
        "\n",
        "    model = NeuralProphet(epochs=50, batch_size=32, learning_rate=0.01, yearly_seasonality=False, daily_seasonality=False)\n",
        "    model.set_plotting_backend('matplotlib')\n",
        "    model.fit(train_df[['ds', 'y']], freq='D')\n",
        "\n",
        "    future = model.make_future_dataframe(train_df[['ds', 'y']], periods=len(test_df))\n",
        "    forecast = model.predict(future)\n",
        "    pred = forecast['yhat1'].tail(len(test_df)).values\n",
        "\n",
        "    np_preds.extend(pred)\n",
        "    np_trues.extend(test_df['y'])\n",
        "\n",
        "model_metrics['Neural Prophet'] = calculate_metrics(np_trues, np_preds)\n",
        "\n",
        "# 3. Hybrid: Prophet + XGBoost\n",
        "hybrid_preds = []\n",
        "hybrid_trues = []\n",
        "for train_idx, test_idx in tscv.split(df):\n",
        "    train_df = df.iloc[train_idx].reset_index().rename(columns={'Date': 'ds', target: 'y'})\n",
        "    test_df = df.iloc[test_idx].reset_index().rename(columns={'Date': 'ds', target: 'y'})\n",
        "\n",
        "    prophet_model = Prophet(weekly_seasonality=True)\n",
        "    prophet_model.fit(train_df[['ds', 'y']])\n",
        "\n",
        "    train_future = prophet_model.make_future_dataframe(periods=0)\n",
        "    train_forecast = prophet_model.predict(train_future)\n",
        "    train_residuals = train_df['y'] - train_forecast['yhat']\n",
        "\n",
        "    test_future = prophet_model.make_future_dataframe(periods=len(test_df))\n",
        "    test_forecast = prophet_model.predict(test_future)\n",
        "    prophet_test_pred = test_forecast['yhat'].tail(len(test_df))\n",
        "\n",
        "    X_train = train_df[features]\n",
        "    y_res_train = train_residuals\n",
        "\n",
        "    xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "    xgb_model.fit(X_train, y_res_train)\n",
        "\n",
        "    X_test = test_df[features]\n",
        "    res_pred = xgb_model.predict(X_test)\n",
        "    pred = prophet_test_pred + res_pred\n",
        "\n",
        "    hybrid_preds.extend(pred)\n",
        "    hybrid_trues.extend(test_df['y'])\n",
        "\n",
        "model_metrics['Prophet + XGBoost Hybrid'] = calculate_metrics(hybrid_trues, hybrid_preds)\n",
        "\n",
        "# Summarize performance\n",
        "print(\"\\nModel Performance Summary:\")\n",
        "metrics_df = pd.DataFrame(model_metrics).T\n",
        "print(metrics_df)\n",
        "\n",
        "winner = metrics_df['MAE'].idxmin()\n",
        "print(f\"\\nChampion DL/Hybrid Model: {winner}\")\n",
        "print(f\"Metrics: {metrics_df.loc[winner].to_dict()}\")"
      ],
      "metadata": {
        "id": "hPLqaCfDrhto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "\n",
        "# Suppress a common SHAP warning\n",
        "warnings.filterwarnings('ignore', category=UserWarning, module='shap.explainers._deep.deep_tf')\n",
        "\n",
        "print(\"--- Preparing data and models for interpretation ---\")\n",
        "\n",
        "# 1. Create a final, persistent train/test split from the last CV fold\n",
        "all_splits = list(tscv.split(df))\n",
        "train_idx, test_idx = all_splits[-1]\n",
        "\n",
        "# Original unscaled data split\n",
        "train_df_final = df.iloc[train_idx]\n",
        "test_df_final = df.iloc[test_idx]\n",
        "\n",
        "# Scaled data split for LSTM\n",
        "train_scaled_final = df_scaled.iloc[train_idx]\n",
        "test_scaled_final = df_scaled.iloc[test_idx]\n",
        "\n",
        "# Prepare data for models that need 'ds', 'y' format\n",
        "# <<< CORRECTION HERE: Changed 'date' to 'Date' to match the actual column name\n",
        "train_prophet_format = train_df_final.reset_index().rename(columns={'Date': 'ds', 'calls': 'y'})\n",
        "# <<< CORRECTION HERE: Changed 'date' to 'Date' to match the actual column name\n",
        "test_prophet_format = test_df_final.reset_index().rename(columns={'Date': 'ds', 'calls': 'y'})\n",
        "\n",
        "# --- Re-train the models one last time on the final split ---\n",
        "\n",
        "# 2a. Train Final LSTM Model\n",
        "print(\"\\nTraining final LSTM model...\")\n",
        "X_train_seq, y_train_seq = create_sequences(train_scaled_final)\n",
        "X_test_seq, y_test_seq = create_sequences(test_scaled_final)\n",
        "\n",
        "final_lstm_model = Sequential()\n",
        "final_lstm_model.add(Input(shape=(7, len(train_scaled_final.columns))))\n",
        "final_lstm_model.add(LSTM(50, activation='relu'))\n",
        "final_lstm_model.add(Dense(1))\n",
        "final_lstm_model.compile(optimizer='adam', loss='mse')\n",
        "final_lstm_model.fit(X_train_seq, y_train_seq, epochs=50, batch_size=32, verbose=0)\n",
        "print(\"LSTM training complete.\")\n",
        "\n",
        "# 2b. Train Final Neural Prophet Model\n",
        "print(\"\\nTraining final Neural Prophet model...\")\n",
        "final_np_model = NeuralProphet(epochs=50, batch_size=32, learning_rate=0.01, yearly_seasonality=False, daily_seasonality=False)\n",
        "final_np_model.set_plotting_backend('matplotlib')\n",
        "final_np_model.fit(train_prophet_format[['ds', 'y']], freq='D')\n",
        "print(\"Neural Prophet training complete.\")\n",
        "\n",
        "# 2c. Train Final Prophet + XGBoost Hybrid Model\n",
        "print(\"\\nTraining final Prophet + XGBoost Hybrid model...\")\n",
        "# Prophet part\n",
        "final_prophet_model = Prophet(weekly_seasonality=True)\n",
        "final_prophet_model.fit(train_prophet_format[['ds', 'y']])\n",
        "\n",
        "# Create Prophet forecast to calculate residuals for XGBoost\n",
        "train_forecast_prophet = final_prophet_model.predict(train_prophet_format[['ds']])\n",
        "train_residuals = train_prophet_format['y'] - train_forecast_prophet['yhat']\n",
        "\n",
        "# Create the forecast object needed for plotting components\n",
        "future_df = final_prophet_model.make_future_dataframe(periods=len(test_prophet_format))\n",
        "final_forecast_object = final_prophet_model.predict(future_df)\n",
        "\n",
        "# XGBoost part\n",
        "X_train_xgb = train_df_final[features]\n",
        "X_test_xgb = test_df_final[features]\n",
        "\n",
        "final_xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "final_xgb_model.fit(X_train_xgb, train_residuals)\n",
        "print(\"Hybrid model training complete.\")\n",
        "\n",
        "# --- Run Interpretability Analysis ---\n",
        "print(\"\\n--- Generating Model Interpretation Plots ---\")\n",
        "\n",
        "# 1. LSTM Interpretability with SHAP\n",
        "try:\n",
        "    background_data = X_train_seq[:100]\n",
        "    explainer_lstm = shap.DeepExplainer(final_lstm_model, background_data)\n",
        "    shap_values_lstm = explainer_lstm.shap_values(X_test_seq)\n",
        "\n",
        "    # Average SHAP values over timesteps for a summary plot\n",
        "    shap_values_lstm_avg = np.mean(shap_values_lstm[0], axis=1)\n",
        "    X_test_for_plot = np.mean(X_test_seq, axis=1)\n",
        "\n",
        "    print(\"\\nDisplaying SHAP plot for LSTM...\")\n",
        "    shap.summary_plot(shap_values_lstm_avg, pd.DataFrame(X_test_for_plot, columns=df_scaled.columns), show=False)\n",
        "    plt.title(\"SHAP Feature Importance for LSTM (Averaged over Timesteps)\")\n",
        "    plt.show()\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during LSTM SHAP analysis: {e}\")\n",
        "\n",
        "# 2. NeuralProphet Interpretability\n",
        "try:\n",
        "    print(\"\\nDisplaying plot for Neural Prophet...\")\n",
        "    fig_params = final_np_model.plot_parameters()\n",
        "    plt.title(\"NeuralProphet Component Contributions\")\n",
        "    plt.show()\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during NeuralProphet plot generation: {e}\")\n",
        "\n",
        "# 3. Prophet + XGBoost Hybrid Interpretability\n",
        "# 3a. Prophet Components\n",
        "try:\n",
        "    print(\"\\nDisplaying component plot for Prophet (from Hybrid)...\")\n",
        "    fig_components = final_prophet_model.plot_components(final_forecast_object)\n",
        "    plt.suptitle(\"Prophet Component Contributions in Hybrid Model\", y=1.02)\n",
        "    plt.show()\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during Prophet components plot generation: {e}\")\n",
        "\n",
        "# 3b. XGBoost with SHAP\n",
        "try:\n",
        "    print(\"\\nDisplaying SHAP plot for XGBoost (from Hybrid)...\")\n",
        "    explainer_xgb = shap.TreeExplainer(final_xgb_model)\n",
        "    shap_values_xgb = explainer_xgb.shap_values(X_test_xgb)\n",
        "\n",
        "    shap.summary_plot(shap_values_xgb, X_test_xgb, show=False)\n",
        "    plt.title(\"SHAP Feature Importance for XGBoost in Hybrid Model\")\n",
        "    plt.show()\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during XGBoost SHAP analysis: {e}\")"
      ],
      "metadata": {
        "id": "uUu9f_Ierlgg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}